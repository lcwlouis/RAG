{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d4475e4",
   "metadata": {},
   "source": [
    "# Generate Queries to test RAG System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a571d21",
   "metadata": {},
   "source": [
    "We put the entire text of the file into context and send it to Gemini-2.5-Flash and ask it to generate a list of queries that we can use to test the RAG system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33bcb68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yy/t6y4brw52tvdr8k9xbwc01d40000gn/T/ipykernel_22924/2970303829.py:61: PydanticDeprecatedSince20: The `schema` method is deprecated; use `model_json_schema` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
      "  response_schema=OutputSchema.schema()\n",
      "Key '$defs' is not supported in schema, ignoring\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\\n  \"test_cases\": [\\n    {\\n      \"citations\": [\"Copyright \\\\nÂ© 2024 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.\"],\\n      \"expected_answer\": \"The copyright for the AWS Prescriptive Guidance: Cloud design patterns, architectures, and implementations is held by Amazon Web Services, Inc. and/or its affiliates, as of 2024.\",\\n      \"query\": \"Who holds the copyright for this document and when was it issued?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Introduction .............................................................................................................................................. 1\"],\\n      \"expected_answer\": \"The Introduction section of the document starts on page 1.\",\\n      \"query\": \"On which page does the Introduction section begin?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Anti-corruption layer pattern .................................................................................................................... 3\"],\\n      \"expected_answer\": \"The Anti-corruption layer pattern section starts on page 3.\",\\n      \"query\": \"What page number is the Anti-corruption layer pattern discussed on?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"API routing patterns ................................................................................................................................ 10\"],\\n      \"expected_answer\": \"API routing patterns are covered starting on page 10.\",\\n      \"query\": \"Where can I find information about API routing patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Circuit breaker pattern ............................................................................................................................ 19\"],\\n      \"expected_answer\": \"The Circuit breaker pattern begins on page 19.\",\\n      \"query\": \"What is the starting page for the Circuit breaker pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Event sourcing pattern ............................................................................................................................ 26\"],\\n      \"expected_answer\": \"The Event sourcing pattern is detailed starting on page 26.\",\\n      \"query\": \"Which page introduces the Event sourcing pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Hexagonal architecture pattern ............................................................................................................... 34\"],\\n      \"expected_answer\": \"The Hexagonal architecture pattern starts on page 34.\",\\n      \"query\": \"On what page does the Hexagonal architecture pattern section start?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Publish-subscribe pattern ........................................................................................................................ 43\"],\\n      \"expected_answer\": \"The Publish-subscribe pattern is discussed from page 43 onwards.\",\\n      \"query\": \"What page number covers the Publish-subscribe pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Retry with backoff pattern ....................................................................................................................... 49\"],\\n      \"expected_answer\": \"The Retry with backoff pattern can be found starting on page 49.\",\\n      \"query\": \"Where can I find the Retry with backoff pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Saga patterns ........................................................................................................................................... 53\"],\\n      \"expected_answer\": \"Saga patterns are introduced on page 53.\",\\n      \"query\": \"What page number is associated with Saga patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Scatter-gather pattern ............................................................................................................................. 69\"],\\n      \"expected_answer\": \"The Scatter-gather pattern starts on page 69.\",\\n      \"query\": \"On which page does the Scatter-gather pattern begin?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Strangler fig pattern ................................................................................................................................ 78\"],\\n      \"expected_answer\": \"The Strangler fig pattern is covered from page 78.\",\\n      \"query\": \"Where can I find information about the Strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Transactional outbox pattern .................................................................................................................. 91\"],\\n      \"expected_answer\": \"The Transactional outbox pattern is discussed starting on page 91.\",\\n      \"query\": \"What page number details the Transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Table of Contents\", \"Glossary ................................................................................................................................................... 105\"],\\n      \"expected_answer\": \"The Glossary starts on page 105.\",\\n      \"query\": \"What is the starting page for the Glossary?\"\\n    },\\n    {\\n      \"citations\": [\"Cloud design patterns, architectures, and implementations\", \"Anitha Deenadayalan, Amazon Web Services (AWS)\"],\\n      \"expected_answer\": \"The author of \\\\\"Cloud design patterns, architectures, and implementations\\\\\" is Anitha Deenadayalan from Amazon Web Services (AWS).\",\\n      \"query\": \"Who is the author of this guide?\"\\n    },\\n    {\\n      \"citations\": [\"May 2024 (document history)\"],\\n      \"expected_answer\": \"The document history indicates May 2024.\",\\n      \"query\": \"When was the document last updated according to its history?\"\\n    },\\n    {\\n      \"citations\": [\"This guide provides guidance for implementing commonly used modernization design patterns by using AWS services.\"],\\n      \"expected_answer\": \"This guide provides guidance for implementing commonly used modernization design patterns by using AWS services.\",\\n      \"query\": \"What is the primary purpose of this guide?\"\\n    },\\n    {\\n      \"citations\": [\"An increasing number of modern applications are designed by using microservices architectures to achieve scalability, improve release velocity, reduce the scope of impact for changes, and reduce regression.\"],\\n      \"expected_answer\": \"Modern applications increasingly use microservices architectures to achieve scalability, improve release velocity, reduce the scope of impact for changes, and reduce regression.\",\\n      \"query\": \"Why are modern applications increasingly designed with microservices architectures?\"\\n    },\\n    {\\n      \"citations\": [\"This leads to improved developer productivity and increased agility, better innovation, and an increased focus on business needs. Microservices architectures also support the use of the best technology for the service and the database, and promote polyglot code and polyglot persistence.\"],\\n      \"expected_answer\": \"Microservices architectures lead to improved developer productivity, increased agility, better innovation, an increased focus on business needs, support for the best technology for services and databases, and promotion of polyglot code and polyglot persistence.\",\\n      \"query\": \"What are the benefits of microservices architectures?\"\\n    },\\n    {\\n      \"citations\": [\"Traditionally, monolithic applications run in a single process, use one data store, and run on servers that scale vertically. In comparison, modern microservice applications are fine-grained, have independent fault domains, run as services across the network, and can use more than one data store depending on the use case.\"],\\n      \"expected_answer\": \"Monolithic applications traditionally run in a single process, use one data store, and scale vertically, whereas modern microservice applications are fine-grained, have independent fault domains, run as services across the network, and can use multiple data stores.\",\\n      \"query\": \"How do monolithic applications differ from modern microservice applications?\"\\n    },\\n    {\\n      \"citations\": [\"The services scale horizontally, and a single transaction might span multiple databases. Development teams must focus on network communication, polyglot persistence, horizontal scaling, eventual consistency, and transaction handling across the data stores when developing applications by using microservices architectures.\"],\\n      \"expected_answer\": \"When developing applications with microservices architectures, development teams must focus on network communication, polyglot persistence, horizontal scaling, eventual consistency, and transaction handling across data stores.\",\\n      \"query\": \"What key aspects must development teams focus on when using microservices architectures?\"\\n    },\\n    {\\n      \"citations\": [\"Therefore, modernization patterns are critical for solving commonly occurring problems in modern application development, and they help accelerate software delivery.\"],\\n      \"expected_answer\": \"Modernization patterns are critical for solving common problems in modern application development and accelerate software delivery.\",\\n      \"query\": \"What is the importance of modernization patterns?\"\\n    },\\n    {\\n      \"citations\": [\"This guide provides a technical reference for cloud architects, technical leads, application and business owners, and developers who want to choose the right cloud architecture for design patterns based on well-architected best practices.\"],\\n      \"expected_answer\": \"This guide serves as a technical reference for cloud architects, technical leads, application and business owners, and developers to choose appropriate cloud architecture for design patterns based on well-architected best practices.\",\\n      \"query\": \"Who is the target audience for this guide?\"\\n    },\\n    {\\n      \"citations\": [\"The guide covers the following patterns: - Anti-corruption layer - API routing patterns: - Hostname routing - Path routing - HTTP header routing - Circuit breaker - Event sourcing - Hexagonal architecture - Publish-subscribe - Retry with backoff - Saga patterns: - Saga choreography - Saga orchestration - Scatter-gather - Strangler fig - Transactional outbox\"],\\n      \"expected_answer\": \"The guide covers Anti-corruption layer, API routing patterns (Hostname, Path, HTTP header), Circuit breaker, Event sourcing, Hexagonal architecture, Publish-subscribe, Retry with backoff, Saga patterns (Choreography, Orchestration), Scatter-gather, Strangler fig, and Transactional outbox.\",\\n      \"query\": \"List all the design patterns covered in this guide.\"\\n    },\\n    {\\n      \"citations\": [\"Targeted business outcomes\", \"Design and implement reliable, secure, operationally efficient architectures that are optimized for cost and performance.\"],\\n      \"expected_answer\": \"One targeted business outcome is to design and implement reliable, secure, operationally efficient architectures that are optimized for cost and performance.\",\\n      \"query\": \"What is one of the targeted business outcomes of using these patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Targeted business outcomes\", \"Reduce the cycle time for use cases that require these patterns, so you can focus on organization-specific challenges instead.\"],\\n      \"expected_answer\": \"Another targeted business outcome is to reduce the cycle time for use cases requiring these patterns, allowing focus on organization-specific challenges.\",\\n      \"query\": \"How do these patterns help with cycle time?\"\\n    },\\n    {\\n      \"citations\": [\"Targeted business outcomes\", \"Accelerate development by standardizing pattern implementations by using AWS services.\"],\\n      \"expected_answer\": \"The patterns accelerate development by standardizing their implementations using AWS services.\",\\n      \"query\": \"How can development be accelerated using these patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Targeted business outcomes\", \"Help your developers build modern applications without inheriting technical debt.\"],\\n      \"expected_answer\": \"These patterns help developers build modern applications without inheriting technical debt.\",\\n      \"query\": \"What is the benefit for developers when using these patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Intent\", \"The anti-corruption layer (ACL) pattern acts as a mediation layer that translates domain model semantics from one system to another system.\"],\\n      \"expected_answer\": \"The anti-corruption layer (ACL) pattern serves as a mediation layer that translates domain model semantics between different systems.\",\\n      \"query\": \"What is the intent of the Anti-corruption layer (ACL) pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Motivation\", \"During the migration process, when a monolithic application is migrated into microservices, there might be changes in the domain model semantics of the newly migrated service. When the features within the monolith are required to call these microservices, the calls should be routed to the migrated service without requiring any changes to the calling services.\"],\\n      \"expected_answer\": \"The motivation for the ACL pattern arises during migration when a monolithic application is moved to microservices, and changes in domain model semantics of the new service require calls to be routed without altering existing calling services.\",\\n      \"query\": \"What motivates the use of the ACL pattern during migration?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Applicability\", \"Your existing monolithic application has to communicate with a function that has been migrated into a microservice, and the migrated service domain model and semantics differ from the original feature.\"],\\n      \"expected_answer\": \"The ACL pattern is applicable when an existing monolithic application needs to communicate with a microservice that has a different domain model and semantics.\",\\n      \"query\": \"When should the ACL pattern be considered for use?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Issues and considerations\", \"Team dependencies: When different services in a system are owned by different teams, the new domain model semantics in the migrated services can lead to changes in the calling systems. However, teams might not be able to make these changes in a coordinated way, because they might have other priorities. ACL decouples the callees and translates the calls to match the semantics of the new services, thus avoiding the need for callers to make changes in the current system.\"],\\n      \"expected_answer\": \"ACL addresses team dependencies by decoupling callees and translating calls to match new service semantics, preventing the need for callers to make changes in the current system, especially when different teams own different services.\",\\n      \"query\": \"How does ACL address team dependencies?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Issues and considerations\", \"Operational overhead: The ACL pattern requires additional effort to operate and maintain. This work includes integrating ACL with monitoring and alerting tools, the release process, and continuous integration and continuous delivery (CI/CD) processes.\"],\\n      \"expected_answer\": \"The ACL pattern introduces operational overhead due to the additional effort required for its operation and maintenance, including integration with monitoring, alerting, release processes, and CI/CD.\",\\n      \"query\": \"What is a potential operational challenge with the ACL pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Issues and considerations\", \"Single point of failure: Any failures in the ACL can make the target service unreachable, causing application issues. To mitigate this issue, you should build in retry capabilities and circuit breakers. See the retry with backoff and circuit breaker patterns to understand more about these options.\"],\\n      \"expected_answer\": \"ACL can become a single point of failure, making the target service unreachable. This can be mitigated by building in retry capabilities and circuit breakers.\",\\n      \"query\": \"What is a risk associated with ACL and how can it be mitigated?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Issues and considerations\", \"Latency: The additional layer can introduce latency due to the conversion of requests from one interface to another. We recommend that you define and test performance tolerance in applications that are sensitive to response time before you deploy ACL into production environments.\"],\\n      \"expected_answer\": \"The additional layer of ACL can introduce latency due to request conversion. It is recommended to define and test performance tolerance in response-time-sensitive applications before deploying ACL to production.\",\\n      \"query\": \"Does ACL introduce latency, and what is recommended to address it?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Implementation\", \"You can implement ACL inside your monolithic application as a class that\\'s specific to the service that\\'s being migrated, or as an independent service.\"],\\n      \"expected_answer\": \"ACL can be implemented either as a service-specific class within the monolithic application or as an independent service.\",\\n      \"query\": \"How can the ACL be implemented?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Implementation using AWS services\", \"The user microservice is migrated out of the ASP.NET monolithic application and deployed as an AWS Lambda function on AWS. Calls to the Lambda function are routed through Amazon API Gateway. ACL is deployed in the monolith to translate the call to adapt to the semantics of the user microservice.\"],\\n      \"expected_answer\": \"In the AWS implementation, the user microservice is deployed as an AWS Lambda function, with calls routed through Amazon API Gateway. The ACL is deployed within the monolith to translate calls to match the user microservice\\'s semantics.\",\\n      \"query\": \"How is the ACL implemented using AWS services in the example?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"Sample code\", \"The following code snippet provides the changes to the original service and the implementation of UserServiceACL.cs. When a request is received, the original user service calls the ACL. The ACL converts the source object to match the interface of the newly migrated service, calls the service, and returns the response to the caller.\"],\\n      \"expected_answer\": \"The sample code shows how the original user service calls the ACL, which then converts the source object to match the new service\\'s interface, calls the service, and returns the response.\",\\n      \"query\": \"What does the sample code for ACL demonstrate?\"\\n    },\\n    {\\n      \"citations\": [\"Anti-corruption layer pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/anti-corruption-layer-pattern.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Anti-corruption layer pattern is available in the GitHub repository at https://github.com/aws-samples/anti-corruption-layer-pattern.\",\\n      \"query\": \"Where can I find the GitHub repository for the ACL pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"There are three major methods for exposing HTTP APIs to upstream consumers by using hostnames and paths: Hostname routing, Path routing, Header-based routing.\"],\\n      \"expected_answer\": \"The three major methods for exposing HTTP APIs to upstream consumers are Hostname routing, Path routing, and Header-based routing.\",\\n      \"query\": \"What are the three main methods for exposing HTTP APIs?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Hostname routing pattern\", \"Routing by hostname is a mechanism for isolating API services by giving each API its own hostname; for example, service-a.api.example.com or service-a.example.com.\"],\\n      \"expected_answer\": \"Hostname routing isolates API services by assigning a unique hostname to each API, such as service-a.api.example.com.\",\\n      \"query\": \"What is hostname routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Hostname routing pattern\", \"Typical use case\", \"Routing by using hostnames reduces the amount of friction in releases, because nothing is shared between service teams. Teams are responsible for managing everything from DNS entries to service operations in production.\"],\\n      \"expected_answer\": \"A typical use case for hostname routing is to reduce release friction by ensuring nothing is shared between service teams, making them responsible for their own DNS entries and production operations.\",\\n      \"query\": \"What is a typical use case for hostname routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Hostname routing pattern\", \"Pros\", \"Hostname routing is by far the most straightforward and scalable method for HTTP API routing. You can use any relevant AWS service to build an architecture that follows this methodâyou can create an architecture with Amazon API Gateway, AWS AppSync, Application Load Balancers, Amazon Elastic Compute Cloud (Amazon EC2), or any other HTTP-compliant service.\"],\\n      \"expected_answer\": \"Hostname routing is the most straightforward and scalable method for HTTP API routing, compatible with AWS services like Amazon API Gateway, AWS AppSync, Application Load Balancers, and Amazon EC2.\",\\n      \"query\": \"What are the advantages of hostname routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Hostname routing pattern\", \"Cons\", \"When you use hostname routing, your consumers have to remember different hostnames to interact with each API that you expose. You can mitigate this issue by providing a client SDK. However, client SDKs come with their own set of challenges.\"],\\n      \"expected_answer\": \"A disadvantage of hostname routing is that consumers must remember different hostnames for each API, which can be mitigated by providing a client SDK, though SDKs have their own challenges.\",\\n      \"query\": \"What is a disadvantage of hostname routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"Routing by paths is the mechanism of grouping multiple or all APIs under the same hostname, and using a request URI to isolate services; for example, api.example.com/service-a or api.example.com/service-b.\"],\\n      \"expected_answer\": \"Path routing groups multiple or all APIs under the same hostname, using a request URI to isolate services, such as api.example.com/service-a.\",\\n      \"query\": \"What is path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"Typical use case\", \"Most teams opt for this method because they want a simple architectureâa developer has to remember only one URL such as api.example.com to interact with the HTTP API. API documentation is often easier to digest because it is often kept together instead of being split across different portals or PDFs.\"],\\n      \"expected_answer\": \"Path-based routing is typically chosen for its simplicity, as developers only need to remember one URL, and API documentation is easier to manage when kept together.\",\\n      \"query\": \"Why do most teams prefer path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"HTTP service reverse proxy\", \"You can use an HTTP server such as NGINX to create dynamic routing configurations. In a Kubernetes architecture, you can also create an ingress rule to match a path to a service.\"],\\n      \"expected_answer\": \"An HTTP server like NGINX can be used to create dynamic routing configurations for path routing, and in Kubernetes, an ingress rule can match a path to a service.\",\\n      \"query\": \"How can an HTTP service reverse proxy be used for path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"HTTP service reverse proxy\", \"Pros\", \"The ultimate aim of the HTTP service reverse proxy method is to create a scalable and manageable approach to unifying APIs into a single domain so it appears coherent to any API consumer. This approach also enables your service teams to deploy and manage their own APIs, with minimal overhead after deployment.\"],\\n      \"expected_answer\": \"The HTTP service reverse proxy method aims to unify APIs into a single domain for consumers, enabling service teams to deploy and manage their APIs with minimal overhead.\",\\n      \"query\": \"What are the pros of using an HTTP service reverse proxy?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"HTTP service reverse proxy\", \"Cons\", \"The major downside of this approach is the extensive testing and management of infrastructure components that are required, although this might not be an issue if you have site reliability engineering (SRE) teams in place.\"],\\n      \"expected_answer\": \"The main drawback of the HTTP service reverse proxy method is the extensive testing and infrastructure management required, though SRE teams can mitigate this.\",\\n      \"query\": \"What is a major downside of the HTTP service reverse proxy method?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"API Gateway\", \"The Amazon API Gateway service (REST APIs and HTTP APIs) can route traffic in a way that\\'s similar to the HTTP service reverse proxy method. Using an API gateway in HTTP proxy mode provides a simple way to wrap many services into an entry point to the top-level subdomain api.example.com, and then proxy requests to the nested service; for example, billing.internal.api.example.com.\"],\\n      \"expected_answer\": \"Amazon API Gateway can route traffic similarly to an HTTP service reverse proxy, providing a simple way to wrap multiple services into a single entry point and proxy requests to nested services.\",\\n      \"query\": \"How does Amazon API Gateway function in path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"API Gateway\", \"Pros\", \"For control over more complex workflows, such as changing request attributes, REST APIs expose the Apache Velocity Template Language (VTL) to allow you to modify the request and response. REST APIs can provide additional benefits such as these: Auth N/Z with AWS Identity and Access Management (IAM), Amazon Cognito, or AWS Lambda authorizers, AWS X-Ray for tracing, Integration with AWS WAF, Basic rate limiting, Usage tokens for bucketing consumers into different tiers.\"],\\n      \"expected_answer\": \"API Gateway\\'s REST APIs offer control over complex workflows, allowing request/response modification via VTL, and provide benefits like Auth N/Z with IAM/Cognito/Lambda authorizers, AWS X-Ray tracing, AWS WAF integration, basic rate limiting, and usage tokens.\",\\n      \"query\": \"What are the benefits of using API Gateway for path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"API Gateway\", \"Cons\", \"At high volumes, cost might be an issue for some users.\"],\\n      \"expected_answer\": \"At high volumes, the cost of using API Gateway can be a concern for some users.\",\\n      \"query\": \"What is a potential drawback of API Gateway at high volumes?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"CloudFront\", \"You can use the dynamic origin selection feature in Amazon CloudFront to conditionally select an origin (a service) to forward the request. You can use this feature to route a number of services through a single hostname such as api.example.com.\"],\\n      \"expected_answer\": \"Amazon CloudFront\\'s dynamic origin selection feature allows conditional selection of a service to forward requests, enabling routing of multiple services through a single hostname like api.example.com.\",\\n      \"query\": \"How can CloudFront be used for path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"CloudFront\", \"Typical use case\", \"The routing logic lives as code within the Lambda@Edge function, so it supports highly customizable routing mechanisms such as A/B testing, canary releases, feature flagging, and path rewriting.\"],\\n      \"expected_answer\": \"A typical use case for CloudFront in path routing involves using Lambda@Edge functions for routing logic, enabling customizable mechanisms like A/B testing, canary releases, feature flagging, and path rewriting.\",\\n      \"query\": \"What are typical use cases for CloudFront in path routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"CloudFront\", \"Pros\", \"If you require caching API responses, this method is good way to unify a collection of services behind a single endpoint. It is a cost-effective method to unify collections of APIs.\"],\\n      \"expected_answer\": \"CloudFront is a cost-effective method for unifying API collections behind a single endpoint, especially when caching API responses is required.\",\\n      \"query\": \"What are the advantages of using CloudFront for API routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"Path routing pattern\", \"CloudFront\", \"Cons\", \"This method supports a maximum of 250 origins (services) that can be unified. This limit is sufficient for most deployments, but it might cause issues with a large number of APIs as you grow your portfolio of services.\"],\\n      \"expected_answer\": \"A limitation of CloudFront for API routing is its maximum support for 250 origins, which might become an issue for large API portfolios.\",\\n      \"query\": \"What is a limitation of CloudFront for API routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"HTTP header routing pattern\", \"Header-based routing enables you to target the correct service for each request by specifying an HTTP header in the HTTP request. For example, sending the header x-service-a-action: get-thing would enable you to get thing from Service A.\"],\\n      \"expected_answer\": \"Header-based routing targets the correct service for each request by specifying an HTTP header, such as \\'x-service-a-action: get-thing\\' to access Service A.\",\\n      \"query\": \"What is HTTP header routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"HTTP header routing pattern\", \"Pros\", \"Configuration changes require minimal effort and can be automated easily. This method is also flexible and supports creative ways to expose only specific operations you would want from a service.\"],\\n      \"expected_answer\": \"HTTP header routing offers minimal effort for configuration changes, easy automation, flexibility, and supports exposing specific service operations creatively.\",\\n      \"query\": \"What are the pros of HTTP header routing?\"\\n    },\\n    {\\n      \"citations\": [\"API routing patterns\", \"HTTP header routing pattern\", \"Cons\", \"As with the hostname routing method, HTTP header routing assumes that you have full control over the client and can manipulate custom HTTP headers. Proxies, content delivery networks (CDNs), and load balancers can limit the header size.\"],\\n      \"expected_answer\": \"Similar to hostname routing, HTTP header routing requires full client control to manipulate custom HTTP headers, and proxies, CDNs, and load balancers may limit header size.\",\\n      \"query\": \"What are the cons of HTTP header routing?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Intent\", \"The circuit breaker pattern can prevent a caller service from retrying a call to another service (callee) when the call has previously caused repeated timeouts or failures. The pattern is also used to detect when the callee service is functional again.\"],\\n      \"expected_answer\": \"The circuit breaker pattern prevents a caller service from retrying calls to a callee service after repeated timeouts or failures, and it also detects when the callee service becomes functional again.\",\\n      \"query\": \"What is the intent of the Circuit breaker pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Motivation\", \"When multiple microservices collaborate to handle requests, one or more services might become unavailable or exhibit high latency. When complex applications use microservices, an outage in one microservice can lead to application failure.\"],\\n      \"expected_answer\": \"The circuit breaker pattern is motivated by the need to prevent application failures caused by unavailable or high-latency microservices in complex, collaborative microservice architectures.\",\\n      \"query\": \"What is the motivation behind the Circuit breaker pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Applicability\", \"Use this pattern when: The caller service makes a call that is most likely going to fail. A high latency exhibited by the callee service (for example, when database connections are slow) causes timeouts to the callee service. The caller service makes a synchronous call, but the callee service isn\\'t available or exhibits high latency.\"],\\n      \"expected_answer\": \"The circuit breaker pattern is applicable when a caller service makes calls likely to fail, when the callee service exhibits high latency causing timeouts, or when a synchronous call is made to an unavailable or high-latency callee service.\",\\n      \"query\": \"When should the Circuit breaker pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Issues and considerations\", \"Service agnostic implementation: To prevent code bloat, we recommend that you implement the circuit breaker object in a microservice-agnostic and API-driven way.\"],\\n      \"expected_answer\": \"To avoid code bloat, it\\'s recommended to implement the circuit breaker object in a microservice-agnostic and API-driven manner.\",\\n      \"query\": \"What is recommended for implementing the circuit breaker object?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Issues and considerations\", \"Observability: The application should have logging set up to identify the calls that fail when the circuit breaker is open.\"],\\n      \"expected_answer\": \"For observability, the application should have logging configured to identify failed calls when the circuit breaker is open.\",\\n      \"query\": \"What is important for observability in the circuit breaker pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Implementation\", \"High-level architecture\", \"In the following example, the caller is the order service and the callee is the payment service. When there are no failures, the order service routes all calls to the payment service by the circuit breaker.\"],\\n      \"expected_answer\": \"In the high-level architecture example, the order service acts as the caller and the payment service as the callee. When no failures occur, the circuit breaker routes all calls from the order service to the payment service.\",\\n      \"query\": \"Describe the high-level architecture of the Circuit breaker pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Implementation using AWS services\", \"The sample solution uses express workflows in AWS Step Functions to implement the circuit breaker pattern. The Step Functions state machine lets you configure the retry capabilities and decision-based control flow required for the pattern implementation.\"],\\n      \"expected_answer\": \"The sample solution uses AWS Step Functions\\' express workflows to implement the circuit breaker pattern, leveraging its state machine for retry capabilities and decision-based control flow.\",\\n      \"query\": \"How is the Circuit breaker pattern implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"Implementation using AWS services\", \"The solution also uses an Amazon DynamoDB table as the data store to track the circuit status. This can be replaced with an in-memory datastore such as Amazon ElastiCache (Redis OSS) for better performance.\"],\\n      \"expected_answer\": \"The solution uses an Amazon DynamoDB table to track circuit status, but for better performance, it can be replaced with an in-memory datastore like Amazon ElastiCache (Redis OSS).\",\\n      \"query\": \"What data store is used to track circuit status in the AWS implementation, and what alternative is suggested for better performance?\"\\n    },\\n    {\\n      \"citations\": [\"Circuit breaker pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/circuit-breaker-netcore-blog.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Circuit breaker pattern is available in the GitHub repository at https://github.com/aws-samples/circuit-breaker-netcore-blog.\",\\n      \"query\": \"Where can I find the GitHub repository for the Circuit breaker pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Intent\", \"In event-driven architectures, the event sourcing pattern stores the events that result in a state change in a data store. This helps to capture and maintain a complete history of state changes, and promotes auditability, traceability, and the ability to analyze past states.\"],\\n      \"expected_answer\": \"The event sourcing pattern stores events that cause state changes in a data store, capturing a complete history for auditability, traceability, and analysis of past states in event-driven architectures.\",\\n      \"query\": \"What is the intent of the Event sourcing pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Motivation\", \"Multiple microservices can collaborate to handle requests, and they communicate through events. These events can result in a change in state (data). Storing event objects in the order in which they occur provides valuable information on the current state of the data entity and additional information about how it arrived at that state.\"],\\n      \"expected_answer\": \"The motivation for event sourcing is to capture and store event objects in chronological order, providing a complete history of state changes and how the current state was reached, especially in microservice collaborations.\",\\n      \"query\": \"What is the motivation behind the Event sourcing pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Applicability\", \"Use the event sourcing pattern when: An immutable history of the events that occur in an application is required for tracking. Polyglot data projections are required from a single source of truth (SSOT). Point-in time reconstruction of the application state is needed. Long-term storage of application state isn\\'t required, but you might want to reconstruct it as needed. Workloads have different read and write volumes. For example, you have write-intensive workloads that don\\'t require real-time processing. Change data capture (CDC) is required to analyze the application performance and other metrics. Audit data is required for all events that happen in a system for reporting and compliance purposes. You want to derive what-if scenarios by changing (inserting, updating, or deleting) events during the replay process to determine the possible end state.\"],\\n      \"expected_answer\": \"The event sourcing pattern is applicable when an immutable event history is needed, polyglot data projections from a single source of truth are required, point-in-time state reconstruction is necessary, long-term state storage isn\\'t a primary need but reconstruction is, workloads have varying read/write volumes (e.g., write-intensive without real-time processing), change data capture is needed for performance analysis, audit data is required for reporting/compliance, or when deriving what-if scenarios by replaying events.\",\\n      \"query\": \"When should the Event sourcing pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Issues and considerations\", \"Optimistic concurrency control: This pattern stores every event that causes a state change in the system. Multiple users or services can try to update the same piece of data at the same time, causing event collisions. To solve this issue, you can implement strategies to detect and resolve event collisions.\"],\\n      \"expected_answer\": \"Event sourcing faces optimistic concurrency control issues when multiple users/services update the same data simultaneously, leading to event collisions. Strategies to detect and resolve these collisions should be implemented.\",\\n      \"query\": \"What is a key issue with optimistic concurrency control in event sourcing?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Issues and considerations\", \"Complexity: Implementing event sourcing necessitates a shift in mindset from traditional CRUD operations to event-driven thinking. The replay process, which is used to restore the system to its original state, can be complex in order to ensure data idempotency. Event storage, backups, and snapshots can also add additional complexity.\"],\\n      \"expected_answer\": \"Implementing event sourcing is complex due to the shift to event-driven thinking, the intricate replay process for data idempotency, and the added complexity of event storage, backups, and snapshots.\",\\n      \"query\": \"What adds to the complexity of implementing event sourcing?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Issues and considerations\", \"Eventual consistency: Data projections derived from the events are eventually consistent because of the latency in updating data by using the command query responsibility segregation (CQRS) pattern or materialized views.\"],\\n      \"expected_answer\": \"Data projections from events in event sourcing are eventually consistent due to latency in updating data via CQRS or materialized views.\",\\n      \"query\": \"Why is eventual consistency a consideration in event sourcing?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Implementation\", \"High-level architecture\", \"Events are logged into an immutable, append-only, chronologically ordered repository or data store known as the event store. Each state change is treated as an individual event object.\"],\\n      \"expected_answer\": \"In event sourcing, events are logged into an immutable, append-only, chronologically ordered event store, where each state change is an individual event object.\",\\n      \"query\": \"How are events stored in the Event sourcing pattern\\'s high-level architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Implementation using AWS services\", \"In the following architecture, Amazon Kinesis Data Streams is used as the event store. This service captures and manages application changes as events, and offers a high-throughput and real-time data streaming solution.\"],\\n      \"expected_answer\": \"In the provided architecture, Amazon Kinesis Data Streams is used as the event store, offering a high-throughput, real-time data streaming solution for capturing and managing application changes as events.\",\\n      \"query\": \"Which AWS service is used as the event store in the example architecture for event sourcing?\"\\n    },\\n    {\\n      \"citations\": [\"Event sourcing pattern\", \"Implementation using AWS services\", \"To implement the event sourcing pattern on AWS, you can also use services such as Amazon EventBridge and Amazon Managed Streaming for Apache Kafka (Amazon MSK) based on your application\\'s needs.\"],\\n      \"expected_answer\": \"Besides Amazon Kinesis Data Streams, Amazon EventBridge and Amazon Managed Streaming for Apache Kafka (Amazon MSK) can also be used to implement the event sourcing pattern on AWS, depending on application needs.\",\\n      \"query\": \"What other AWS services can be used for event sourcing besides Kinesis Data Streams?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Intent\", \"The hexagonal architecture pattern, which is also known as the ports and adapters pattern, was proposed by Dr. Alistair Cockburn in 2005. It aims to create loosely coupled architectures where application components can be tested independently, with no dependencies on data stores or user interfaces (UIs).\"],\\n      \"expected_answer\": \"The hexagonal architecture pattern, also known as the ports and adapters pattern, was proposed by Dr. Alistair Cockburn in 2005. Its intent is to create loosely coupled architectures, enabling independent testing of application components without dependencies on data stores or UIs.\",\\n      \"query\": \"What is the intent of the Hexagonal architecture pattern and who proposed it?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Motivation\", \"The hexagonal architecture pattern is used to isolate business logic (domain logic) from related infrastructure code, such as code to access a database or external APIs. This pattern is useful for creating loosely coupled business logic and infrastructure code for AWS Lambda functions that require integration with external services.\"],\\n      \"expected_answer\": \"The hexagonal architecture pattern is motivated by the need to isolate business logic from infrastructure code, particularly for AWS Lambda functions integrating with external services, to create loosely coupled components.\",\\n      \"query\": \"What is the motivation behind the Hexagonal architecture pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Applicability\", \"Use the hexagonal architecture pattern when: You want to decouple your application architecture to create components that can be fully tested. Multiple types of clients can use the same domain logic. Your UI and database components require periodical technology refreshes that don\\'t affect application logic. Your application requires multiple input providers and output consumers, and customizing the application logic leads to code complexity and lack of extensibility.\"],\\n      \"expected_answer\": \"The hexagonal architecture pattern is applicable when decoupling application architecture for testability, when multiple client types use the same domain logic, when UI/database components need technology refreshes without affecting application logic, or when an application requires multiple input/output providers and consumers, where custom logic leads to complexity.\",\\n      \"query\": \"When should the Hexagonal architecture pattern be applied?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Issues and considerations\", \"Testability: By design, a hexagonal architecture uses abstractions for inputs and outputs. Therefore, writing unit tests and testing in isolation become easier because of the inherent loose coupling.\"],\\n      \"expected_answer\": \"Hexagonal architecture enhances testability by using abstractions for inputs and outputs, which facilitates easier unit testing and isolated testing due to its inherent loose coupling.\",\\n      \"query\": \"How does hexagonal architecture improve testability?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Implementation\", \"Ports are technology-agnostic entry points into an application component. These custom interfaces determine the interface that allows external actors to communicate with the application component, regardless of who or what implements the interface.\"],\\n      \"expected_answer\": \"Ports in hexagonal architecture are technology-agnostic entry points into an application component, defining custom interfaces for external actors to communicate with the component.\",\\n      \"query\": \"What are ports in hexagonal architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Implementation\", \"Adapters interact with the application through a port by using a specific technology. Adapters plug into these ports, receive data from or provide data to the ports, and transform the data for further processing.\"],\\n      \"expected_answer\": \"Adapters in hexagonal architecture interact with the application through a port using specific technology, plugging into ports to receive or provide data and transform it for processing.\",\\n      \"query\": \"What are adapters in hexagonal architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Implementation using AWS services\", \"AWS Lambda functions often contain both business logic and database integration code, which are tightly coupled to meet an objective. You can use the hexagonal architecture pattern to separate business logic from infrastructure code.\"],\\n      \"expected_answer\": \"The hexagonal architecture pattern can be used with AWS Lambda functions to separate business logic from infrastructure code, addressing the common tight coupling between them.\",\\n      \"query\": \"How can hexagonal architecture be applied to AWS Lambda functions?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"Sample code\", \"The sample code in this section shows how to implement the domain model by using Lambda, separate it from infrastructure code (such as the code to access DynamoDB), and implement unit testing for the function.\"],\\n      \"expected_answer\": \"The sample code demonstrates implementing a domain model with Lambda, separating it from infrastructure code like DynamoDB access, and unit testing the function.\",\\n      \"query\": \"What does the sample code for hexagonal architecture illustrate?\"\\n    },\\n    {\\n      \"citations\": [\"Hexagonal architecture pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/aws-lambda-domain-model-sample.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Hexagonal architecture pattern is available in the GitHub repository at https://github.com/aws-samples/aws-lambda-domain-model-sample.\",\\n      \"query\": \"Where can I find the GitHub repository for the Hexagonal architecture pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Intent\", \"The publish-subscribe pattern, which is also known as the pub-sub pattern, is a messaging pattern that decouples a message sender (publisher) from interested receivers (subscribers). This pattern implements asynchronous communications by publishing messages or events through an intermediary known as a message broker or router (message infrastructure).\"],\\n      \"expected_answer\": \"The publish-subscribe (pub-sub) pattern is a messaging pattern that decouples publishers from subscribers, enabling asynchronous communication through a message broker or router.\",\\n      \"query\": \"What is the intent of the Publish-subscribe pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Motivation\", \"In distributed architectures, system components often need to provide information to other components as events take place within the system. The publish-subscribe pattern separates concerns so that applications can focus on their core capabilities while the message infrastructure handles communication responsibilities such as message routing and reliable delivery.\"],\\n      \"expected_answer\": \"The publish-subscribe pattern is motivated by the need to separate concerns in distributed architectures, allowing applications to focus on core capabilities while the message infrastructure handles communication responsibilities like routing and reliable delivery.\",\\n      \"query\": \"What is the motivation behind the Publish-subscribe pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Applicability\", \"Use the publish-subscribe pattern when: Parallel processing is required if a single message has different workflows. Broadcasting messages to multiple subscribers and real-time responses from receivers aren\\'t required. The system or application can tolerate eventual consistency for data or state. The application or component has to communicate with other applications or services that might use different languages, protocols, or platforms.\"],\\n      \"expected_answer\": \"The publish-subscribe pattern is applicable when parallel processing of a single message with different workflows is needed, broadcasting messages to multiple subscribers without real-time responses is acceptable, the system tolerates eventual consistency, or when an application needs to communicate with services using different languages, protocols, or platforms.\",\\n      \"query\": \"When should the Publish-subscribe pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Issues and considerations\", \"Subscriber availability: The publisher isn\\'t aware whether the subscribers are listening, and they might not be. Published messages are transient in nature and can result in being dropped if the subscribers aren\\'t available.\"],\\n      \"expected_answer\": \"A consideration for the publish-subscribe pattern is subscriber availability; publishers are unaware if subscribers are listening, and transient messages can be dropped if subscribers are unavailable.\",\\n      \"query\": \"What is a key issue regarding subscriber availability in pub-sub?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Implementation\", \"High-level architecture\", \"In a publish-subscribe pattern, the asynchronous messaging subsystem known as a message broker or router keeps track of subscriptions. When a producer publishes an event, the messaging infrastructure sends a message to each consumer.\"],\\n      \"expected_answer\": \"In the publish-subscribe pattern, a message broker or router manages subscriptions, and when a producer publishes an event, the messaging infrastructure sends a message to each consumer.\",\\n      \"query\": \"How does the high-level architecture of the Publish-subscribe pattern work?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Implementation using AWS services\", \"Amazon SNS is a fully managed publisher-subscriber service that provides application-to-application (A2A) messaging to decouple distributed applications. It also provides application-to-person (A2P) messaging for sending SMS, email, and other push notifications.\"],\\n      \"expected_answer\": \"Amazon SNS is a fully managed publisher-subscriber service that offers A2A messaging for decoupling distributed applications and A2P messaging for sending SMS, email, and push notifications.\",\\n      \"query\": \"What is Amazon SNS and what does it provide?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Implementation using AWS services\", \"Amazon SNS provides two types of topics: standard and first in, first out (FIFO).\"],\\n      \"expected_answer\": \"Amazon SNS provides two types of topics: standard and First-In, First-Out (FIFO).\",\\n      \"query\": \"What are the two types of topics provided by Amazon SNS?\"\\n    },\\n    {\\n      \"citations\": [\"Publish-subscribe pattern\", \"Implementation using AWS services\", \"You can use Amazon EventBridge when you need more complex routing of messages from multiple producers across different protocols to subscribed consumers, or direct and fan-out subscriptions. EventBridge also supports content-based routing, filtering, sequencing, and splitting or aggregation.\"],\\n      \"expected_answer\": \"Amazon EventBridge is suitable for complex message routing from multiple producers across different protocols to subscribed consumers, supporting direct and fan-out subscriptions, content-based routing, filtering, sequencing, and splitting/aggregation.\",\\n      \"query\": \"When should Amazon EventBridge be used for publish-subscribe?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Intent\", \"The retry with backoff pattern improves application stability by transparently retrying operations that fail due to transient errors.\"],\\n      \"expected_answer\": \"The retry with backoff pattern aims to improve application stability by transparently retrying operations that fail due to transient errors.\",\\n      \"query\": \"What is the intent of the Retry with backoff pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Motivation\", \"In distributed architectures, transient errors might be caused by service throttling, temporary loss of network connectivity, or temporary service unavailability. Automatically retrying operations that fail because of these transient errors improves the user experience and application resilience.\"],\\n      \"expected_answer\": \"The motivation for the retry with backoff pattern is to improve user experience and application resilience by automatically retrying operations that fail due to transient errors like service throttling, temporary network loss, or service unavailability in distributed architectures.\",\\n      \"query\": \"What motivates the use of the Retry with backoff pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Applicability\", \"Use the retry with backoff pattern when: Your services frequently throttle the request to prevent overload, resulting in a 429 Too many requests exception to the calling process. The network is an unseen participant in distributed architectures, and temporary network issues result in failures. The service being called is temporarily unavailable, causing failures. Frequent retries might cause service degradation unless you introduce a backoff timeout by using this pattern.\"],\\n      \"expected_answer\": \"The retry with backoff pattern is applicable when services frequently throttle requests (429 errors), temporary network issues cause failures, or the called service is temporarily unavailable, to prevent service degradation from frequent retries.\",\\n      \"query\": \"When should the Retry with backoff pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Issues and considerations\", \"Idempotency: If multiple calls to the method have the same effect as a single call on the system state, the operation is considered idempotent. Operations should be idempotent when you use the retry with backoff pattern. Otherwise, partial updates might corrupt the system state.\"],\\n      \"expected_answer\": \"When using the retry with backoff pattern, operations should be idempotent to prevent partial updates from corrupting the system state if multiple calls have the same effect as a single call.\",\\n      \"query\": \"Why is idempotency important for the Retry with backoff pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Implementation\", \"High-level architecture\", \"The following diagram illustrates how Service A can retry the calls to Service B until a successful response is returned. If Service B doesn\\'t return a successful response after a few tries, Service A can stop retrying and return a failure to its caller.\"],\\n      \"expected_answer\": \"The high-level architecture shows Service A retrying calls to Service B until a successful response is received. If Service B fails to respond successfully after several attempts, Service A stops retrying and returns a failure.\",\\n      \"query\": \"Describe the high-level architecture of the Retry with backoff pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Implementation using AWS services\", \"The sample solution uses express workflows in AWS Step Functions to implement the circuit breaker pattern. The Step Functions state machine lets you configure the retry capabilities and decision-based control flow required for the pattern implementation.\"],\\n      \"expected_answer\": \"The sample solution uses AWS Step Functions\\' express workflows to implement the circuit breaker pattern, leveraging its state machine for retry capabilities and decision-based control flow.\",\\n      \"query\": \"How is the Retry with backoff pattern implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"Implementation using AWS services\", \"In this example, a maximum of three retries are configured with an increase multiplier of 1.5 seconds. If the first retry occurs after 3 seconds, the second retry occurs after 3 x 1.5 seconds = 4.5 seconds, and the third retry occurs after 4.5 x 1.5 seconds = 6.75 seconds. If the third retry is unsuccessful, the workflow fails. The backoff logic doesn\\'t require any custom codeâit\\'s provided as a configuration by AWS Step Functions.\"],\\n      \"expected_answer\": \"In the example, a maximum of three retries are configured with a 1.5-second increase multiplier. The first retry is after 3 seconds, the second after 4.5 seconds, and the third after 6.75 seconds. If the third fails, the workflow fails. AWS Step Functions provides the backoff logic as a configuration.\",\\n      \"query\": \"Explain the retry logic configuration in the AWS Step Functions example for retry with backoff.\"\\n    },\\n    {\\n      \"citations\": [\"Retry with backoff pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/retry-with-backoff.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Retry with backoff pattern is available in the GitHub repository at https://github.com/aws-samples/retry-with-backoff.\",\\n      \"query\": \"Where can I find the GitHub repository for the Retry with backoff pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Saga patterns\", \"A saga consists of a sequence of local transactions. Each local transaction in a saga updates the database and triggers the next local transaction. If a transaction fails, the saga runs compensating transactions to revert the database changes made by the previous transactions.\"],\\n      \"expected_answer\": \"A saga is a sequence of local transactions where each updates the database and triggers the next. If a transaction fails, compensating transactions are run to revert previous database changes.\",\\n      \"query\": \"What is a saga in the context of design patterns?\"\\n    },\\n    {\\n      \"citations\": [\"Saga patterns\", \"This sequence of local transactions helps achieve a business workflow by using continuation and compensation principles. The continuation principle decides the forward recovery of the workflow, whereas the compensation principle decides the backward recovery.\"],\\n      \"expected_answer\": \"Sagas achieve business workflows using continuation for forward recovery and compensation for backward recovery, ensuring data integrity.\",\\n      \"query\": \"What principles do sagas use to achieve business workflows?\"\\n    },\\n    {\\n      \"citations\": [\"Saga patterns\", \"The saga pattern has two variants: choreography and orchestration.\"],\\n      \"expected_answer\": \"The two variants of the saga pattern are choreography and orchestration.\",\\n      \"query\": \"What are the two variants of the saga pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography\", \"The saga choreography pattern depends on the events published by the microservices. The saga participants (microservices) subscribe to the events and act based on the event triggers.\"],\\n      \"expected_answer\": \"The saga choreography pattern relies on events published by microservices, where participants subscribe to and act upon these event triggers.\",\\n      \"query\": \"How does the saga choreography pattern work?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography\", \"The saga choreography pattern is suitable when there are only a few participants in the saga, and you need a simple implementation with no single point of failure. When more participants are added, it becomes harder to track the dependencies between the participants by using this pattern.\"],\\n      \"expected_answer\": \"Saga choreography is suitable for sagas with few participants and simple implementations without a single point of failure. However, tracking dependencies becomes difficult with more participants.\",\\n      \"query\": \"When is the saga choreography pattern suitable?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration\", \"The saga orchestration pattern has a central coordinator called an orchestrator. The saga orchestrator manages and coordinates the entire transaction lifecycle.\"],\\n      \"expected_answer\": \"The saga orchestration pattern uses a central coordinator, an orchestrator, to manage and coordinate the entire transaction lifecycle.\",\\n      \"query\": \"What is the role of an orchestrator in the saga orchestration pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration\", \"The saga orchestration pattern is suitable when there are many participants, and loose coupling is required between saga participants. The orchestrator encapsulates the complexity in the logic by making the participants loosely coupled. However, the orchestrator can become a single point of failure because it controls the entire workflow.\"],\\n      \"expected_answer\": \"Saga orchestration is suitable for many participants requiring loose coupling, as the orchestrator encapsulates complexity. However, it can become a single point of failure.\",\\n      \"query\": \"When is the saga orchestration pattern suitable?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Intent\", \"The saga choreography pattern helps preserve data integrity in distributed transactions that span multiple services by using event subscriptions.\"],\\n      \"expected_answer\": \"The saga choreography pattern aims to preserve data integrity in distributed transactions across multiple services through event subscriptions.\",\\n      \"query\": \"What is the intent of the Saga choreography pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Motivation\", \"In distributed systems that follow a database-per-service design pattern, the two-phase commit is not an option. This is because each transaction is distributed across various databases, and there is no single controller that can coordinate a process that\\'s similar to the two-phase commit in relational data stores. In this case, one solution is to use the saga choreography pattern.\"],\\n      \"expected_answer\": \"The saga choreography pattern is motivated by the inability to use two-phase commit in distributed systems with a database-per-service design, where transactions span multiple databases without a single coordinator.\",\\n      \"query\": \"What motivates the use of the Saga choreography pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Applicability\", \"Use the saga choreography pattern when: Your system requires data integrity and consistency in distributed transactions that span multiple data stores. The data store (for example, a NoSQL database) doesn\\'t provide 2PC to provide ACID transactions, you need to update multiple tables within a single transaction, and implementing 2PC within the application boundaries would be a complex task. A central controlling process that manages the participant transactions might become a single point of failure. The saga participants are independent services and need to be loosely coupled. There is communication between bounded contexts in a business domain.\"],\\n      \"expected_answer\": \"The saga choreography pattern is applicable when distributed transactions across multiple data stores require data integrity and consistency, when a data store lacks 2PC for ACID transactions and implementing it is complex, when a central controller is a single point of failure, when saga participants need to be independent and loosely coupled, or when communication between bounded contexts in a business domain is present.\",\\n      \"query\": \"When should the Saga choreography pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Issues and considerations\", \"Complexity: As the number of microservices increases, saga choreography can become difficult to manage because of the number of interactions between the microservices. Additionally, compensatory transactions and retries add complexities to the application code, which can result in maintenance overhead.\"],\\n      \"expected_answer\": \"Saga choreography becomes complex and incurs maintenance overhead as the number of microservices increases due to numerous interactions, compensatory transactions, and retries.\",\\n      \"query\": \"What is a complexity issue with saga choreography?\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Implementation\", \"High-level architecture\", \"In the following architecture diagram, the saga choreography has three participants: the order service, the inventory service, and the payment service. Three steps are required to complete the transaction: T1, T2, and T3. Three compensatory transactions restore the data to the initial state: C1, C2, and C3.\"],\\n      \"expected_answer\": \"In the high-level architecture, saga choreography involves three participants (order, inventory, payment services) and three transaction steps (T1, T2, T3), with three compensatory transactions (C1, C2, C3) to restore data on failure.\",\\n      \"query\": \"Describe the high-level architecture of the Saga choreography pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Saga choreography pattern\", \"Implementation using AWS services\", \"You can implement the saga choreography pattern by using Amazon EventBridge. EventBridge uses events to connect application components. It processes events through event buses or pipes.\"],\\n      \"expected_answer\": \"The saga choreography pattern can be implemented using Amazon EventBridge, which connects application components through events processed via event buses or pipes.\",\\n      \"query\": \"How can the Saga choreography pattern be implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Intent\", \"The saga orchestration pattern uses a central coordinator (orchestrator) to help preserve data integrity in distributed transactions that span multiple services.\"],\\n      \"expected_answer\": \"The saga orchestration pattern uses a central coordinator (orchestrator) to maintain data integrity in distributed transactions across multiple services.\",\\n      \"query\": \"What is the intent of the Saga orchestration pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Motivation\", \"In distributed systems that follow a database-per-service design pattern, the two-phase commit is not an option. This is because each transaction is distributed across various databases, and there is no single controller that can coordinate a process that\\'s similar to the two-phase commit in relational data stores. In this case, one solution is to use the saga orchestration pattern.\"],\\n      \"expected_answer\": \"The saga orchestration pattern is motivated by the inability to use two-phase commit in distributed systems with a database-per-service design, where transactions span multiple databases without a single coordinator.\",\\n      \"query\": \"What motivates the use of the Saga orchestration pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Applicability\", \"Use the saga orchestration pattern when: Your system requires data integrity and consistency in distributed transactions that span multiple data stores. The data store doesn\\'t provide 2PC to provide ACID transactions, and implementing 2PC within the application boundaries is a complex task. You have NoSQL databases, which do not provide ACID transactions, and you need to update multiple tables within a single transaction.\"],\\n      \"expected_answer\": \"The saga orchestration pattern is applicable when distributed transactions across multiple data stores require data integrity and consistency, when the data store lacks 2PC for ACID transactions and implementing it is complex, or when NoSQL databases are used and multiple tables need updating within a single transaction.\",\\n      \"query\": \"When should the Saga orchestration pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Issues and considerations\", \"Single point of failure: The orchestrator can become a single point of failure because it coordinates the entire transaction. In some cases, the saga choreography pattern is preferred because of this issue.\"],\\n      \"expected_answer\": \"A key issue with the saga orchestration pattern is that the orchestrator can become a single point of failure, leading to a preference for saga choreography in some cases.\",\\n      \"query\": \"What is a significant issue with the saga orchestration pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Implementation\", \"High-level architecture\", \"In the following architecture diagram, the saga orchestrator has three participants: the order service, the inventory service, and the payment service. Three steps are required to complete the transaction: T1, T2, and T3. The saga orchestrator is aware of the steps and runs them in the required order. When step T3 fails (payment failure), the orchestrator runs the compensatory transactions C1 and C2 to restore the data to the initial state.\"],\\n      \"expected_answer\": \"In the high-level architecture, the saga orchestrator coordinates three participants (order, inventory, payment services) through steps T1, T2, T3. If T3 fails, the orchestrator executes compensatory transactions C1 and C2 to restore the initial data state.\",\\n      \"query\": \"Describe the high-level architecture of the Saga orchestration pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Implementation using AWS services\", \"The sample solution uses the standard workflow in Step Functions to implement the saga orchestration pattern.\"],\\n      \"expected_answer\": \"The sample solution implements the saga orchestration pattern using the standard workflow in AWS Step Functions.\",\\n      \"query\": \"How is the Saga orchestration pattern implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"Implementation using AWS services\", \"The use of Step Functions mitigates the single point of failure issue, which is inherent in the implementation of the saga orchestration pattern. Step Functions has built-in fault tolerance and maintains service capacity across multiple Availability Zones in each AWS Region to protect applications against individual machine or data center failures.\"],\\n      \"expected_answer\": \"Using AWS Step Functions mitigates the single point of failure in saga orchestration due to its built-in fault tolerance and Multi-AZ service capacity, protecting applications from machine or data center failures.\",\\n      \"query\": \"How does AWS Step Functions mitigate the single point of failure in saga orchestration?\"\\n    },\\n    {\\n      \"citations\": [\"Saga orchestration pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/saga-orchestration-netcore-blog.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Saga orchestration pattern is available in the GitHub repository at https://github.com/aws-samples/saga-orchestration-netcore-blog.\",\\n      \"query\": \"Where can I find the GitHub repository for the Saga orchestration pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Intent\", \"The scatter-gather pattern is a message routing pattern that involves broadcasting similar or related requests to multiple recipients, and aggregating their responses back into a single message by using a component called an aggregator.\"],\\n      \"expected_answer\": \"The scatter-gather pattern is a message routing pattern that broadcasts requests to multiple recipients and aggregates their responses into a single message using an aggregator.\",\\n      \"query\": \"What is the intent of the Scatter-gather pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Motivation\", \"In application processing, a request that might take a long time to process sequentially can be split into multiple requests that are processed in parallel. You can also send requests to multiple external systems through API calls to get a response. The scatter-gather pattern is useful when you need input from multiple sources.\"],\\n      \"expected_answer\": \"The scatter-gather pattern is motivated by the need to parallelize long sequential requests or gather input from multiple external sources via API calls, reducing processing time.\",\\n      \"query\": \"What is the motivation behind the Scatter-gather pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Applicability\", \"Use the scatter-gather pattern when: You plan to aggregate and consolidate data from various APIs to create an accurate response. The same request has to be sent to multiple recipients simultaneously to complete a transaction. You want to implement a reliable and scalable system where load balancing can be achieved by distributing requests across multiple recipients. You want to optimize performance when implementing complex queries that involve multiple data sources. You are implementing a type of map-reduce processing where the data request is routed to multiple data processing endpoints for sharding and replication. You want to distribute write operations across a partition key space in write-heavy workloads in key-value databases.\"],\\n      \"expected_answer\": \"The scatter-gather pattern is applicable when aggregating data from various APIs, sending the same request to multiple recipients simultaneously, implementing a reliable and scalable system with load balancing, optimizing complex queries across multiple data sources, performing map-reduce processing with sharding/replication, or distributing write operations in write-heavy key-value databases.\",\\n      \"query\": \"When should the Scatter-gather pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Issues and considerations\", \"Fault tolerance: This pattern relies on multiple recipients that work in parallel, so it is essential to handle failures gracefully. To mitigate the impact of recipient failures on the overall system, you can implement strategies such as redundancy, replication, and fault detection.\"],\\n      \"expected_answer\": \"Fault tolerance is a key consideration for the scatter-gather pattern, requiring graceful handling of recipient failures through strategies like redundancy, replication, and fault detection to mitigate system impact.\",\\n      \"query\": \"What is a key consideration for fault tolerance in scatter-gather?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Implementation\", \"High-level architecture\", \"The scatter-gather pattern uses a root controller to distribute requests to recipients that will process the requests. During the scatter phase, this pattern can use two mechanisms to send messages to recipients: Scatter by distribution and Scatter by auction.\"],\\n      \"expected_answer\": \"The scatter-gather pattern\\'s high-level architecture uses a root controller to distribute requests to recipients. During the scatter phase, it employs two mechanisms: scatter by distribution or scatter by auction.\",\\n      \"query\": \"Describe the high-level architecture of the Scatter-gather pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Implementation\", \"High-level architecture\", \"Scatter by distribution: In the scatter by distribution method, the root controller divides the incoming request into independent tasks and assigns them to available recipients (the scatter phase). Each recipient (process, container, or Lambda function) works independently and in parallel on its computation, and produces a portion of the response. When the recipients complete their tasks, they send their responses to an aggregator (the gather phase).\"],\\n      \"expected_answer\": \"In scatter by distribution, the root controller divides requests into independent tasks for parallel processing by recipients (e.g., processes, containers, Lambda functions). Each recipient computes a portion of the response, which is then sent to an aggregator for the gather phase.\",\\n      \"query\": \"Explain the \\'Scatter by distribution\\' method.\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Implementation\", \"High-level architecture\", \"Scatter by auction: If the controller isn\\'t aware of the recipients or the recipients are loosely coupled, you can use the scatter by auction method. In this method, the recipients subscribe to a topic and the controller publishes the request to the topic. Recipients publish the results to a response queue.\"],\\n      \"expected_answer\": \"The \\'Scatter by auction\\' method is used when the controller is unaware of recipients or they are loosely coupled. Recipients subscribe to a topic where the controller publishes requests, and then they publish their results to a response queue.\",\\n      \"query\": \"Explain the \\'Scatter by auction\\' method.\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Implementation using AWS services\", \"Scatter by distribution\", \"In the following architecture, the root controller is a data file processor (Amazon ECS) that splits the incoming request data into individual Amazon Simple Storage Service (Amazon S3) buckets and starts an AWS Step Functions workflow. The workflow downloads the data and initiates parallel file processing. The Parallel state waits for all the tasks to return a response. An AWS Lambda function aggregates the data and saves it back to Amazon S3.\"],\\n      \"expected_answer\": \"In the AWS implementation of scatter by distribution, an Amazon ECS data file processor acts as the root controller, splitting request data into S3 buckets and initiating an AWS Step Functions workflow for parallel file processing. A Lambda function then aggregates the data and saves it back to S3.\",\\n      \"query\": \"How is \\'Scatter by distribution\\' implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"Implementation using AWS services\", \"Scatter by auction\", \"The following diagram shows an AWS architecture for the scatter by auction method. The root controller flight booking service scatters the flight search request to multiple microservices. A publish-subscribe channel is implemented with Amazon Simple Notification Service (Amazon SNS), which is a managed messaging service for communications.\"],\\n      \"expected_answer\": \"The AWS architecture for scatter by auction uses a flight booking service as the root controller to scatter flight search requests to microservices via an Amazon SNS publish-subscribe channel.\",\\n      \"query\": \"How is \\'Scatter by auction\\' implemented using AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Scatter-gather pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/asynchronous-messaging-workshop/tree/master/code/lab-3.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Scatter-gather pattern is available in the GitHub repository at https://github.com/aws-samples/asynchronous-messaging-workshop/tree/master/code/lab-3.\",\\n      \"query\": \"Where can I find the GitHub repository for the Scatter-gather pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Intent\", \"The strangler fig pattern helps migrate a monolithic application to a microservices architecture incrementally, with reduced transformation risk and business disruption.\"],\\n      \"expected_answer\": \"The strangler fig pattern aims to incrementally migrate monolithic applications to a microservices architecture, reducing transformation risk and business disruption.\",\\n      \"query\": \"What is the intent of the Strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Motivation\", \"Monolithic applications are developed to provide most of their functionality within a single process or container. The code is tightly coupled. As a result, application changes require thorough retesting to avoid regression issues. The changes cannot be tested in isolation, which impacts the cycle time.\"],\\n      \"expected_answer\": \"The strangler fig pattern is motivated by the challenges of monolithic applications, such as tightly coupled code, extensive retesting for changes, and difficulty in isolated testing, all of which impact cycle time.\",\\n      \"query\": \"What motivates the use of the Strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Applicability\", \"Use the strangler fig pattern when: You want to migrate your monolithic application gradually to a microservices architecture. A big bang migration approach is risky because of the size and complexity of the monolith. The business wants to add new features and cannot wait for the transformation to be complete. End users must be minimally impacted during the transformation.\"],\\n      \"expected_answer\": \"The strangler fig pattern is applicable when gradually migrating a monolithic application to microservices, when a big bang migration is too risky due to monolith size/complexity, when new features are needed before transformation completion, or when minimizing end-user impact during transformation is crucial.\",\\n      \"query\": \"When should the Strangler fig pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Issues and considerations\", \"Code base access: To implement the strangler fig pattern, you must have access to the monolith application\\'s code base. As features are migrated out of the monolith, you will need to make minor code changes and implement an anti-corruption layer within the monolith to route calls to new microservices.\"],\\n      \"expected_answer\": \"Implementing the strangler fig pattern requires access to the monolith\\'s code base to make minor changes and implement an anti-corruption layer for routing calls to new microservices as features are migrated.\",\\n      \"query\": \"Why is code base access important for the strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Issues and considerations\", \"Anti-corruption layer: During the migration process, when the features within the monolith have to call the features that were migrated as microservices, you should implement an anti-corruption layer (ACL) that routes each call to the appropriate microservice.\"],\\n      \"expected_answer\": \"During migration with the strangler fig pattern, an anti-corruption layer (ACL) should be implemented within the monolith to route calls from existing features to newly migrated microservices.\",\\n      \"query\": \"What is the role of an Anti-corruption layer in the strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Implementation\", \"In the strangler fig pattern, you replace specific functionality with a new service or application, one component at a time. A proxy layer intercepts requests that go to the monolithic application and routes them to either the legacy system or the new system.\"],\\n      \"expected_answer\": \"In the strangler fig pattern, specific functionality is replaced incrementally with new services, and a proxy layer intercepts and routes requests to either the legacy or new system.\",\\n      \"query\": \"How is the Strangler fig pattern implemented?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Implementation\", \"High-level architecture\", \"The first step is to add a proxy layer between the storefront UI and the monolithic application. At the start, the proxy routes all traffic to the monolithic application.\"],\\n      \"expected_answer\": \"The first step in the high-level architecture of the strangler fig pattern is to introduce a proxy layer between the storefront UI and the monolithic application, initially routing all traffic to the monolith.\",\\n      \"query\": \"What is the initial step in the high-level architecture of the Strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Implementation\", \"Handling data synchronization\", \"As a best practice, the microservice should own its data. The user service stores its data in its own data store. It might need to synchronize data with the monolithic database to handle dependencies such as reporting and to support downstream applications that are not yet ready to access the microservices directly.\"],\\n      \"expected_answer\": \"In the strangler fig pattern, microservices should own their data, but data synchronization with the monolithic database might be necessary for reporting and supporting downstream applications not yet migrated.\",\\n      \"query\": \"How is data synchronization handled in the strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Implementation using AWS services\", \"Using API Gateway as the application proxy\", \"In the following architecture, AWS Migration Hub Refactor Spaces deploys Amazon API Gateway in front of the monolithic application. Refactor Spaces creates a refactoring infrastructure inside your account, and API Gateway acts as the proxy layer for routing calls to the monolith.\"],\\n      \"expected_answer\": \"In the AWS implementation, AWS Migration Hub Refactor Spaces deploys Amazon API Gateway as the proxy layer in front of the monolithic application, routing calls to the monolith.\",\\n      \"query\": \"How is API Gateway used as an application proxy in the Strangler fig pattern with AWS services?\"\\n    },\\n    {\\n      \"citations\": [\"Strangler fig pattern\", \"Implementation using AWS services\", \"Using multiple accounts\", \"Refactor Spaces helps you create and configure the AWS infrastructure for routing API calls away from the monolithic application. Refactor Spaces orchestrates API Gateway, Network Load Balancer, and resource-based AWS Identity and Access Management (IAM) policies inside your AWS accounts as part of its application resource.\"],\\n      \"expected_answer\": \"Refactor Spaces facilitates routing API calls away from monolithic applications by orchestrating API Gateway, Network Load Balancer, and resource-based IAM policies within AWS accounts.\",\\n      \"query\": \"How does Refactor Spaces assist with routing in a multi-account AWS environment for the Strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Intent\", \"The transactional outbox pattern resolves the dual write operations issue that occurs in distributed systems when a single operation involves both a database write operation and a message or event notification.\"],\\n      \"expected_answer\": \"The transactional outbox pattern resolves the dual write operations issue in distributed systems where a single operation involves both a database write and a message/event notification.\",\\n      \"query\": \"What is the intent of the Transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Motivation\", \"When a microservice sends an event notification after a database update, these two operations should run atomically to ensure data consistency and reliability.\"],\\n      \"expected_answer\": \"The transactional outbox pattern is motivated by the need for atomic execution of database updates and event notifications in microservices to ensure data consistency and reliability.\",\\n      \"query\": \"What is the motivation behind the Transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Applicability\", \"Use the transactional outbox pattern when: You\\'re building an event-driven application where a database update initiates an event notification . You want to ensure atomicity in operations that involve two services. You want to implement the event sourcing pattern.\"],\\n      \"expected_answer\": \"The transactional outbox pattern is applicable when building event-driven applications where database updates trigger event notifications, ensuring atomicity in two-service operations, or implementing the event sourcing pattern.\",\\n      \"query\": \"When should the Transactional outbox pattern be used?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Issues and considerations\", \"Duplicate messages: The events processing service might send out duplicate messages or events, so we recommend that you make the consuming service idempotent by tracking the processed messages.\"],\\n      \"expected_answer\": \"A consideration for the transactional outbox pattern is duplicate messages; it\\'s recommended to make the consuming service idempotent by tracking processed messages.\",\\n      \"query\": \"What is a key issue with duplicate messages in the transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Implementation\", \"High-level architecture\", \"The following sequence diagram shows the order of events that happen during dual write operations.\"],\\n      \"expected_answer\": \"The high-level architecture illustrates the sequence of events during dual write operations.\",\\n      \"query\": \"Describe the high-level architecture of the Transactional outbox pattern.\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Implementation using AWS services\", \"To address this problem, you can use an outbox table or change data capture (CDC).\"],\\n      \"expected_answer\": \"To address the dual write problem, you can use an outbox table or change data capture (CDC).\",\\n      \"query\": \"What two options can be used to address the dual write problem in the transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Implementation using AWS services\", \"Using an outbox table with a relational database\", \"An outbox table stores all the events from the flight service with a timestamp and a sequence number. When the flight table is updated, the outbox table is also updated in the same transaction. Another service (for example, the event processing service) reads from the outbox table and sends the event to Amazon SQS.\"],\\n      \"expected_answer\": \"With an outbox table, events from the flight service are stored with timestamps and sequence numbers. When the flight table is updated, the outbox table is also updated in the same transaction. An event processing service then reads from the outbox table and sends the event to Amazon SQS.\",\\n      \"query\": \"How does using an outbox table work with a relational database in the transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Implementation using AWS services\", \"Using change data capture (CDC)\", \"Some databases support the publishing of item-level modifications to capture changed data. You can identify the changed items and send an event notification accordingly. This saves the overhead of creating another table to track the updates.\"],\\n      \"expected_answer\": \"Change data capture (CDC) allows databases to publish item-level modifications, enabling identification of changed items and sending event notifications, thus avoiding the need for an additional tracking table.\",\\n      \"query\": \"What is change data capture (CDC) in the context of the transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Implementation using AWS services\", \"Using change data capture (CDC)\", \"Amazon DynamoDB is a key-value NoSQL database that supports CDC updates. In the following sequence diagram, DynamoDB publishes item-level modifications to Amazon DynamoDB Streams. The event processing service reads from the streams and publishes the event notification to the payment service for further processing.\"],\\n      \"expected_answer\": \"Amazon DynamoDB, a NoSQL database, supports CDC updates by publishing item-level modifications to DynamoDB Streams. An event processing service reads these streams and publishes event notifications to the payment service.\",\\n      \"query\": \"How does Amazon DynamoDB support CDC in the transactional outbox pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"Sample code\", \"Using an outbox table\", \"The sample code in this section shows how you can implement the transactional outbox pattern by using an outbox table.\"],\\n      \"expected_answer\": \"The sample code demonstrates implementing the transactional outbox pattern using an outbox table.\",\\n      \"query\": \"What does the sample code for the transactional outbox pattern with an outbox table show?\"\\n    },\\n    {\\n      \"citations\": [\"Transactional outbox pattern\", \"GitHub repository\", \"For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/transactional-outbox-pattern.\"],\\n      \"expected_answer\": \"A complete implementation of the sample architecture for the Transactional outbox pattern is available in the GitHub repository at https://github.com/aws-samples/transactional-outbox-pattern.\",\\n      \"query\": \"Where can I find the GitHub repository for the Transactional outbox pattern sample architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"New patterns\", \"Added two new patterns: hexagonal architecture and scatter-gather.\", \"May 7, 2024\"],\\n      \"expected_answer\": \"On May 7, 2024, hexagonal architecture and scatter-gather patterns were added.\",\\n      \"query\": \"What new patterns were added on May 7, 2024?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"New code examples\", \"Added sample code for the change data capture (CDC) use case to the transactional outbox pattern pattern.\", \"February 23, 2024\"],\\n      \"expected_answer\": \"On February 23, 2024, sample code for the change data capture (CDC) use case was added to the transactional outbox pattern.\",\\n      \"query\": \"What update was made to the transactional outbox pattern on February 23, 2024?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"New code examples\", \"Updated the transactional outbox pattern with sample code.\", \"November 16, 2023\"],\\n      \"expected_answer\": \"On November 16, 2023, the transactional outbox pattern was updated with sample code.\",\\n      \"query\": \"What was updated in the transactional outbox pattern on November 16, 2023?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"Removed the section on orchestration and choreography patterns, which were superseded by saga choreography and saga orchestration.\", \"November 16, 2023\"],\\n      \"expected_answer\": \"On November 16, 2023, the sections on orchestration and choreography patterns were removed, superseded by saga choreography and saga orchestration.\",\\n      \"query\": \"What sections were removed on November 16, 2023, and why?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"New patterns\", \"Added three new patterns: saga choreography, publish-subscribe, and event sourcing.\", \"November 14, 2023\"],\\n      \"expected_answer\": \"On November 14, 2023, saga choreography, publish-subscribe, and event sourcing patterns were added.\",\\n      \"query\": \"What new patterns were added on November 14, 2023?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"Update\", \"Updated the strangler fig pattern implementation section.\", \"October 2, 2023\"],\\n      \"expected_answer\": \"On October 2, 2023, the strangler fig pattern implementation section was updated.\",\\n      \"query\": \"What update was made to the strangler fig pattern on October 2, 2023?\"\\n    },\\n    {\\n      \"citations\": [\"Document history\", \"Initial publication\", \"This first release includes eight design patterns: anti-corruption layer (ACL), API routing, circuit breaker, orchestration and choreography, retry with backoff, saga orchestration, strangler fig, and transactional outbox.\", \"July 28, 2023\"],\\n      \"expected_answer\": \"The initial publication on July 28, 2023, included eight design patterns: anti-corruption layer (ACL), API routing, circuit breaker, orchestration and choreography, retry with backoff, saga orchestration, strangler fig, and transactional outbox.\",\\n      \"query\": \"When was the initial publication of this guide, and what patterns did it include?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"7 Rs\", \"Seven common migration strategies for moving applications to the cloud. These strategies build upon the 5 Rs that Gartner identified in 2011 and consist of the following: Refactor/re-architect, Replatform (lift and reshape), Repurchase (drop and shop), Rehost (lift and shift), Relocate (hypervisor-level lift and shift), Retain (revisit), Retire.\"],\\n      \"expected_answer\": \"The 7 Rs are seven common migration strategies for moving applications to the cloud, building on Gartner\\'s 5 Rs from 2011. They include Refactor/re-architect, Replatform (lift and reshape), Repurchase (drop and shop), Rehost (lift and shift), Relocate (hypervisor-level lift and shift), Retain (revisit), and Retire.\",\\n      \"query\": \"What are the 7 Rs in cloud migration strategies?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"ACID\", \"A set of software properties that guarantee the data validity and operational reliability of a database, even in the case of errors, power failures, or other problems.\"],\\n      \"expected_answer\": \"ACID refers to a set of software properties that guarantee data validity and operational reliability for a database, even during errors or power failures.\",\\n      \"query\": \"What does ACID stand for in database contexts?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"active-active migration\", \"A database migration method in which the source and target databases are kept in sync (by using a bidirectional replication tool or dual write operations), and both databases handle transactions from connecting applications during migration.\"],\\n      \"expected_answer\": \"Active-active migration is a database migration method where both source and target databases are kept in sync via bidirectional replication or dual writes, and both handle transactions from connecting applications during migration.\",\\n      \"query\": \"Define active-active migration.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"active-passive migration\", \"A database migration method in which in which the source and target databases are kept in sync, but only the source database handles transactions from connecting applications while data is replicated to the target database. The target database doesnât accept any transactions during migration.\"],\\n      \"expected_answer\": \"Active-passive migration is a database migration method where source and target databases are kept in sync, but only the source handles transactions while data replicates to the target, which does not accept transactions during migration.\",\\n      \"query\": \"What is active-passive migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"anti-pattern\", \"A frequently used solution for a recurring issue where the solution is counter-productive, ineffective, or less effective than an alternative.\"],\\n      \"expected_answer\": \"An anti-pattern is a frequently used solution for a recurring issue that is counter-productive, ineffective, or less effective than an alternative.\",\\n      \"query\": \"What is an anti-pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Availability Zone\", \"A distinct location within an AWS Region that is insulated from failures in other Availability Zones and provides inexpensive, low-latency network connectivity to other Availability Zones in the same Region.\"],\\n      \"expected_answer\": \"An Availability Zone is a distinct location within an AWS Region, insulated from failures in other AZs, offering inexpensive, low-latency network connectivity to other AZs in the same Region.\",\\n      \"query\": \"What is an Availability Zone?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"blue/green deployment\", \"A deployment strategy where you create two separate but identical environments. You run the current application version in one environment (blue) and the new application version in the other environment (green). This strategy helps you quickly roll back with minimal impact.\"],\\n      \"expected_answer\": \"Blue/green deployment is a strategy where two identical environments run current (blue) and new (green) application versions, allowing quick rollbacks with minimal impact.\",\\n      \"query\": \"Explain blue/green deployment.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"canary deployment\", \"The slow and incremental release of a version to end users. When you are confident, you deploy the new version and replace the current version in its entirety.\"],\\n      \"expected_answer\": \"Canary deployment is a slow, incremental release of a new version to end users. Once confident, the new version fully replaces the current one.\",\\n      \"query\": \"What is canary deployment?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"change data capture (CDC)\", \"The process of tracking changes to a data source, such as a database table, and recording metadata about the change. You can use CDC for various purposes, such as auditing or replicating changes in a target system to maintain synchronization.\"],\\n      \"expected_answer\": \"Change data capture (CDC) is the process of tracking and recording metadata about changes to a data source, like a database table, used for purposes such as auditing or replicating changes for synchronization.\",\\n      \"query\": \"Define change data capture (CDC).\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"chaos engineering\", \"Intentionally introducing failures or disruptive events to test a systemâs resilience. You can use AWS Fault Injection Service (AWS FIS) to perform experiments that stress your AWS workloads and evaluate their response.\"],\\n      \"expected_answer\": \"Chaos engineering involves intentionally introducing failures or disruptive events to test system resilience, often using tools like AWS Fault Injection Service (AWS FIS) to evaluate workload responses.\",\\n      \"query\": \"What is chaos engineering?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"CI/CD\", \"The process of automating the source, build, test, staging, and production stages of the software release process. CI/CD is commonly described as a pipeline. CI/CD can help you automate processes, improve productivity, improve code quality, and deliver faster.\"],\\n      \"expected_answer\": \"CI/CD is the automation of the source, build, test, staging, and production stages of software release, commonly described as a pipeline, which helps automate processes, improve productivity, code quality, and delivery speed.\",\\n      \"query\": \"What is CI/CD?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Cloud Center of Excellence (CCoE)\", \"A multi-disciplinary team that drives cloud adoption efforts across an organization, including developing cloud best practices, mobilizing resources, establishing migration timelines, and leading the organization through large-scale transformations.\"],\\n      \"expected_answer\": \"A Cloud Center of Excellence (CCoE) is a multi-disciplinary team that spearheads cloud adoption within an organization, developing best practices, mobilizing resources, setting migration timelines, and guiding large-scale transformations.\",\\n      \"query\": \"What is a Cloud Center of Excellence (CCoE)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data at rest\", \"Data that is stationary in your network, such as data that is in storage.\"],\\n      \"expected_answer\": \"Data at rest refers to data that is stationary in your network, such as data in storage.\",\\n      \"query\": \"What is data at rest?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data in transit\", \"Data that is actively moving through your network, such as between network resources.\"],\\n      \"expected_answer\": \"Data in transit is data actively moving through your network, for example, between network resources.\",\\n      \"query\": \"What is data in transit?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data mesh\", \"An architectural framework that provides distributed, decentralized data ownership with centralized management and governance.\"],\\n      \"expected_answer\": \"A data mesh is an architectural framework offering distributed, decentralized data ownership with centralized management and governance.\",\\n      \"query\": \"Define data mesh.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"defense-in-depth\", \"An information security approach in which a series of security mechanisms and controls are thoughtfully layered throughout a computer network to protect the confidentiality, integrity, and availability of the network and the data within.\"],\\n      \"expected_answer\": \"Defense-in-depth is an information security approach that layers security mechanisms and controls throughout a network to protect its confidentiality, integrity, and availability, as well as its data.\",\\n      \"query\": \"What is defense-in-depth?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"disaster recovery (DR)\", \"The strategy and process you use to minimize downtime and data loss caused by a disaster.\"],\\n      \"expected_answer\": \"Disaster recovery (DR) is the strategy and process used to minimize downtime and data loss resulting from a disaster.\",\\n      \"query\": \"What is disaster recovery (DR)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"domain-driven design\", \"An approach to developing a complex software system by connecting its components to evolving domains, or core business goals, that each component serves.\"],\\n      \"expected_answer\": \"Domain-driven design is an approach to developing complex software systems by linking components to evolving domains or core business goals they serve.\",\\n      \"query\": \"What is domain-driven design?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"eventual consistency\", \"The sequential processing of local transactions results in eventual consistency, which can be a challenge in systems that require strong consistency.\"],\\n      \"expected_answer\": \"Eventual consistency results from sequential processing of local transactions and can be a challenge for systems requiring strong consistency.\",\\n      \"query\": \"What is eventual consistency?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"fail fast\", \"A philosophy that uses frequent and incremental testing to reduce the development lifecycle. It is a critical part of an agile approach.\"],\\n      \"expected_answer\": \"Fail fast is an agile philosophy that reduces the development lifecycle through frequent, incremental testing.\",\\n      \"query\": \"What is the \\'fail fast\\' philosophy?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"fault isolation boundary\", \"In the AWS Cloud, a boundary such as an Availability Zone, AWS Region, control plane, or data plane that limits the effect of a failure and helps improve the resilience of workloads.\"],\\n      \"expected_answer\": \"In the AWS Cloud, a fault isolation boundary, such as an Availability Zone or AWS Region, limits the impact of a failure and enhances workload resilience.\",\\n      \"query\": \"What is a fault isolation boundary in the AWS Cloud?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"foundation model (FM)\", \"A large deep-learning neural network that has been training on massive datasets of generalized and unlabeled data. FMs are capable of performing a wide variety of general tasks, such as understanding language, generating text and images, and conversing in natural language.\"],\\n      \"expected_answer\": \"A foundation model (FM) is a large deep-learning neural network trained on massive, generalized, unlabeled datasets, capable of diverse tasks like language understanding, text/image generation, and natural language conversation.\",\\n      \"query\": \"What is a foundation model (FM)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"generative AI\", \"A subset of AI models that have been trained on large amounts of data and that can use a simple text prompt to create new content and artifacts, such as images, videos, text, and audio.\"],\\n      \"expected_answer\": \"Generative AI is a subset of AI models trained on large datasets that can create new content like images, videos, text, and audio from simple text prompts.\",\\n      \"query\": \"What is generative AI?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"golden image\", \"A snapshot of a system or software that is used as a template to deploy new instances of that system or software.\"],\\n      \"expected_answer\": \"A golden image is a system or software snapshot used as a template for deploying new instances.\",\\n      \"query\": \"What is a golden image?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"high availability (HA)\", \"The ability of a workload to operate continuously, without intervention, in the event of challenges or disasters. HA systems are designed to automatically fail over, consistently deliver high-quality performance, and handle different loads and failures with minimal performance impact.\"],\\n      \"expected_answer\": \"High availability (HA) is a workload\\'s ability to operate continuously without intervention during challenges or disasters, designed for automatic failover, consistent high performance, and minimal impact from loads and failures.\",\\n      \"query\": \"What is high availability (HA)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"IaC\", \"The process of provisioning and managing an application\\'s infrastructure through a set of configuration files. IaC is designed to help you centralize infrastructure management, standardize resources, and scale quickly so that new environments are repeatable, reliable, and consistent.\"],\\n      \"expected_answer\": \"IaC (Infrastructure as Code) is the process of provisioning and managing application infrastructure via configuration files, aiming to centralize management, standardize resources, and enable quick, repeatable, reliable, and consistent scaling of new environments.\",\\n      \"query\": \"What is Infrastructure as Code (IaC)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"immutable infrastructure\", \"A model that deploys new infrastructure for production workloads instead of updating, patching, or modifying the existing infrastructure. Immutable infrastructures are inherently more consistent, reliable, and predictable than mutable infrastructure.\"],\\n      \"expected_answer\": \"Immutable infrastructure is a model where new infrastructure is deployed for production workloads instead of modifying existing ones, leading to more consistent, reliable, and predictable systems than mutable infrastructure.\",\\n      \"query\": \"What is immutable infrastructure?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"incremental migration\", \"A cutover strategy in which you migrate your application in small parts instead of performing a single, full cutover. For example, you might move only a few microservices or users to the new system initially. After you verify that everything is working properly, you can incrementally move additional microservices or users until you can decommission your legacy system.\"],\\n      \"expected_answer\": \"Incremental migration is a cutover strategy where applications are migrated in small parts, rather than a single full cutover, allowing for gradual movement of microservices or users and verification before decommissioning the legacy system.\",\\n      \"query\": \"Explain incremental migration.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"least privilege\", \"The security best practice of granting the minimum permissions required to perform a task.\"],\\n      \"expected_answer\": \"Least privilege is the security best practice of granting only the minimum permissions necessary to perform a task.\",\\n      \"query\": \"What is the principle of least privilege?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"large language model (LLM)\", \"A deep learning AI model that is pretrained on a vast amount of data. An LLM can perform multiple tasks, such as answering questions, summarizing documents, translating text into other languages, and completing sentences.\"],\\n      \"expected_answer\": \"A large language model (LLM) is a deep learning AI model pretrained on vast data, capable of tasks like answering questions, summarizing documents, translating text, and completing sentences.\",\\n      \"query\": \"What is a large language model (LLM)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"microservice\", \"A small, independent service that communicates over well-defined APIs and is typically owned by small, self-contained teams.\"],\\n      \"expected_answer\": \"A microservice is a small, independent service that communicates via well-defined APIs, typically owned by small, self-contained teams.\",\\n      \"query\": \"Define microservice.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"microservices architecture\", \"An approach to building an application with independent components that run each application process as a microservice. These microservices communicate through a well-defined interface by using lightweight APIs.\"],\\n      \"expected_answer\": \"Microservices architecture is an approach to building applications with independent components, where each process runs as a microservice, communicating via well-defined interfaces and lightweight APIs.\",\\n      \"query\": \"What is microservices architecture?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"modernization\", \"Transforming an outdated (legacy or monolithic) application and its infrastructure into an agile, elastic, and highly available system in the cloud to reduce costs, gain efficiencies, and take advantage of innovations.\"],\\n      \"expected_answer\": \"Modernization involves transforming outdated applications and infrastructure into agile, elastic, highly available cloud systems to reduce costs, improve efficiency, and leverage innovation.\",\\n      \"query\": \"What does modernization entail?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"monolithic applications (monoliths)\", \"Applications that run as a single service with tightly coupled processes. Monolithic applications have several drawbacks. If one application feature experiences a spike in demand, the entire architecture must be scaled. Adding or improving a monolithic applicationâs features also becomes more complex when the code base grows.\"],\\n      \"expected_answer\": \"Monolithic applications run as a single service with tightly coupled processes, leading to drawbacks such as needing to scale the entire architecture for a single feature\\'s demand spike, and increased complexity in adding or improving features as the codebase grows.\",\\n      \"query\": \"What are monolithic applications and their drawbacks?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"online migration\", \"A migration method in which the source workload is copied to the target system without being taken offline. Applications that are connected to the workload can continue to function during the migration. This method involves zero to minimal downtime and is typically used for critical production workloads.\"],\\n      \"expected_answer\": \"Online migration is a method where the source workload is copied to the target system without downtime, allowing connected applications to function during the process. It\\'s typically used for critical production workloads.\",\\n      \"query\": \"Describe online migration.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"polyglot persistence\", \"Independently choosing a microserviceâs data storage technology based on data access patterns and other requirements. If your microservices have the same data storage technology, they can encounter implementation challenges or experience poor performance.\"],\\n      \"expected_answer\": \"Polyglot persistence is the independent selection of a microservice\\'s data storage technology based on its data access patterns and requirements, avoiding challenges and poor performance that can arise from using the same technology across all microservices.\",\\n      \"query\": \"What is polyglot persistence?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"publish/subscribe (pub/sub)\", \"A pattern that enables asynchronous communications among microservices to improve scalability and responsiveness.\"],\\n      \"expected_answer\": \"Publish/subscribe (pub/sub) is a pattern that enables asynchronous communication among microservices to enhance scalability and responsiveness.\",\\n      \"query\": \"What is the publish/subscribe (pub/sub) pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"recovery point objective (RPO)\", \"The maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.\"],\\n      \"expected_answer\": \"RPO (Recovery Point Objective) is the maximum acceptable time since the last data recovery point, defining the tolerable data loss between that point and a service interruption.\",\\n      \"query\": \"What is RPO?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"recovery time objective (RTO)\", \"The maximum acceptable delay between the interruption of service and restoration of service.\"],\\n      \"expected_answer\": \"RTO (Recovery Time Objective) is the maximum acceptable delay between service interruption and restoration.\",\\n      \"query\": \"What is RTO?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"resiliency\", \"An application\\'s ability to resist or recover from disruptions. High availability and disaster recovery are common considerations when planning for resiliency in the AWS Cloud.\"],\\n      \"expected_answer\": \"Resiliency is an application\\'s ability to resist or recover from disruptions, with high availability and disaster recovery being key considerations in the AWS Cloud.\",\\n      \"query\": \"Define resiliency.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Retrieval Augmented Generation (RAG)\", \"A generative AI technology in which an LLM references an authoritative data source that is outside of its training data sources before generating a response.\"],\\n      \"expected_answer\": \"Retrieval Augmented Generation (RAG) is a generative AI technology where an LLM references an authoritative external data source before generating a response.\",\\n      \"query\": \"What is Retrieval Augmented Generation (RAG)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"shared responsibility model\", \"A model describing the responsibility you share with AWS for cloud security and compliance. AWS is responsible for security of the cloud, whereas you are responsible for security in the cloud.\"],\\n      \"expected_answer\": \"The shared responsibility model outlines that AWS is responsible for security *of* the cloud, while the user is responsible for security *in* the cloud, regarding cloud security and compliance.\",\\n      \"query\": \"Explain the shared responsibility model.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"single point of failure (SPOF)\", \"A failure in a single, critical component of an application that can disrupt the system.\"],\\n      \"expected_answer\": \"A single point of failure (SPOF) is a failure in a single, critical application component that can disrupt the entire system.\",\\n      \"query\": \"What is a single point of failure (SPOF)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"strangler fig pattern\", \"An approach to modernizing monolithic systems by incrementally rewriting and replacing system functionality until the legacy system can be decommissioned.\"],\\n      \"expected_answer\": \"The strangler fig pattern is an approach to modernize monolithic systems by incrementally rewriting and replacing functionality until the legacy system can be decommissioned.\",\\n      \"query\": \"What is the strangler fig pattern?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"two-pizza team\", \"A small DevOps team that you can feed with two pizzas. A two-pizza team size ensures the best possible opportunity for collaboration in software development.\"],\\n      \"expected_answer\": \"A two-pizza team is a small DevOps team, ideally sized to be fed by two pizzas, designed to maximize collaboration in software development.\",\\n      \"query\": \"What is a two-pizza team?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"undifferentiated tasks\", \"Also known as heavy lifting, work that is necessary to create and operate an application but that doesnât provide direct value to the end user or provide competitive advantage.\"],\\n      \"expected_answer\": \"Undifferentiated tasks, also known as heavy lifting, are necessary for application creation and operation but do not provide direct value to the end user or competitive advantage.\",\\n      \"query\": \"What are undifferentiated tasks?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"zero-day vulnerability\", \"An unmitigated flaw or vulnerability in a production system. Threat actors can use this type of vulnerability to attack the system. Developers frequently become aware of the vulnerability as a result of the attack.\"],\\n      \"expected_answer\": \"A zero-day vulnerability is an unmitigated flaw in a production system that threat actors can exploit, often becoming known to developers only after an attack.\",\\n      \"query\": \"What is a zero-day vulnerability?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"zero-shot prompting\", \"Providing an LLM with instructions for performing a task but no examples (shots) that can help guide it. The LLM must use its pre-trained knowledge to handle the task.\"],\\n      \"expected_answer\": \"Zero-shot prompting involves providing an LLM with task instructions but no examples, requiring the LLM to use its pre-trained knowledge to complete the task.\",\\n      \"query\": \"What is zero-shot prompting?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"few-shot prompting\", \"Providing an LLM with a small number of examples that demonstrate the task and desired output before asking it to perform a similar task. This technique is an application of in-context learning, where models learn from examples (shots) that are embedded in prompts.\"],\\n      \"expected_answer\": \"Few-shot prompting provides an LLM with a small number of examples demonstrating a task and desired output, allowing the model to learn from these in-context examples before performing similar tasks.\",\\n      \"query\": \"What is few-shot prompting?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"hot data\", \"Data that is frequently accessed, such as real-time data or recent translational data. This data typically requires a high-performance storage tier or class to provide fast query responses.\"],\\n      \"expected_answer\": \"Hot data is frequently accessed data, like real-time or recent transactional data, requiring high-performance storage for fast query responses.\",\\n      \"query\": \"What is hot data?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"cold data\", \"Data that is rarely accessed and is typically historical. When querying this kind of data, slow queries are typically acceptable. Moving this data to lower-performing and less expensive storage tiers or classes can reduce costs.\"],\\n      \"expected_answer\": \"Cold data is rarely accessed, typically historical data, where slow queries are acceptable. Moving it to lower-performing, less expensive storage tiers can reduce costs.\",\\n      \"query\": \"What is cold data?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"warm data\", \"Data that is infrequently accessed. When querying this kind of data, moderately slow queries are typically acceptable.\"],\\n      \"expected_answer\": \"Warm data is infrequently accessed data where moderately slow queries are typically acceptable.\",\\n      \"query\": \"What is warm data?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"hotfix\", \"An urgent fix for a critical issue in a production environment. Due to its urgency, a hotfix is usually made outside of the typical DevOps release workflow.\"],\\n      \"expected_answer\": \"A hotfix is an urgent fix for a critical production issue, typically deployed outside the standard DevOps release workflow due to its urgency.\",\\n      \"query\": \"What is a hotfix?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"hypercare period\", \"Immediately following cutover, the period of time when a migration team manages and monitors the migrated applications in the cloud in order to address any issues. Typically, this period is 1â4 days in length.\"],\\n      \"expected_answer\": \"The hypercare period is the 1-4 day period immediately after cutover when a migration team manages and monitors migrated cloud applications to address any issues.\",\\n      \"query\": \"What is the hypercare period in migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"idle application\", \"An application that has an average CPU and memory usage between 5 and 20 percent over a period of 90 days. In a migration project, it is common to retire these applications or retain them on premises.\"],\\n      \"expected_answer\": \"An idle application has average CPU and memory usage between 5% and 20% over 90 days; in migration projects, these are often retired or kept on-premises.\",\\n      \"query\": \"What defines an idle application?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"zombie application\", \"An application that has an average CPU and memory usage below 5 percent. In a migration project, it is common to retire these applications.\"],\\n      \"expected_answer\": \"A zombie application has average CPU and memory usage below 5 percent, and is commonly retired in migration projects.\",\\n      \"query\": \"What is a zombie application?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"landing zone\", \"A landing zone is a well-architected, multi-account AWS environment that is scalable and secure. This is a starting point from which your organizations can quickly launch and deploy workloads and applications with confidence in their security and infrastructure environment.\"],\\n      \"expected_answer\": \"A landing zone is a well-architected, scalable, and secure multi-account AWS environment, serving as a starting point for organizations to confidently launch and deploy workloads.\",\\n      \"query\": \"What is a landing zone?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"large migration\", \"A migration of 300 or more servers.\"],\\n      \"expected_answer\": \"A large migration involves 300 or more servers.\",\\n      \"query\": \"How many servers define a large migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"migration factory\", \"Cross-functional teams that streamline the migration of workloads through automated, agile approaches.\"],\\n      \"expected_answer\": \"A migration factory consists of cross-functional teams that streamline workload migration using automated, agile approaches.\",\\n      \"query\": \"What is a migration factory?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"migration at scale\", \"The process of moving the majority of the application portfolio to the cloud in waves, with more applications moved at a faster rate in each wave. This phase uses the best practices and lessons learned from the earlier phases to implement a migration factory of teams, tools, and processes to streamline the migration of workloads through automation and agile delivery.\"],\\n      \"expected_answer\": \"Migration at scale is the process of moving most of an application portfolio to the cloud in increasing waves, leveraging best practices and lessons learned to establish a migration factory for streamlined, automated, and agile workload migration.\",\\n      \"query\": \"What is migration at scale?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Migration Acceleration Program (MAP)\", \"An AWS program that provides consulting support, training, and services to help organizations build a strong operational foundation for moving to the cloud, and to help offset the initial cost of migrations.\"],\\n      \"expected_answer\": \"The Migration Acceleration Program (MAP) is an AWS program offering consulting, training, and services to help organizations build a strong operational foundation for cloud migration and offset initial costs.\",\\n      \"query\": \"What is the Migration Acceleration Program (MAP)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Migration Portfolio Assessment (MPA)\", \"An online tool that provides information for validating the business case for migrating to the AWS Cloud. MPA provides detailed portfolio assessment (server right-sizing, pricing, TCO comparisons, migration cost analysis) as well as migration planning (application data analysis and data collection, application grouping, migration prioritization, and wave planning).\"],\\n      \"expected_answer\": \"Migration Portfolio Assessment (MPA) is an online tool that validates the business case for AWS Cloud migration, offering detailed portfolio assessment (server right-sizing, pricing, TCO, cost analysis) and migration planning (data analysis, grouping, prioritization, wave planning).\",\\n      \"query\": \"What is Migration Portfolio Assessment (MPA)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Migration Readiness Assessment (MRA)\", \"The process of gaining insights about an organizationâs cloud readiness status, identifying strengths and weaknesses, and building an action plan to close identified gaps, using the AWS CAF.\"],\\n      \"expected_answer\": \"Migration Readiness Assessment (MRA) is the process of evaluating an organization\\'s cloud readiness using AWS CAF, identifying strengths and weaknesses, and creating an action plan to address gaps.\",\\n      \"query\": \"What is Migration Readiness Assessment (MRA)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"offline migration\", \"A migration method in which the source workload is taken down during the migration process. This method involves extended downtime and is typically used for small, non-critical workloads.\"],\\n      \"expected_answer\": \"Offline migration is a method where the source workload is taken down during migration, resulting in extended downtime, typically used for small, non-critical workloads.\",\\n      \"query\": \"What is offline migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"operational readiness review (ORR)\", \"A checklist of questions and associated best practices that help you understand, evaluate, prevent, or reduce the scope of incidents and possible failures.\"],\\n      \"expected_answer\": \"An operational readiness review (ORR) is a checklist of questions and best practices to understand, evaluate, prevent, or reduce the scope of incidents and failures.\",\\n      \"query\": \"What is an operational readiness review (ORR)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"organizational change management (OCM)\", \"A framework for managing major, disruptive business transformations from a people, culture, and leadership perspective.\"],\\n      \"expected_answer\": \"Organizational change management (OCM) is a framework for managing major, disruptive business transformations from the perspective of people, culture, and leadership.\",\\n      \"query\": \"What is organizational change management (OCM)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"playbook\", \"A set of predefined steps that capture the work associated with migrations, such as delivering core operations functions in the cloud. A playbook can take the form of scripts, automated runbooks, or a summary of processes or steps required to operate your modernized environment.\"],\\n      \"expected_answer\": \"A playbook is a set of predefined steps capturing migration work, such as delivering cloud operations functions. It can be scripts, automated runbooks, or process summaries for operating a modernized environment.\",\\n      \"query\": \"What is a playbook in the context of migrations?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"query plan\", \"A series of steps, like instructions, that are used to access the data in a SQL relational database system.\"],\\n      \"expected_answer\": \"A query plan is a series of instructional steps used to access data in a SQL relational database system.\",\\n      \"query\": \"What is a query plan?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"query plan regression\", \"When a database service optimizer chooses a less optimal plan than it did before a given change to the database environment. This can be caused by changes to statistics, constraints, environment settings, query parameter bindings, and updates to the database engine.\"],\\n      \"expected_answer\": \"Query plan regression occurs when a database optimizer selects a suboptimal plan after an environment change, caused by alterations in statistics, constraints, settings, parameter bindings, or database engine updates.\",\\n      \"query\": \"What is query plan regression?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"read replica\", \"A copy of a database thatâs used for read-only purposes. You can route queries to the read replica to reduce the load on your primary database.\"],\\n      \"expected_answer\": \"A read replica is a read-only copy of a database, used to offload queries from the primary database.\",\\n      \"query\": \"What is a read replica?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"runbook\", \"A set of manual or automated procedures required to perform a specific task. These are typically built to streamline repetitive operations or procedures with high error rates.\"],\\n      \"expected_answer\": \"A runbook is a set of manual or automated procedures for specific tasks, designed to streamline repetitive operations or those with high error rates.\",\\n      \"query\": \"What is a runbook?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"secret\", \"In AWS Secrets Manager, confidential or restricted information, such as a password or user credentials, that you store in encrypted form. It consists of the secret value and its metadata.\"],\\n      \"expected_answer\": \"In AWS Secrets Manager, a secret is confidential or restricted information, like a password or user credentials, stored in encrypted form, comprising the secret value and its metadata.\",\\n      \"query\": \"What is a secret in AWS Secrets Manager?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"security hardening\", \"The process of reducing the attack surface to make it more resistant to attacks. This can include actions such as removing resources that are no longer needed, implementing the security best practice of granting least privilege, or deactivating unnecessary features in configuration files.\"],\\n      \"expected_answer\": \"Security hardening is the process of reducing an attack surface to improve resistance to attacks, involving actions like removing unneeded resources, implementing least privilege, or deactivating unnecessary features.\",\\n      \"query\": \"What is security hardening?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"service control policy (SCP)\", \"A policy that provides centralized control over permissions for all accounts in an organization in AWS Organizations. SCPs define guardrails or set limits on actions that an administrator can delegate to users or roles.\"],\\n      \"expected_answer\": \"A service control policy (SCP) provides centralized control over permissions for all accounts in an AWS Organizations organization, defining guardrails or limits on actions an administrator can delegate.\",\\n      \"query\": \"What is a service control policy (SCP)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"service endpoint\", \"The URL of the entry point for an AWS service. You can use the endpoint to connect programmatically to the target service.\"],\\n      \"expected_answer\": \"A service endpoint is the URL entry point for an AWS service, used for programmatic connections to that service.\",\\n      \"query\": \"What is a service endpoint?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"star schema\", \"A database organizational structure that uses one large fact table to store transactional or measured data and uses one or more smaller dimensional tables to store data attributes. This structure is designed for use in a data warehouse or for business intelligence purposes.\"],\\n      \"expected_answer\": \"A star schema is a database structure with a large fact table for transactional data and smaller dimensional tables for data attributes, designed for data warehousing or business intelligence.\",\\n      \"query\": \"What is a star schema?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"subnet\", \"A range of IP addresses in your VPC. A subnet must reside in a single Availability Zone.\"],\\n      \"expected_answer\": \"A subnet is a range of IP addresses within your VPC, confined to a single Availability Zone.\",\\n      \"query\": \"What is a subnet?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"tags\", \"Key-value pairs that act as metadata for organizing your AWS resources. Tags can help you manage, identify, organize, search for, and filter resources.\"],\\n      \"expected_answer\": \"Tags are key-value pairs serving as metadata to organize AWS resources, aiding in management, identification, organization, searching, and filtering.\",\\n      \"query\": \"What are tags in AWS?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"training\", \"To provide data for your ML model to learn from. The training data must contain the correct answer. The learning algorithm finds patterns in the training data that map the input data attributes to the target (the answer that you want to predict). It outputs an ML model that captures these patterns.\"],\\n      \"expected_answer\": \"Training an ML model involves providing data with correct answers, allowing the learning algorithm to find patterns mapping input attributes to the target, and producing an ML model that captures these patterns.\",\\n      \"query\": \"What is training in machine learning?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"transit gateway\", \"A network transit hub that you can use to interconnect your VPCs and on-premises networks.\"],\\n      \"expected_answer\": \"A transit gateway is a network transit hub used to interconnect VPCs and on-premises networks.\",\\n      \"query\": \"What is a transit gateway?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"trunk-based workflow\", \"An approach in which developers build and test features locally in a feature branch and then merge those changes into the main branch. The main branch is then built to the development, preproduction, and production environments, sequentially.\"],\\n      \"expected_answer\": \"A trunk-based workflow involves developers building and testing features locally in a feature branch, merging changes into the main branch, which is then sequentially built to development, preproduction, and production environments.\",\\n      \"query\": \"What is a trunk-based workflow?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"VPC peering\", \"A connection between two VPCs that allows you to route traffic by using private IP addresses.\"],\\n      \"expected_answer\": \"VPC peering is a connection between two VPCs that enables traffic routing using private IP addresses.\",\\n      \"query\": \"What is VPC peering?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"workload\", \"A collection of resources and code that delivers business value, such as a customer-facing application or backend process.\"],\\n      \"expected_answer\": \"A workload is a collection of resources and code that delivers business value, such as a customer-facing application or backend process.\",\\n      \"query\": \"Define workload.\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"write once, read many (WORM)\", \"A storage model that writes data a single time and prevents the data from being deleted or modified. Authorized users can read the data as many times as needed, but they cannot change it.\"],\\n      \"expected_answer\": \"Write once, read many (WORM) is a storage model where data is written once and cannot be deleted or modified, but authorized users can read it repeatedly.\",\\n      \"query\": \"What is WORM storage?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"computer vision (CV)\", \"A field of AI that uses machine learning to analyze and extract information from visual formats such as digital images and videos.\"],\\n      \"expected_answer\": \"Computer vision (CV) is an AI field that uses machine learning to analyze and extract information from visual formats like digital images and videos.\",\\n      \"query\": \"What is computer vision (CV)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"machine learning (ML)\", \"A type of artificial intelligence that uses algorithms and techniques for pattern recognition and learning. ML analyzes and learns from recorded data, such as Internet of Things (IoT) data, to generate a statistical model based on patterns.\"],\\n      \"expected_answer\": \"Machine learning (ML) is a type of artificial intelligence that uses algorithms and techniques for pattern recognition and learning, analyzing recorded data to generate statistical models based on patterns.\",\\n      \"query\": \"What is machine learning (ML)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"deep learning\", \"An ML subfield that uses multiple layers of artificial neural networks to identify mapping between input data and target variables of interest.\"],\\n      \"expected_answer\": \"Deep learning is an ML subfield that uses multiple layers of artificial neural networks to map input data to target variables.\",\\n      \"query\": \"What is deep learning?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Internet of Things (IoT)\", \"The network of connected physical objects with embedded sensors or processors that communicate with other devices and systems through the internet or over a local communication network.\"],\\n      \"expected_answer\": \"The Internet of Things (IoT) is a network of physical objects with embedded sensors or processors that communicate with other devices and systems via the internet or local networks.\",\\n      \"query\": \"What is the Internet of Things (IoT)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"industrial Internet of Things (IIoT)\", \"The use of internet-connected sensors and devices in the industrial sectors, such as manufacturing, energy, automotive, healthcare, life sciences, and agriculture.\"],\\n      \"expected_answer\": \"Industrial Internet of Things (IIoT) refers to the use of internet-connected sensors and devices in industrial sectors like manufacturing, energy, automotive, healthcare, life sciences, and agriculture.\",\\n      \"query\": \"What is Industrial Internet of Things (IIoT)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"operational technology (OT)\", \"Hardware and software systems that work with the physical environment to control industrial operations, equipment, and infrastructure.\"],\\n      \"expected_answer\": \"Operational technology (OT) refers to hardware and software systems that interact with the physical environment to control industrial operations, equipment, and infrastructure.\",\\n      \"query\": \"What is operational technology (OT)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"historian modernization\", \"An approach used to modernize and upgrade operational technology (OT) systems to better serve the needs of the manufacturing industry. A historian is a type of database that is used to collect and store data from various sources in a factory.\"],\\n      \"expected_answer\": \"Historian modernization is an approach to upgrade operational technology (OT) systems for the manufacturing industry, where a historian is a database collecting and storing factory data.\",\\n      \"query\": \"What is historian modernization?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Industry 4.0\", \"A term that was introduced by Klaus Schwab in 2016 to refer to the modernization of manufacturing processes through advances in connectivity, real-time data, automation, analytics, and AI/ML.\"],\\n      \"expected_answer\": \"Industry 4.0, introduced by Klaus Schwab in 2016, refers to the modernization of manufacturing processes through advancements in connectivity, real-time data, automation, analytics, and AI/ML.\",\\n      \"query\": \"What is Industry 4.0 and who introduced the term?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Message Queuing Telemetry Transport (MQTT)\", \"A lightweight, machine-to-machine (M2M) communication protocol, based on the publish/ subscribe pattern, for resource-constrained IoT devices.\"],\\n      \"expected_answer\": \"Message Queuing Telemetry Transport (MQTT) is a lightweight, publish/subscribe-based M2M communication protocol designed for resource-constrained IoT devices.\",\\n      \"query\": \"What is MQTT?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Open Process Communications - Unified Architecture (OPC-UA)\", \"A machine-to-machine (M2M) communication protocol for industrial automation. OPC-UA provides an interoperability standard with data encryption, authentication, and authorization schemes.\"],\\n      \"expected_answer\": \"Open Process Communications - Unified Architecture (OPC-UA) is an M2M communication protocol for industrial automation, offering an interoperability standard with data encryption, authentication, and authorization.\",\\n      \"query\": \"What is OPC-UA?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"programmable logic controller (PLC)\", \"In manufacturing, a highly reliable, adaptable computer that monitors machines and automates manufacturing processes.\"],\\n      \"expected_answer\": \"In manufacturing, a programmable logic controller (PLC) is a highly reliable, adaptable computer that monitors machines and automates manufacturing processes.\",\\n      \"query\": \"What is a PLC in manufacturing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"supervisory control and data acquisition (SCADA)\", \"In manufacturing, a system that uses hardware and software to monitor physical assets and production operations.\"],\\n      \"expected_answer\": \"In manufacturing, SCADA is a system that uses hardware and software to monitor physical assets and production operations.\",\\n      \"query\": \"What is SCADA in manufacturing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"product lifecycle management (PLM)\", \"The management of data and processes for a product throughout its entire lifecycle, from design, development, and launch, through growth and maturity, to decline and removal.\"],\\n      \"expected_answer\": \"Product lifecycle management (PLM) is the management of data and processes for a product across its entire lifecycle, from design to decline.\",\\n      \"query\": \"What is product lifecycle management (PLM)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"enterprise resource planning (ERP)\", \"A system that automates and manages key business processes (such as accounting, MES, and project management) for an enterprise.\"],\\n      \"expected_answer\": \"Enterprise resource planning (ERP) is a system that automates and manages key business processes like accounting, MES, and project management for an enterprise.\",\\n      \"query\": \"What is enterprise resource planning (ERP)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"manufacturing execution system (MES)\", \"A software system for tracking, monitoring, documenting, and controlling production processes that convert raw materials to finished products on the shop floor.\"],\\n      \"expected_answer\": \"A manufacturing execution system (MES) is a software system that tracks, monitors, documents, and controls production processes from raw materials to finished products on the shop floor.\",\\n      \"query\": \"What is a manufacturing execution system (MES)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"electronic data interchange (EDI)\", \"The automated exchange of business documents between organizations.\"],\\n      \"expected_answer\": \"Electronic data interchange (EDI) is the automated exchange of business documents between organizations.\",\\n      \"query\": \"What is electronic data interchange (EDI)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"cloud computing\", \"The cloud technology that is typically used for remote data storage and IoT device management. Cloud computing is commonly connected to edge computing technology.\"],\\n      \"expected_answer\": \"Cloud computing is a technology typically used for remote data storage and IoT device management, often connected to edge computing.\",\\n      \"query\": \"What is cloud computing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"edge computing\", \"The technology that increases the computing power for smart devices at the edges of an IoT network. When compared with cloud computing, edge computing can reduce communication latency and improve response time.\"],\\n      \"expected_answer\": \"Edge computing increases computing power for smart devices at the edges of an IoT network, reducing communication latency and improving response time compared to cloud computing.\",\\n      \"query\": \"What is edge computing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data warehouse\", \"A data management system that supports business intelligence, such as analytics. Data warehouses commonly contain large amounts of historical data, and they are typically used for queries and analysis.\"],\\n      \"expected_answer\": \"A data warehouse is a data management system supporting business intelligence and analytics, typically containing large amounts of historical data for queries and analysis.\",\\n      \"query\": \"What is a data warehouse?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data minimization\", \"The principle of collecting and processing only the data that is strictly necessary. Practicing data minimization in the AWS Cloud can reduce privacy risks, costs, and your analytics carbon footprint.\"],\\n      \"expected_answer\": \"Data minimization is the principle of collecting and processing only strictly necessary data, which in the AWS Cloud can reduce privacy risks, costs, and analytics carbon footprint.\",\\n      \"query\": \"What is data minimization?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data perimeter\", \"A set of preventive guardrails in your AWS environment that help make sure that only trusted identities are accessing trusted resources from expected networks.\"],\\n      \"expected_answer\": \"A data perimeter is a set of preventive guardrails in an AWS environment ensuring only trusted identities access trusted resources from expected networks.\",\\n      \"query\": \"What is a data perimeter?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data provenance\", \"The process of tracking the origin and history of data throughout its lifecycle, such as how the data was generated, transmitted, and stored.\"],\\n      \"expected_answer\": \"Data provenance is the process of tracking data\\'s origin and history throughout its lifecycle, including how it was generated, transmitted, and stored.\",\\n      \"query\": \"What is data provenance?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data classification\", \"A process for identifying and categorizing the data in your network based on its criticality and sensitivity. It is a critical component of any cybersecurity risk management strategy because it helps you determine the appropriate protection and retention controls for the data.\"],\\n      \"expected_answer\": \"Data classification is the process of identifying and categorizing network data by criticality and sensitivity, crucial for cybersecurity risk management to determine appropriate protection and retention controls.\",\\n      \"query\": \"What is data classification?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data preprocessing\", \"To transform raw data into a format that is easily parsed by your ML model. Preprocessing data can mean removing certain columns or rows and addressing missing, inconsistent, or duplicate values.\"],\\n      \"expected_answer\": \"Data preprocessing transforms raw data into a format easily parsed by an ML model, involving tasks like removing columns/rows and handling missing, inconsistent, or duplicate values.\",\\n      \"query\": \"What is data preprocessing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data drift\", \"A meaningful variation between the production data and the data that was used to train an ML model, or a meaningful change in the input data over time. Data drift can reduce the overall quality, accuracy, and fairness in ML model predictions.\"],\\n      \"expected_answer\": \"Data drift is a significant variation between production data and ML model training data, or a meaningful change in input data over time, which can reduce ML model prediction quality, accuracy, and fairness.\",\\n      \"query\": \"What is data drift?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"data subject\", \"An individual whose data is being collected and processed.\"],\\n      \"expected_answer\": \"A data subject is an individual whose data is being collected and processed.\",\\n      \"query\": \"Who is a data subject?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"digital twin\", \"A virtual representation of a real-world system, such as a building, factory, industrial equipment, or production line. Digital twins support predictive maintenance, remote monitoring, and production optimization.\"],\\n      \"expected_answer\": \"A digital twin is a virtual representation of a real-world system, like a factory, supporting predictive maintenance, remote monitoring, and production optimization.\",\\n      \"query\": \"What is a digital twin?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"encryption\", \"A computing process that transforms plaintext data, which is human-readable, into ciphertext.\"],\\n      \"expected_answer\": \"Encryption is a computing process that transforms human-readable plaintext data into ciphertext.\",\\n      \"query\": \"What is encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"encryption key\", \"A cryptographic string of randomized bits that is generated by an encryption algorithm. Keys can vary in length, and each key is designed to be unpredictable and unique.\"],\\n      \"expected_answer\": \"An encryption key is a cryptographic string of randomized bits generated by an encryption algorithm, varying in length, and designed to be unpredictable and unique.\",\\n      \"query\": \"What is an encryption key?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"envelope encryption\", \"The process of encrypting an encryption key with another encryption key.\"],\\n      \"expected_answer\": \"Envelope encryption is the process of encrypting an encryption key with another encryption key.\",\\n      \"query\": \"What is envelope encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"symmetric encryption\", \"An encryption algorithm that uses the same key to encrypt and decrypt the data.\"],\\n      \"expected_answer\": \"Symmetric encryption uses the same key for both encrypting and decrypting data.\",\\n      \"query\": \"What is symmetric encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"asymmetric encryption\", \"An encryption algorithm that uses a pair of keys, a public key for encryption and a private key for decryption. You can share the public key because it isnât used for decryption, but access to the private key should be highly restricted.\"],\\n      \"expected_answer\": \"Asymmetric encryption uses a public key for encryption and a private key for decryption; the public key can be shared, but private key access must be highly restricted.\",\\n      \"query\": \"What is asymmetric encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"client-side encryption\", \"Encryption of data locally, before the target AWS service receives it.\"],\\n      \"expected_answer\": \"Client-side encryption is the local encryption of data before it reaches the target AWS service.\",\\n      \"query\": \"What is client-side encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"server-side encryption\", \"Encryption of data at its destination, by the AWS service that receives it.\"],\\n      \"expected_answer\": \"Server-side encryption is the encryption of data at its destination by the receiving AWS service.\",\\n      \"query\": \"What is server-side encryption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"environment\", \"An instance of a running application. The following are common types of environments in cloud computing: development environment, lower environments, production environment, upper environments.\"],\\n      \"expected_answer\": \"An environment is an instance of a running application, with common types in cloud computing including development, lower, production, and upper environments.\",\\n      \"query\": \"What is an environment in cloud computing?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"development environment\", \"An instance of a running application that is available only to the core team responsible for maintaining the application. Development environments are used to test changes before promoting them to upper environments. This type of environment is sometimes referred to as a test environment.\"],\\n      \"expected_answer\": \"A development environment is an instance of a running application accessible only to the core maintenance team, used for testing changes before promotion to upper environments, sometimes called a test environment.\",\\n      \"query\": \"What is a development environment?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"production environment\", \"An instance of a running application that end users can access. In a CI/CD pipeline, the production environment is the last deployment environment.\"],\\n      \"expected_answer\": \"A production environment is an instance of a running application accessible by end users, serving as the final deployment environment in a CI/CD pipeline.\",\\n      \"query\": \"What is a production environment?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"lower environments\", \"All development environments for an application, such as those used for initial builds and tests.\"],\\n      \"expected_answer\": \"Lower environments encompass all development environments for an application, including those used for initial builds and tests.\",\\n      \"query\": \"What are lower environments?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"upper environments\", \"All environments that can be accessed by users other than the core development team. This can include a production environment, preproduction environments, and environments for user acceptance testing.\"],\\n      \"expected_answer\": \"Upper environments include all environments accessible by users beyond the core development team, such as production, preproduction, and user acceptance testing environments.\",\\n      \"query\": \"What are upper environments?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Gitflow workflow\", \"An approach in which lower and upper environments use different branches in a source code repository. The Gitflow workflow is considered legacy, and the trunk-based workflow is the modern, preferred approach.\"],\\n      \"expected_answer\": \"Gitflow workflow is a legacy approach where lower and upper environments use different branches in a source code repository; trunk-based workflow is the modern, preferred alternative.\",\\n      \"query\": \"What is Gitflow workflow?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"branch\", \"A contained area of a code repository. The first branch created in a repository is the main branch. You can create a new branch from an existing branch, and you can then develop features or fix bugs in the new branch.\"],\\n      \"expected_answer\": \"A branch is a contained area within a code repository. The initial branch is the main branch, from which new branches can be created for developing features or fixing bugs.\",\\n      \"query\": \"What is a branch in a code repository?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"main branch\", \"The first branch created in a repository is the main branch.\"],\\n      \"expected_answer\": \"The main branch is the first branch created in a repository.\",\\n      \"query\": \"What is the main branch?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"feature branch\", \"A branch you create to build a feature is commonly referred to as a feature branch.\"],\\n      \"expected_answer\": \"A feature branch is a branch created specifically for building a new feature.\",\\n      \"query\": \"What is a feature branch?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"heterogeneous database migration\", \"Migrating your source database to a target database that uses a different database engine (for example, Oracle to Amazon Aurora). Heterogeneous migration is typically part of a re-architecting effort, and converting the schema can be a complex task.\"],\\n      \"expected_answer\": \"Heterogeneous database migration involves moving a source database to a target database with a different engine (e.g., Oracle to Amazon Aurora), typically part of a re-architecting effort, and schema conversion can be complex.\",\\n      \"query\": \"What is heterogeneous database migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"homogeneous database migration\", \"Migrating your source database to a target database that shares the same database engine (for example, Microsoft SQL Server to Amazon RDS for SQL Server). Homogeneous migration is typically part of a rehosting or replatforming effort. You can use native database utilities to migrate the schema.\"],\\n      \"expected_answer\": \"Homogeneous database migration involves moving a source database to a target database with the same engine (e.g., SQL Server to Amazon RDS for SQL Server), typically for rehosting or replatforming, using native database utilities for schema migration.\",\\n      \"query\": \"What is homogeneous database migration?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"RACI matrix\", \"A matrix that defines the roles and responsibilities for all parties involved in migration activities and cloud operations. The matrix name is derived from the responsibility types defined in the matrix: responsible (R), accountable (A), consulted (C), and informed (I).\"],\\n      \"expected_answer\": \"A RACI matrix defines roles and responsibilities for migration and cloud operations, with its name derived from the responsibility types: Responsible (R), Accountable (A), Consulted (C), and Informed (I).\",\\n      \"query\": \"What is a RACI matrix?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"RASCI matrix\", \"If you include support, the matrix is called a RASCI matrix, and if you exclude it, it\\'s called a RACI matrix.\"],\\n      \"expected_answer\": \"If the support (S) type is included, the matrix is called a RASCI matrix; otherwise, it\\'s a RACI matrix.\",\\n      \"query\": \"What is the difference between a RACI and RASCI matrix?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"security control\", \"A technical or administrative guardrail that prevents, detects, or reduces the ability of a threat actor to exploit a security vulnerability. There are four primary types of security controls: preventative, detective, responsive, and proactive.\"],\\n      \"expected_answer\": \"A security control is a technical or administrative guardrail that prevents, detects, or reduces a threat actor\\'s ability to exploit a security vulnerability. The four primary types are preventative, detective, responsive, and proactive.\",\\n      \"query\": \"What is a security control and what are its primary types?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"preventative control\", \"A security control that is designed to prevent an event from occurring. These controls are a first line of defense to help prevent unauthorized access or unwanted changes to your network.\"],\\n      \"expected_answer\": \"A preventative control is a security control designed to prevent an event from occurring, serving as a first line of defense against unauthorized access or unwanted network changes.\",\\n      \"query\": \"What is a preventative control?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"detective control\", \"A security control that is designed to detect, log, and alert after an event has occurred. These controls are a second line of defense, alerting you to security events that bypassed the preventative controls in place.\"],\\n      \"expected_answer\": \"A detective control is a security control designed to detect, log, and alert after an event, acting as a second line of defense by notifying of security events that bypassed preventative controls.\",\\n      \"query\": \"What is a detective control?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"responsive control\", \"A security control that is designed to drive remediation of adverse events or deviations from your security baseline.\"],\\n      \"expected_answer\": \"A responsive control is a security control designed to remediate adverse events or deviations from a security baseline.\",\\n      \"query\": \"What is a responsive control?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"proactive control\", \"A security control designed to prevent the deployment of noncompliant resources. These controls scan resources before they are provisioned. If the resource is not compliant with the control, then it isnât provisioned.\"],\\n      \"expected_answer\": \"A proactive control is a security control designed to prevent the deployment of noncompliant resources by scanning them before provisioning and blocking non-compliant ones.\",\\n      \"query\": \"What is a proactive control?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"security by design\", \"A system engineering approach that takes security into account through the whole development process.\"],\\n      \"expected_answer\": \"Security by design is a system engineering approach that integrates security considerations throughout the entire development process.\",\\n      \"query\": \"What is security by design?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"privacy by design\", \"A system engineering approach that takes privacy into account through the whole development process.\"],\\n      \"expected_answer\": \"Privacy by design is a system engineering approach that integrates privacy considerations throughout the entire development process.\",\\n      \"query\": \"What is privacy by design?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"anonymization\", \"The process of permanently deleting personal information in a dataset. Anonymization can help protect personal privacy. Anonymized data is no longer considered to be personal data.\"],\\n      \"expected_answer\": \"Anonymization is the process of permanently deleting personal information from a dataset to protect privacy, rendering the data no longer personal.\",\\n      \"query\": \"What is anonymization?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"pseudonymization\", \"The process of replacing personal identifiers in a dataset with placeholder values. Pseudonymization can help protect personal privacy. Pseudonymized data is still considered to be personal data.\"],\\n      \"expected_answer\": \"Pseudonymization is the process of replacing personal identifiers in a dataset with placeholder values to protect privacy, though the data is still considered personal.\",\\n      \"query\": \"What is pseudonymization?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"bad bot\", \"A bot that is intended to disrupt or cause harm to individuals or organizations.\"],\\n      \"expected_answer\": \"A bad bot is a bot designed to disrupt or harm individuals or organizations.\",\\n      \"query\": \"What is a bad bot?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"botnet\", \"Networks of bots that are infected by malware and are under the control of a single party, known as a bot herder or bot operator.\"],\\n      \"expected_answer\": \"A botnet is a network of malware-infected bots controlled by a single party, known as a bot herder or operator.\",\\n      \"query\": \"What is a botnet?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"malware\", \"Software that is designed to compromise computer security or privacy. Malware might disrupt computer systems, leak sensitive information, or gain unauthorized access.\"],\\n      \"expected_answer\": \"Malware is software designed to compromise computer security or privacy, potentially disrupting systems, leaking sensitive information, or gaining unauthorized access.\",\\n      \"query\": \"What is malware?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"ransomware\", \"A malicious software that is designed to block access to a computer system or data until a payment is made.\"],\\n      \"expected_answer\": \"Ransomware is malicious software designed to block access to a computer system or data until a payment is made.\",\\n      \"query\": \"What is ransomware?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"zero-day exploit\", \"An attack, typically malware, that takes advantage of a zero-day vulnerability.\"],\\n      \"expected_answer\": \"A zero-day exploit is an attack, usually malware, that leverages a zero-day vulnerability.\",\\n      \"query\": \"What is a zero-day exploit?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"vulnerability\", \"A software or hardware flaw that compromises the security of the system.\"],\\n      \"expected_answer\": \"A vulnerability is a software or hardware flaw that compromises system security.\",\\n      \"query\": \"What is a vulnerability?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"configuration drift\", \"For a workload, a configuration change from the expected state. It might cause the workload to become noncompliant, and it\\'s typically gradual and unintentional.\"],\\n      \"expected_answer\": \"Configuration drift is a gradual, unintentional configuration change in a workload from its expected state, potentially leading to noncompliance.\",\\n      \"query\": \"What is configuration drift?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"drift detection\", \"Tracking deviations from a baselined configuration. For example, you can use AWS CloudFormation to detect drift in system resources, or you can use AWS Control Tower to detect changes in your landing zone that might affect compliance with governance requirements.\"],\\n      \"expected_answer\": \"Drift detection tracks deviations from a baselined configuration, such as using AWS CloudFormation for system resources or AWS Control Tower for landing zone changes affecting governance compliance.\",\\n      \"query\": \"What is drift detection?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"conformance pack\", \"A collection of AWS Config rules and remediation actions that you can assemble to customize your compliance and security checks. You can deploy a conformance pack as a single entity in an AWS account and Region, or across an organization, by using a YAML template.\"],\\n      \"expected_answer\": \"A conformance pack is a collection of AWS Config rules and remediation actions customizable for compliance and security checks, deployable as a single entity in an AWS account/Region or across an organization via a YAML template.\",\\n      \"query\": \"What is a conformance pack?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"IT service management (ITSM)\", \"Activities associated with designing, implementing, managing, and supporting IT services for an organization.\"],\\n      \"expected_answer\": \"IT service management (ITSM) encompasses activities related to designing, implementing, managing, and supporting IT services for an organization.\",\\n      \"query\": \"What is IT service management (ITSM)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"IT information library (ITIL)\", \"A set of best practices for delivering IT services and aligning these services with business requirements. ITIL provides the foundation for ITSM.\"],\\n      \"expected_answer\": \"ITIL (IT information library) is a set of best practices for delivering IT services and aligning them with business requirements, forming the foundation for ITSM.\",\\n      \"query\": \"What is ITIL?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"cloud operating model\", \"In an IT organization, the operating model that is used to build, mature, and optimize one or more cloud environments.\"],\\n      \"expected_answer\": \"A cloud operating model is the framework used by an IT organization to build, mature, and optimize cloud environments.\",\\n      \"query\": \"What is a cloud operating model?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"AWS Cloud Adoption Framework (AWS CAF)\", \"A framework of guidelines and best practices from AWS to help organizations develop an efficient and effective plan to move successfully to the cloud.\"],\\n      \"expected_answer\": \"The AWS Cloud Adoption Framework (AWS CAF) is an AWS framework providing guidelines and best practices to help organizations develop efficient and effective plans for successful cloud migration.\",\\n      \"query\": \"What is the AWS Cloud Adoption Framework (AWS CAF)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"AWS Workload Qualification Framework (AWS WQF)\", \"A tool that evaluates database migration workloads, recommends migration strategies, and provides work estimates. AWS WQF is included with AWS Schema Conversion Tool (AWS SCT).\"],\\n      \"expected_answer\": \"AWS Workload Qualification Framework (AWS WQF) is a tool included with AWS Schema Conversion Tool (AWS SCT) that evaluates database migration workloads, recommends strategies, and provides work estimates.\",\\n      \"query\": \"What is the AWS Workload Qualification Framework (AWS WQF)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"cloud stages of adoption\", \"The four phases that organizations typically go through when they migrate to the AWS Cloud: Project, Foundation, Migration, Re-invention.\"],\\n      \"expected_answer\": \"The four cloud stages of adoption are Project, Foundation, Migration, and Re-invention.\",\\n      \"query\": \"What are the four cloud stages of adoption?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"business continuity planning (BCP)\", \"A plan that addresses the potential impact of a disruptive event, such as a large-scale migration, on operations and enables a business to resume operations quickly.\"],\\n      \"expected_answer\": \"Business continuity planning (BCP) is a plan addressing the potential impact of disruptive events on operations, enabling quick business resumption.\",\\n      \"query\": \"What is business continuity planning (BCP)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"application portfolio\", \"A collection of detailed information about each application used by an organization, including the cost to build and maintain the application, and its business value.\"],\\n      \"expected_answer\": \"An application portfolio is a collection of detailed information about an organization\\'s applications, including their build/maintenance costs and business value.\",\\n      \"query\": \"What is an application portfolio?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"portfolio assessment\", \"A process of discovering, analyzing, and prioritizing the application portfolio in order to plan the migration.\"],\\n      \"expected_answer\": \"Portfolio assessment is the process of discovering, analyzing, and prioritizing an application portfolio to plan migration.\",\\n      \"query\": \"What is portfolio assessment?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"CMDB\", \"A repository that stores and manages information about a database and its IT environment, including both hardware and software components and their configurations.\"],\\n      \"expected_answer\": \"A CMDB is a repository that stores and manages information about a database and its IT environment, including hardware, software, and configurations.\",\\n      \"query\": \"What is a CMDB?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"code repository\", \"A location where source code and other assets, such as documentation, samples, and scripts, are stored and updated through version control processes.\"],\\n      \"expected_answer\": \"A code repository is a location where source code and other assets like documentation, samples, and scripts are stored and updated via version control.\",\\n      \"query\": \"What is a code repository?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"version control\", \"Processes and tools that track changes, such as changes to source code in a repository.\"],\\n      \"expected_answer\": \"Version control refers to processes and tools that track changes, such as those in source code repositories.\",\\n      \"query\": \"What is version control?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"deployment\", \"The process of making an application, new features, or code fixes available in the target environment. Deployment involves implementing changes in a code base and then building and running that code base in the applicationâs environments.\"],\\n      \"expected_answer\": \"Deployment is the process of making an application, new features, or code fixes available in the target environment, involving implementing changes in a codebase, then building and running it in the application\\'s environments.\",\\n      \"query\": \"What is deployment?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"release\", \"In a deployment process, the act of promoting changes to a production environment.\"],\\n      \"expected_answer\": \"In a deployment process, a release is the act of promoting changes to a production environment.\",\\n      \"query\": \"What is a release in a deployment process?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"infrastructure\", \"All of the resources and assets contained within an application\\'s environment.\"],\\n      \"expected_answer\": \"Infrastructure refers to all resources and assets within an application\\'s environment.\",\\n      \"query\": \"What is infrastructure?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"mechanism\", \"A complete process in which you create a tool, drive adoption of the tool, and then inspect the results in order to make adjustments. A mechanism is a cycle that reinforces and improves itself as it operates.\"],\\n      \"expected_answer\": \"A mechanism is a complete process involving tool creation, adoption, and result inspection for adjustments, forming a self-reinforcing and improving cycle.\",\\n      \"query\": \"What is a mechanism in the context of operations?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"operational-level agreement (OLA)\", \"An agreement that clarifies what functional IT groups promise to deliver to each other, to support a service-level agreement (SLA).\"],\\n      \"expected_answer\": \"An operational-level agreement (OLA) clarifies what functional IT groups promise to deliver to each other to support a service-level agreement (SLA).\",\\n      \"query\": \"What is an OLA?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"service-level agreement (SLA)\", \"An agreement that clarifies what an IT team promises to deliver to their customers, such as service uptime and performance.\"],\\n      \"expected_answer\": \"A service-level agreement (SLA) is an agreement clarifying what an IT team promises to deliver to customers, including service uptime and performance.\",\\n      \"query\": \"What is an SLA?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"service-level indicator (SLI)\", \"A measurement of a performance aspect of a service, such as its error rate, availability, or throughput.\"],\\n      \"expected_answer\": \"A service-level indicator (SLI) measures a service\\'s performance aspect, such as error rate, availability, or throughput.\",\\n      \"query\": \"What is an SLI?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"service-level objective (SLO)\", \"A target metric that represents the health of a service, as measured by a service-level indicator.\"],\\n      \"expected_answer\": \"A service-level objective (SLO) is a target metric indicating a service\\'s health, measured by a service-level indicator.\",\\n      \"query\": \"What is an SLO?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"workstream\", \"Functional groups in a migration project that are responsible for a specific set of tasks. Each workstream is independent but supports the other workstreams in the project.\"],\\n      \"expected_answer\": \"A workstream refers to independent functional groups in a migration project, each responsible for specific tasks while supporting other workstreams.\",\\n      \"query\": \"What is a workstream in a migration project?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"responsible, accountable, consulted, informed (RACI) matrix\", \"The matrix name is derived from the responsibility types defined in the matrix: responsible (R), accountable (A), consulted (C), and informed (I).\"],\\n      \"expected_answer\": \"The RACI matrix derives its name from the responsibility types: Responsible (R), Accountable (A), Consulted (C), and Informed (I).\",\\n      \"query\": \"What do the letters in RACI stand for?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"binary classification\", \"A process that predicts a binary outcome (one of two possible classes). For example, your ML model might need to predict problems such as \\\\\"Is this email spam or not spam?\\\\\" or \\\\\"Is this product a book or a car?\\\\\"\"],\\n      \"expected_answer\": \"Binary classification predicts one of two possible outcomes, such as whether an email is spam or not spam.\",\\n      \"query\": \"What is binary classification?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"multiclass classification\", \"A process that helps generate predictions for multiple classes (predicting one of more than two outcomes). For example, an ML model might ask \\\\\"Is this product a book, car, or phone?\\\\\" or \\\\\"Which product category is most interesting to this customer?\\\\\"\"],\\n      \"expected_answer\": \"Multiclass classification generates predictions for more than two outcomes, such as identifying a product as a book, car, or phone.\",\\n      \"query\": \"What is multiclass classification?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"regression\", \"An ML technique that predicts a numeric value. For example, to solve the problem of \\\\\"What price will this house sell for?\\\\\" an ML model could use a linear regression model to predict a houseâs sale price based on known facts about the house (for example, the square footage).\"],\\n      \"expected_answer\": \"Regression is an ML technique that predicts a numeric value, such as a house\\'s sale price based on its square footage.\",\\n      \"query\": \"What is regression in machine learning?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"target variable\", \"The value that you are trying to predict in supervised ML. This is also referred to as an outcome variable. For example, in a manufacturing setting the target variable could be a product defect.\"],\\n      \"expected_answer\": \"The target variable, also known as an outcome variable, is the value being predicted in supervised machine learning, such as a product defect in manufacturing.\",\\n      \"query\": \"What is a target variable in supervised ML?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"features\", \"The input data that you use to make a prediction. For example, in a manufacturing context, features could be images that are periodically captured from the manufacturing line.\"],\\n      \"expected_answer\": \"Features are the input data used for predictions, such as images captured from a manufacturing line.\",\\n      \"query\": \"What are features in machine learning?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"feature importance\", \"How significant a feature is for a modelâs predictions. This is usually expressed as a numerical score that can be calculated through various techniques, such as Shapley Additive Explanations (SHAP) and integrated gradients.\"],\\n      \"expected_answer\": \"Feature importance quantifies a feature\\'s significance for a model\\'s predictions, typically expressed as a numerical score calculated using techniques like SHAP and integrated gradients.\",\\n      \"query\": \"What is feature importance?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"feature transformation\", \"To optimize data for the ML process, including enriching data with additional sources, scaling values, or extracting multiple sets of information from a single data field. This enables the ML model to benefit from the data.\"],\\n      \"expected_answer\": \"Feature transformation optimizes data for ML by enriching it with additional sources, scaling values, or extracting multiple information sets from a single field, enabling the ML model to benefit from the data.\",\\n      \"query\": \"What is feature transformation?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"interpretability\", \"A characteristic of a machine learning model that describes the degree to which a human can understand how the model\\'s predictions depend on its inputs.\"],\\n      \"expected_answer\": \"Interpretability describes how well a human can understand a machine learning model\\'s predictions based on its inputs.\",\\n      \"query\": \"What is interpretability in machine learning?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"uncertainty\", \"A concept that refers to imprecise, incomplete, or unknown information that can undermine the reliability of predictive ML models. There are two types of uncertainty: Epistemic uncertainty is caused by limited, incomplete data, whereas aleatoric uncertainty is caused by the noise and randomness inherent in the data.\"],\\n      \"expected_answer\": \"Uncertainty refers to imprecise, incomplete, or unknown information that can undermine ML model reliability. It has two types: epistemic (due to limited data) and aleatoric (due to inherent data noise/randomness).\",\\n      \"query\": \"What is uncertainty in ML models, and what are its two types?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"cold cache\", \"A buffer cache that is empty, not well populated, or contains stale or irrelevant data. This affects performance because the database instance must read from the main memory or disk, which is slower than reading from the buffer cache.\"],\\n      \"expected_answer\": \"A cold cache is an empty, poorly populated, or stale buffer cache, impacting performance as the database must read slower from main memory or disk instead of the cache.\",\\n      \"query\": \"What is a cold cache?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"warm cache\", \"A buffer cache that contains current, relevant data that is frequently accessed. The database instance can read from the buffer cache, which is faster than reading from the main memory or disk.\"],\\n      \"expected_answer\": \"A warm cache is a buffer cache containing current, frequently accessed data, allowing the database instance to read faster from it than from main memory or disk.\",\\n      \"query\": \"What is a warm cache?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"buffer cache\", \"The memory area where the most frequently accessed data is stored.\"],\\n      \"expected_answer\": \"The buffer cache is the memory area where the most frequently accessed data is stored.\",\\n      \"query\": \"What is a buffer cache?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"database definition language (DDL)\", \"Statements or commands for creating or modifying the structure of tables and objects in a database.\"],\\n      \"expected_answer\": \"Database Definition Language (DDL) consists of statements or commands used to create or modify the structure of tables and objects in a database.\",\\n      \"query\": \"What is DDL?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"database manipulation language (DML)\", \"Statements or commands for modifying (inserting, updating, and deleting) information in a database.\"],\\n      \"expected_answer\": \"Database Manipulation Language (DML) consists of statements or commands for modifying (inserting, updating, and deleting) information in a database.\",\\n      \"query\": \"What is DML?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"predicate\", \"A query condition that returns true or false, commonly located in a WHERE clause.\"],\\n      \"expected_answer\": \"A predicate is a query condition, typically found in a WHERE clause, that returns true or false.\",\\n      \"query\": \"What is a predicate in a database query?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"predicate pushdown\", \"A database query optimization technique that filters the data in the query before transfer. This reduces the amount of data that must be retrieved and processed from the relational database, and it improves query performance.\"],\\n      \"expected_answer\": \"Predicate pushdown is a database query optimization technique that filters data before transfer, reducing data retrieval and processing from the relational database, thereby improving query performance.\",\\n      \"query\": \"What is predicate pushdown?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"window function\", \"A SQL function that performs a calculation on a group of rows that relate in some way to the current record. Window functions are useful for processing tasks, such as calculating a moving average or accessing the value of rows based on the relative position of the current row.\"],\\n      \"expected_answer\": \"A window function is a SQL function that calculates over a group of rows related to the current record, useful for tasks like moving averages or accessing row values based on relative position.\",\\n      \"query\": \"What is a window function in SQL?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"aggregate function\", \"A SQL function that operates on a group of rows and calculates a single return value for the group. Examples of aggregate functions include SUM and MAX.\"],\\n      \"expected_answer\": \"An aggregate function is a SQL function that operates on a group of rows to calculate a single return value for that group, such as SUM or MAX.\",\\n      \"query\": \"What is an aggregate function in SQL?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"endianness\", \"The order in which bytes are stored in computer memory. Big-endian systems store the most significant byte first. Little-endian systems store the least significant byte first.\"],\\n      \"expected_answer\": \"Endianness refers to the byte order in computer memory: big-endian stores the most significant byte first, while little-endian stores the least significant byte first.\",\\n      \"query\": \"What is endianness?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"big-endian system\", \"A system that stores the most significant byte first.\"],\\n      \"expected_answer\": \"A big-endian system stores the most significant byte first.\",\\n      \"query\": \"What is a big-endian system?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"little-endian system\", \"A system that stores the least significant byte first.\"],\\n      \"expected_answer\": \"A little-endian system stores the least significant byte first.\",\\n      \"query\": \"What is a little-endian system?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"vacuuming\", \"A database maintenance operation that involves cleaning up after incremental updates to reclaim storage and improve performance.\"],\\n      \"expected_answer\": \"Vacuuming is a database maintenance operation that cleans up after incremental updates to reclaim storage and improve performance.\",\\n      \"query\": \"What is vacuuming in database maintenance?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"private hosted zones\", \"A container that holds information about how you want Amazon Route 53 to respond to DNS queries for a domain and its subdomains within one or more VPCs.\"],\\n      \"expected_answer\": \"Private hosted zones are containers in Amazon Route 53 that define how DNS queries for a domain and its subdomains are resolved within one or more VPCs.\",\\n      \"query\": \"What are private hosted zones?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"Region\", \"A collection of AWS resources in a geographic area. Each AWS Region is isolated and independent of the others to provide fault tolerance, stability, and resilience.\"],\\n      \"expected_answer\": \"An AWS Region is a collection of AWS resources in a geographic area, isolated and independent for fault tolerance, stability, and resilience.\",\\n      \"query\": \"What is an AWS Region?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"origin access control (OAC)\", \"In CloudFront, an enhanced option for restricting access to secure your Amazon Simple Storage Service (Amazon S3) content. OAC supports all S3 buckets in all AWS Regions, server-side encryption with AWS KMS (SSE-KMS), and dynamic PUT and DELETE requests to the S3 bucket.\"],\\n      \"expected_answer\": \"Origin Access Control (OAC) in CloudFront is an enhanced option for securing Amazon S3 content by restricting access. It supports all S3 buckets across all AWS Regions, server-side encryption with AWS KMS, and dynamic PUT/DELETE requests to S3 buckets.\",\\n      \"query\": \"What is Origin Access Control (OAC) in CloudFront?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"origin access identity (OAI)\", \"In CloudFront, an option for restricting access to secure your Amazon S3 content. When you use OAI, CloudFront creates a principal that Amazon S3 can authenticate with. Authenticated principals can access content in an S3 bucket only through a specific CloudFront distribution.\"],\\n      \"expected_answer\": \"Origin Access Identity (OAI) in CloudFront restricts access to Amazon S3 content by creating a principal that S3 authenticates with, allowing access only through a specific CloudFront distribution.\",\\n      \"query\": \"What is Origin Access Identity (OAI) in CloudFront?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"geo blocking\", \"In Amazon CloudFront, an option to prevent users in specific countries from accessing content distributions. You can use an allow list or block list to specify approved and banned countries.\"],\\n      \"expected_answer\": \"Geo blocking, or geographic restrictions, in Amazon CloudFront is an option to prevent users in specific countries from accessing content distributions, using allow or block lists.\",\\n      \"query\": \"What is geo blocking in Amazon CloudFront?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"attribute-based access control (ABAC)\", \"The practice of creating fine-grained permissions based on user attributes, such as department, job role, and team name.\"],\\n      \"expected_answer\": \"Attribute-based access control (ABAC) is the practice of creating fine-grained permissions based on user attributes like department, job role, and team name.\",\\n      \"query\": \"What is attribute-based access control (ABAC)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"fine-grained access control (FGAC)\", \"The use of multiple conditions to allow or deny an access request.\"],\\n      \"expected_answer\": \"Fine-grained access control (FGAC) uses multiple conditions to allow or deny an access request.\",\\n      \"query\": \"What is fine-grained access control (FGAC)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"row and column access control (RCAC)\", \"The use of basic, flexible SQL expressions that have defined access rules. RCAC consists of row permissions and column masks.\"],\\n      \"expected_answer\": \"Row and column access control (RCAC) uses basic, flexible SQL expressions with defined access rules, comprising row permissions and column masks.\",\\n      \"query\": \"What is row and column access control (RCAC)?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"identity-based policy\", \"A policy attached to one or more IAM principals that defines their permissions within the AWS Cloud environment.\"],\\n      \"expected_answer\": \"An identity-based policy is attached to IAM principals, defining their permissions within the AWS Cloud environment.\",\\n      \"query\": \"What is an identity-based policy?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"resource-based policy\", \"A policy attached to a resource, such as an Amazon S3 bucket, an endpoint, or an encryption key. This type of policy specifies which principals are allowed access, supported actions, and any other conditions that must be met.\"],\\n      \"expected_answer\": \"A resource-based policy is attached to a resource (e.g., S3 bucket, endpoint, encryption key), specifying allowed principals, actions, and conditions for access.\",\\n      \"query\": \"What is a resource-based policy?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"permissions boundary\", \"An IAM management policy that is attached to IAM principals to set the maximum permissions that the user or role can have.\"],\\n      \"expected_answer\": \"A permissions boundary is an IAM management policy attached to IAM principals, setting the maximum permissions for that user or role.\",\\n      \"query\": \"What is a permissions boundary?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"system prompt\", \"A technique for providing context, instructions, or guidelines to an LLM to direct its behavior. System prompts help set context and establish rules for interactions with users.\"],\\n      \"expected_answer\": \"A system prompt is a technique for providing context, instructions, or guidelines to an LLM to direct its behavior, helping to set context and establish rules for user interactions.\",\\n      \"query\": \"What is a system prompt for an LLM?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"prompt chaining\", \"Using the output of one LLM prompt as the input for the next prompt to generate better responses. This technique is used to break down a complex task into subtasks, or to iteratively refine or expand a preliminary response.\"],\\n      \"expected_answer\": \"Prompt chaining uses the output of one LLM prompt as input for the next, improving responses by breaking down complex tasks or iteratively refining/expanding preliminary responses.\",\\n      \"query\": \"What is prompt chaining?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"managed services\", \"AWS services for which AWS operates the infrastructure layer, the operating system, and platforms, and you access the endpoints to store and retrieve data. Amazon Simple Storage Service (Amazon S3) and Amazon DynamoDB are examples of managed services. These are also known as abstracted services.\"],\\n      \"expected_answer\": \"Managed services are AWS services where AWS operates the infrastructure, OS, and platforms, while users access endpoints for data storage and retrieval. Examples include Amazon S3 and Amazon DynamoDB, also known as abstracted services.\",\\n      \"query\": \"What are managed services in AWS?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"abstracted services\", \"See managed services.\"],\\n      \"expected_answer\": \"Abstracted services are also known as managed services.\",\\n      \"query\": \"What are abstracted services?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"business capability\", \"What a business does to generate value (for example, sales, customer service, or marketing). Microservices architectures and development decisions can be driven by business capabilities.\"],\\n      \"expected_answer\": \"A business capability is what a business does to generate value, such as sales or customer service, and can drive microservices architectures and development decisions.\",\\n      \"query\": \"What is a business capability?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"brownfield strategy\", \"The existing infrastructure in your environment. When adopting a brownfield strategy for a system architecture, you design the architecture around the constraints of the current systems and infrastructure.\"],\\n      \"expected_answer\": \"A brownfield strategy involves designing system architecture around the constraints of existing infrastructure in your environment.\",\\n      \"query\": \"What is a brownfield strategy?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"greenfield strategy\", \"The absence of existing infrastructure in a new environment. When adopting a greenfield strategy for a system architecture, you can select all new technologies without the restriction of compatibility with existing infrastructure, also known as brownfield.\"],\\n      \"expected_answer\": \"A greenfield strategy involves designing system architecture in a new environment without existing infrastructure constraints, allowing selection of all new technologies.\",\\n      \"query\": \"What is a greenfield strategy?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"inbound (ingress) VPC\", \"In an AWS multi-account architecture, a VPC that accepts, inspects, and routes network connections from outside an application.\"],\\n      \"expected_answer\": \"In an AWS multi-account architecture, an inbound (ingress) VPC accepts, inspects, and routes network connections originating from outside an application.\",\\n      \"query\": \"What is an inbound (ingress) VPC?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"outbound (egress) VPC\", \"In an AWS multi-account architecture, a VPC that handles network connections that are initiated from within an application.\"],\\n      \"expected_answer\": \"In an AWS multi-account architecture, an outbound (egress) VPC handles network connections initiated from within an application.\",\\n      \"query\": \"What is an outbound (egress) VPC?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"inspection VPC\", \"In an AWS multi-account architecture, a centralized VPC that manages inspections of network traffic between VPCs (in the same or different AWS Regions), the internet, and on-premises networks.\"],\\n      \"expected_answer\": \"In an AWS multi-account architecture, an inspection VPC is a centralized VPC that manages network traffic inspections between VPCs (within or across regions), the internet, and on-premises networks.\",\\n      \"query\": \"What is an inspection VPC?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"member account\", \"All AWS accounts other than the management account that are part of an organization in AWS Organizations. An account can be a member of only one organization at a time.\"],\\n      \"expected_answer\": \"A member account is any AWS account, excluding the management account, that belongs to an organization in AWS Organizations. An account can only be a member of one organization at a time.\",\\n      \"query\": \"What is a member account in AWS Organizations?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"delegated administrator\", \"In AWS Organizations, a compatible service can register an AWS member account to administer the organizationâs accounts and manage permissions for that service. This account is called the delegated administrator for that service.\"],\\n      \"expected_answer\": \"In AWS Organizations, a delegated administrator is an AWS member account registered by a compatible service to administer the organization\\'s accounts and manage permissions for that service.\",\\n      \"query\": \"What is a delegated administrator in AWS Organizations?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"trusted access\", \"Granting permissions to a service that you specify to perform tasks in your organization in AWS Organizations and in its accounts on your behalf. The trusted service creates a service-linked role in each account, when that role is needed, to perform management tasks for you.\"],\\n      \"expected_answer\": \"Trusted access grants specified services permissions to perform tasks in your AWS Organizations organization and its accounts on your behalf, creating service-linked roles as needed for management tasks.\",\\n      \"query\": \"What is trusted access in AWS Organizations?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"organization trail\", \"A trail thatâs created by AWS CloudTrail that logs all events for all AWS accounts in an organization in AWS Organizations. This trail is created in each AWS account thatâs part of the organization and tracks the activity in each account.\"],\\n      \"expected_answer\": \"An organization trail is an AWS CloudTrail trail that logs all events for all AWS accounts within an AWS Organizations organization, created in each account to track its activity.\",\\n      \"query\": \"What is an organization trail in AWS CloudTrail?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"break-glass access\", \"In exceptional circumstances and through an approved process, a quick means for a user to gain access to an AWS account that they don\\'t typically have permissions to access.\"],\\n      \"expected_answer\": \"Break-glass access is a quick, approved means for a user to gain access to an AWS account they typically lack permissions for, used in exceptional circumstances.\",\\n      \"query\": \"What is break-glass access?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"behavior graph\", \"A unified, interactive view of resource behavior and interactions over time. You can use a behavior graph with Amazon Detective to examine failed logon attempts, suspicious API calls, and similar actions.\"],\\n      \"expected_answer\": \"A behavior graph provides a unified, interactive view of resource behavior and interactions over time, usable with Amazon Detective to examine failed logons, suspicious API calls, and similar actions.\",\\n      \"query\": \"What is a behavior graph?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"security response automation\", \"A predefined and programmed action that is designed to automatically respond to or remediate a security event. These automations serve as detective or responsive security controls that help you implement AWS security best practices.\"],\\n      \"expected_answer\": \"Security response automation is a predefined, programmed action designed to automatically respond to or remediate security events, serving as detective or responsive security controls to implement AWS security best practices.\",\\n      \"query\": \"What is security response automation?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"security information and event management (SIEM) system\", \"Tools and services that combine security information management (SIM) and security event management (SEM) systems. A SIEM system collects, monitors, and analyzes data from servers, networks, devices, and other sources to detect threats and security breaches, and to generate alerts.\"],\\n      \"expected_answer\": \"A SIEM system combines SIM and SEM tools/services to collect, monitor, and analyze data from various sources (servers, networks, devices) to detect threats, security breaches, and generate alerts.\",\\n      \"query\": \"What is a SIEM system?\"\\n    },\\n    {\\n      \"citations\": [\"Glossary\", \"synthetic testing\", \"Testing a system in a way that simulates user interactions to detect potential issues or to monitor performance. You can use Amazon CloudWatch Synthetics to create these tests.\"],\\n      \"expected_answer\": \"Synthetic testing simulates user interactions to detect issues or monitor performance, and can be created using Amazon CloudWatch Synthetics.\",\\n      \"query\": \"What is synthetic testing?\"\\n    }\\n  ]\\n}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "class TestCase(BaseModel):\n",
    "    query: str\n",
    "    expected_answer: str\n",
    "    citations: List[str]\n",
    "\n",
    "class OutputSchema(BaseModel):\n",
    "    test_cases: List[TestCase]\n",
    "\n",
    "# Load document context\n",
    "with open(\"../texts/cloud-design-patterns.txt\", \"r\") as f:\n",
    "    document_context = f.read()\n",
    "\n",
    "# Prepare system prompt\n",
    "system_prompt = \"\"\"\n",
    "You are a world-class assistant specializing in generating comprehensive test cases for Retrieval-Augmented Generation (RAG) systems.\n",
    "\n",
    "Given the full context of a document, your task is to create a diverse set of at least 100 queries to rigorously evaluate the RAG system. Each query should target specific facts, details, or concepts from the context, and once specific queries are exhausted, include broader or inferential questions that still relate to the content.\n",
    "\n",
    "For each test case, provide:\n",
    "- `query`: A clear, concise question that could be asked of the RAG system.\n",
    "- `expected_answer`: The precise answer that should be returned, based strictly on the context.\n",
    "- `citations`: A list of references (quotes, chapter titles, or locations) from the context that support the answer.\n",
    "\n",
    "Ensure queries cover a wide range of topics, including factual recall, reasoning, chronology, character analysis, and thematic understanding. Avoid duplication and strive for variety in question types.\n",
    "\n",
    "Return the output as a JSON object with a list of test cases in the following format:\n",
    "{{\n",
    "    \"test_cases\": [\n",
    "        {{\n",
    "            \"query\": \"...\",\n",
    "            \"expected_answer\": \"...\",\n",
    "            \"citations\": [\"...\"]\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "# Set up Gemini LLM with LangChain\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    thinking_budget=0,\n",
    "    response_mime_type=\"application/json\",\n",
    "    response_schema=OutputSchema.schema()\n",
    ")\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\"],\n",
    "    template=system_prompt\n",
    ")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Generate the test set\n",
    "result = chain.run(context=document_context)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1379d64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'citations': ['Copyright \\nÂ© 2024 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.'], 'expected_answer': 'The copyright for the AWS Prescriptive Guidance: Cloud design patterns, architectures, and implementations is held by Amazon Web Services, Inc. and/or its affiliates, as of 2024.', 'query': 'Who holds the copyright for this document and when was it issued?'}, {'citations': ['Table of Contents', 'Introduction .............................................................................................................................................. 1'], 'expected_answer': 'The Introduction section of the document starts on page 1.', 'query': 'On which page does the Introduction section begin?'}, {'citations': ['Table of Contents', 'Anti-corruption layer pattern .................................................................................................................... 3'], 'expected_answer': 'The Anti-corruption layer pattern section starts on page 3.', 'query': 'What page number is the Anti-corruption layer pattern discussed on?'}, {'citations': ['Table of Contents', 'API routing patterns ................................................................................................................................ 10'], 'expected_answer': 'API routing patterns are covered starting on page 10.', 'query': 'Where can I find information about API routing patterns?'}, {'citations': ['Table of Contents', 'Circuit breaker pattern ............................................................................................................................ 19'], 'expected_answer': 'The Circuit breaker pattern begins on page 19.', 'query': 'What is the starting page for the Circuit breaker pattern?'}, {'citations': ['Table of Contents', 'Event sourcing pattern ............................................................................................................................ 26'], 'expected_answer': 'The Event sourcing pattern is detailed starting on page 26.', 'query': 'Which page introduces the Event sourcing pattern?'}, {'citations': ['Table of Contents', 'Hexagonal architecture pattern ............................................................................................................... 34'], 'expected_answer': 'The Hexagonal architecture pattern starts on page 34.', 'query': 'On what page does the Hexagonal architecture pattern section start?'}, {'citations': ['Table of Contents', 'Publish-subscribe pattern ........................................................................................................................ 43'], 'expected_answer': 'The Publish-subscribe pattern is discussed from page 43 onwards.', 'query': 'What page number covers the Publish-subscribe pattern?'}, {'citations': ['Table of Contents', 'Retry with backoff pattern ....................................................................................................................... 49'], 'expected_answer': 'The Retry with backoff pattern can be found starting on page 49.', 'query': 'Where can I find the Retry with backoff pattern?'}, {'citations': ['Table of Contents', 'Saga patterns ........................................................................................................................................... 53'], 'expected_answer': 'Saga patterns are introduced on page 53.', 'query': 'What page number is associated with Saga patterns?'}, {'citations': ['Table of Contents', 'Scatter-gather pattern ............................................................................................................................. 69'], 'expected_answer': 'The Scatter-gather pattern starts on page 69.', 'query': 'On which page does the Scatter-gather pattern begin?'}, {'citations': ['Table of Contents', 'Strangler fig pattern ................................................................................................................................ 78'], 'expected_answer': 'The Strangler fig pattern is covered from page 78.', 'query': 'Where can I find information about the Strangler fig pattern?'}, {'citations': ['Table of Contents', 'Transactional outbox pattern .................................................................................................................. 91'], 'expected_answer': 'The Transactional outbox pattern is discussed starting on page 91.', 'query': 'What page number details the Transactional outbox pattern?'}, {'citations': ['Table of Contents', 'Glossary ................................................................................................................................................... 105'], 'expected_answer': 'The Glossary starts on page 105.', 'query': 'What is the starting page for the Glossary?'}, {'citations': ['Cloud design patterns, architectures, and implementations', 'Anitha Deenadayalan, Amazon Web Services (AWS)'], 'expected_answer': 'The author of \"Cloud design patterns, architectures, and implementations\" is Anitha Deenadayalan from Amazon Web Services (AWS).', 'query': 'Who is the author of this guide?'}, {'citations': ['May 2024 (document history)'], 'expected_answer': 'The document history indicates May 2024.', 'query': 'When was the document last updated according to its history?'}, {'citations': ['This guide provides guidance for implementing commonly used modernization design patterns by using AWS services.'], 'expected_answer': 'This guide provides guidance for implementing commonly used modernization design patterns by using AWS services.', 'query': 'What is the primary purpose of this guide?'}, {'citations': ['An increasing number of modern applications are designed by using microservices architectures to achieve scalability, improve release velocity, reduce the scope of impact for changes, and reduce regression.'], 'expected_answer': 'Modern applications increasingly use microservices architectures to achieve scalability, improve release velocity, reduce the scope of impact for changes, and reduce regression.', 'query': 'Why are modern applications increasingly designed with microservices architectures?'}, {'citations': ['This leads to improved developer productivity and increased agility, better innovation, and an increased focus on business needs. Microservices architectures also support the use of the best technology for the service and the database, and promote polyglot code and polyglot persistence.'], 'expected_answer': 'Microservices architectures lead to improved developer productivity, increased agility, better innovation, an increased focus on business needs, support for the best technology for services and databases, and promotion of polyglot code and polyglot persistence.', 'query': 'What are the benefits of microservices architectures?'}, {'citations': ['Traditionally, monolithic applications run in a single process, use one data store, and run on servers that scale vertically. In comparison, modern microservice applications are fine-grained, have independent fault domains, run as services across the network, and can use more than one data store depending on the use case.'], 'expected_answer': 'Monolithic applications traditionally run in a single process, use one data store, and scale vertically, whereas modern microservice applications are fine-grained, have independent fault domains, run as services across the network, and can use multiple data stores.', 'query': 'How do monolithic applications differ from modern microservice applications?'}, {'citations': ['The services scale horizontally, and a single transaction might span multiple databases. Development teams must focus on network communication, polyglot persistence, horizontal scaling, eventual consistency, and transaction handling across the data stores when developing applications by using microservices architectures.'], 'expected_answer': 'When developing applications with microservices architectures, development teams must focus on network communication, polyglot persistence, horizontal scaling, eventual consistency, and transaction handling across data stores.', 'query': 'What key aspects must development teams focus on when using microservices architectures?'}, {'citations': ['Therefore, modernization patterns are critical for solving commonly occurring problems in modern application development, and they help accelerate software delivery.'], 'expected_answer': 'Modernization patterns are critical for solving common problems in modern application development and accelerate software delivery.', 'query': 'What is the importance of modernization patterns?'}, {'citations': ['This guide provides a technical reference for cloud architects, technical leads, application and business owners, and developers who want to choose the right cloud architecture for design patterns based on well-architected best practices.'], 'expected_answer': 'This guide serves as a technical reference for cloud architects, technical leads, application and business owners, and developers to choose appropriate cloud architecture for design patterns based on well-architected best practices.', 'query': 'Who is the target audience for this guide?'}, {'citations': ['The guide covers the following patterns: - Anti-corruption layer - API routing patterns: - Hostname routing - Path routing - HTTP header routing - Circuit breaker - Event sourcing - Hexagonal architecture - Publish-subscribe - Retry with backoff - Saga patterns: - Saga choreography - Saga orchestration - Scatter-gather - Strangler fig - Transactional outbox'], 'expected_answer': 'The guide covers Anti-corruption layer, API routing patterns (Hostname, Path, HTTP header), Circuit breaker, Event sourcing, Hexagonal architecture, Publish-subscribe, Retry with backoff, Saga patterns (Choreography, Orchestration), Scatter-gather, Strangler fig, and Transactional outbox.', 'query': 'List all the design patterns covered in this guide.'}, {'citations': ['Targeted business outcomes', 'Design and implement reliable, secure, operationally efficient architectures that are optimized for cost and performance.'], 'expected_answer': 'One targeted business outcome is to design and implement reliable, secure, operationally efficient architectures that are optimized for cost and performance.', 'query': 'What is one of the targeted business outcomes of using these patterns?'}, {'citations': ['Targeted business outcomes', 'Reduce the cycle time for use cases that require these patterns, so you can focus on organization-specific challenges instead.'], 'expected_answer': 'Another targeted business outcome is to reduce the cycle time for use cases requiring these patterns, allowing focus on organization-specific challenges.', 'query': 'How do these patterns help with cycle time?'}, {'citations': ['Targeted business outcomes', 'Accelerate development by standardizing pattern implementations by using AWS services.'], 'expected_answer': 'The patterns accelerate development by standardizing their implementations using AWS services.', 'query': 'How can development be accelerated using these patterns?'}, {'citations': ['Targeted business outcomes', 'Help your developers build modern applications without inheriting technical debt.'], 'expected_answer': 'These patterns help developers build modern applications without inheriting technical debt.', 'query': 'What is the benefit for developers when using these patterns?'}, {'citations': ['Anti-corruption layer pattern', 'Intent', 'The anti-corruption layer (ACL) pattern acts as a mediation layer that translates domain model semantics from one system to another system.'], 'expected_answer': 'The anti-corruption layer (ACL) pattern serves as a mediation layer that translates domain model semantics between different systems.', 'query': 'What is the intent of the Anti-corruption layer (ACL) pattern?'}, {'citations': ['Anti-corruption layer pattern', 'Motivation', 'During the migration process, when a monolithic application is migrated into microservices, there might be changes in the domain model semantics of the newly migrated service. When the features within the monolith are required to call these microservices, the calls should be routed to the migrated service without requiring any changes to the calling services.'], 'expected_answer': 'The motivation for the ACL pattern arises during migration when a monolithic application is moved to microservices, and changes in domain model semantics of the new service require calls to be routed without altering existing calling services.', 'query': 'What motivates the use of the ACL pattern during migration?'}, {'citations': ['Anti-corruption layer pattern', 'Applicability', 'Your existing monolithic application has to communicate with a function that has been migrated into a microservice, and the migrated service domain model and semantics differ from the original feature.'], 'expected_answer': 'The ACL pattern is applicable when an existing monolithic application needs to communicate with a microservice that has a different domain model and semantics.', 'query': 'When should the ACL pattern be considered for use?'}, {'citations': ['Anti-corruption layer pattern', 'Issues and considerations', 'Team dependencies: When different services in a system are owned by different teams, the new domain model semantics in the migrated services can lead to changes in the calling systems. However, teams might not be able to make these changes in a coordinated way, because they might have other priorities. ACL decouples the callees and translates the calls to match the semantics of the new services, thus avoiding the need for callers to make changes in the current system.'], 'expected_answer': 'ACL addresses team dependencies by decoupling callees and translating calls to match new service semantics, preventing the need for callers to make changes in the current system, especially when different teams own different services.', 'query': 'How does ACL address team dependencies?'}, {'citations': ['Anti-corruption layer pattern', 'Issues and considerations', 'Operational overhead: The ACL pattern requires additional effort to operate and maintain. This work includes integrating ACL with monitoring and alerting tools, the release process, and continuous integration and continuous delivery (CI/CD) processes.'], 'expected_answer': 'The ACL pattern introduces operational overhead due to the additional effort required for its operation and maintenance, including integration with monitoring, alerting, release processes, and CI/CD.', 'query': 'What is a potential operational challenge with the ACL pattern?'}, {'citations': ['Anti-corruption layer pattern', 'Issues and considerations', 'Single point of failure: Any failures in the ACL can make the target service unreachable, causing application issues. To mitigate this issue, you should build in retry capabilities and circuit breakers. See the retry with backoff and circuit breaker patterns to understand more about these options.'], 'expected_answer': 'ACL can become a single point of failure, making the target service unreachable. This can be mitigated by building in retry capabilities and circuit breakers.', 'query': 'What is a risk associated with ACL and how can it be mitigated?'}, {'citations': ['Anti-corruption layer pattern', 'Issues and considerations', 'Latency: The additional layer can introduce latency due to the conversion of requests from one interface to another. We recommend that you define and test performance tolerance in applications that are sensitive to response time before you deploy ACL into production environments.'], 'expected_answer': 'The additional layer of ACL can introduce latency due to request conversion. It is recommended to define and test performance tolerance in response-time-sensitive applications before deploying ACL to production.', 'query': 'Does ACL introduce latency, and what is recommended to address it?'}, {'citations': ['Anti-corruption layer pattern', 'Implementation', \"You can implement ACL inside your monolithic application as a class that's specific to the service that's being migrated, or as an independent service.\"], 'expected_answer': 'ACL can be implemented either as a service-specific class within the monolithic application or as an independent service.', 'query': 'How can the ACL be implemented?'}, {'citations': ['Anti-corruption layer pattern', 'Implementation using AWS services', 'The user microservice is migrated out of the ASP.NET monolithic application and deployed as an AWS Lambda function on AWS. Calls to the Lambda function are routed through Amazon API Gateway. ACL is deployed in the monolith to translate the call to adapt to the semantics of the user microservice.'], 'expected_answer': \"In the AWS implementation, the user microservice is deployed as an AWS Lambda function, with calls routed through Amazon API Gateway. The ACL is deployed within the monolith to translate calls to match the user microservice's semantics.\", 'query': 'How is the ACL implemented using AWS services in the example?'}, {'citations': ['Anti-corruption layer pattern', 'Sample code', 'The following code snippet provides the changes to the original service and the implementation of UserServiceACL.cs. When a request is received, the original user service calls the ACL. The ACL converts the source object to match the interface of the newly migrated service, calls the service, and returns the response to the caller.'], 'expected_answer': \"The sample code shows how the original user service calls the ACL, which then converts the source object to match the new service's interface, calls the service, and returns the response.\", 'query': 'What does the sample code for ACL demonstrate?'}, {'citations': ['Anti-corruption layer pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/anti-corruption-layer-pattern.'], 'expected_answer': 'A complete implementation of the sample architecture for the Anti-corruption layer pattern is available in the GitHub repository at https://github.com/aws-samples/anti-corruption-layer-pattern.', 'query': 'Where can I find the GitHub repository for the ACL pattern sample architecture?'}, {'citations': ['API routing patterns', 'There are three major methods for exposing HTTP APIs to upstream consumers by using hostnames and paths: Hostname routing, Path routing, Header-based routing.'], 'expected_answer': 'The three major methods for exposing HTTP APIs to upstream consumers are Hostname routing, Path routing, and Header-based routing.', 'query': 'What are the three main methods for exposing HTTP APIs?'}, {'citations': ['API routing patterns', 'Hostname routing pattern', 'Routing by hostname is a mechanism for isolating API services by giving each API its own hostname; for example, service-a.api.example.com or service-a.example.com.'], 'expected_answer': 'Hostname routing isolates API services by assigning a unique hostname to each API, such as service-a.api.example.com.', 'query': 'What is hostname routing?'}, {'citations': ['API routing patterns', 'Hostname routing pattern', 'Typical use case', 'Routing by using hostnames reduces the amount of friction in releases, because nothing is shared between service teams. Teams are responsible for managing everything from DNS entries to service operations in production.'], 'expected_answer': 'A typical use case for hostname routing is to reduce release friction by ensuring nothing is shared between service teams, making them responsible for their own DNS entries and production operations.', 'query': 'What is a typical use case for hostname routing?'}, {'citations': ['API routing patterns', 'Hostname routing pattern', 'Pros', 'Hostname routing is by far the most straightforward and scalable method for HTTP API routing. You can use any relevant AWS service to build an architecture that follows this methodâyou can create an architecture with Amazon API Gateway, AWS AppSync, Application Load Balancers, Amazon Elastic Compute Cloud (Amazon EC2), or any other HTTP-compliant service.'], 'expected_answer': 'Hostname routing is the most straightforward and scalable method for HTTP API routing, compatible with AWS services like Amazon API Gateway, AWS AppSync, Application Load Balancers, and Amazon EC2.', 'query': 'What are the advantages of hostname routing?'}, {'citations': ['API routing patterns', 'Hostname routing pattern', 'Cons', 'When you use hostname routing, your consumers have to remember different hostnames to interact with each API that you expose. You can mitigate this issue by providing a client SDK. However, client SDKs come with their own set of challenges.'], 'expected_answer': 'A disadvantage of hostname routing is that consumers must remember different hostnames for each API, which can be mitigated by providing a client SDK, though SDKs have their own challenges.', 'query': 'What is a disadvantage of hostname routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'Routing by paths is the mechanism of grouping multiple or all APIs under the same hostname, and using a request URI to isolate services; for example, api.example.com/service-a or api.example.com/service-b.'], 'expected_answer': 'Path routing groups multiple or all APIs under the same hostname, using a request URI to isolate services, such as api.example.com/service-a.', 'query': 'What is path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'Typical use case', 'Most teams opt for this method because they want a simple architectureâa developer has to remember only one URL such as api.example.com to interact with the HTTP API. API documentation is often easier to digest because it is often kept together instead of being split across different portals or PDFs.'], 'expected_answer': 'Path-based routing is typically chosen for its simplicity, as developers only need to remember one URL, and API documentation is easier to manage when kept together.', 'query': 'Why do most teams prefer path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'HTTP service reverse proxy', 'You can use an HTTP server such as NGINX to create dynamic routing configurations. In a Kubernetes architecture, you can also create an ingress rule to match a path to a service.'], 'expected_answer': 'An HTTP server like NGINX can be used to create dynamic routing configurations for path routing, and in Kubernetes, an ingress rule can match a path to a service.', 'query': 'How can an HTTP service reverse proxy be used for path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'HTTP service reverse proxy', 'Pros', 'The ultimate aim of the HTTP service reverse proxy method is to create a scalable and manageable approach to unifying APIs into a single domain so it appears coherent to any API consumer. This approach also enables your service teams to deploy and manage their own APIs, with minimal overhead after deployment.'], 'expected_answer': 'The HTTP service reverse proxy method aims to unify APIs into a single domain for consumers, enabling service teams to deploy and manage their APIs with minimal overhead.', 'query': 'What are the pros of using an HTTP service reverse proxy?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'HTTP service reverse proxy', 'Cons', 'The major downside of this approach is the extensive testing and management of infrastructure components that are required, although this might not be an issue if you have site reliability engineering (SRE) teams in place.'], 'expected_answer': 'The main drawback of the HTTP service reverse proxy method is the extensive testing and infrastructure management required, though SRE teams can mitigate this.', 'query': 'What is a major downside of the HTTP service reverse proxy method?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'API Gateway', \"The Amazon API Gateway service (REST APIs and HTTP APIs) can route traffic in a way that's similar to the HTTP service reverse proxy method. Using an API gateway in HTTP proxy mode provides a simple way to wrap many services into an entry point to the top-level subdomain api.example.com, and then proxy requests to the nested service; for example, billing.internal.api.example.com.\"], 'expected_answer': 'Amazon API Gateway can route traffic similarly to an HTTP service reverse proxy, providing a simple way to wrap multiple services into a single entry point and proxy requests to nested services.', 'query': 'How does Amazon API Gateway function in path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'API Gateway', 'Pros', 'For control over more complex workflows, such as changing request attributes, REST APIs expose the Apache Velocity Template Language (VTL) to allow you to modify the request and response. REST APIs can provide additional benefits such as these: Auth N/Z with AWS Identity and Access Management (IAM), Amazon Cognito, or AWS Lambda authorizers, AWS X-Ray for tracing, Integration with AWS WAF, Basic rate limiting, Usage tokens for bucketing consumers into different tiers.'], 'expected_answer': \"API Gateway's REST APIs offer control over complex workflows, allowing request/response modification via VTL, and provide benefits like Auth N/Z with IAM/Cognito/Lambda authorizers, AWS X-Ray tracing, AWS WAF integration, basic rate limiting, and usage tokens.\", 'query': 'What are the benefits of using API Gateway for path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'API Gateway', 'Cons', 'At high volumes, cost might be an issue for some users.'], 'expected_answer': 'At high volumes, the cost of using API Gateway can be a concern for some users.', 'query': 'What is a potential drawback of API Gateway at high volumes?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'CloudFront', 'You can use the dynamic origin selection feature in Amazon CloudFront to conditionally select an origin (a service) to forward the request. You can use this feature to route a number of services through a single hostname such as api.example.com.'], 'expected_answer': \"Amazon CloudFront's dynamic origin selection feature allows conditional selection of a service to forward requests, enabling routing of multiple services through a single hostname like api.example.com.\", 'query': 'How can CloudFront be used for path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'CloudFront', 'Typical use case', 'The routing logic lives as code within the Lambda@Edge function, so it supports highly customizable routing mechanisms such as A/B testing, canary releases, feature flagging, and path rewriting.'], 'expected_answer': 'A typical use case for CloudFront in path routing involves using Lambda@Edge functions for routing logic, enabling customizable mechanisms like A/B testing, canary releases, feature flagging, and path rewriting.', 'query': 'What are typical use cases for CloudFront in path routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'CloudFront', 'Pros', 'If you require caching API responses, this method is good way to unify a collection of services behind a single endpoint. It is a cost-effective method to unify collections of APIs.'], 'expected_answer': 'CloudFront is a cost-effective method for unifying API collections behind a single endpoint, especially when caching API responses is required.', 'query': 'What are the advantages of using CloudFront for API routing?'}, {'citations': ['API routing patterns', 'Path routing pattern', 'CloudFront', 'Cons', 'This method supports a maximum of 250 origins (services) that can be unified. This limit is sufficient for most deployments, but it might cause issues with a large number of APIs as you grow your portfolio of services.'], 'expected_answer': 'A limitation of CloudFront for API routing is its maximum support for 250 origins, which might become an issue for large API portfolios.', 'query': 'What is a limitation of CloudFront for API routing?'}, {'citations': ['API routing patterns', 'HTTP header routing pattern', 'Header-based routing enables you to target the correct service for each request by specifying an HTTP header in the HTTP request. For example, sending the header x-service-a-action: get-thing would enable you to get thing from Service A.'], 'expected_answer': \"Header-based routing targets the correct service for each request by specifying an HTTP header, such as 'x-service-a-action: get-thing' to access Service A.\", 'query': 'What is HTTP header routing?'}, {'citations': ['API routing patterns', 'HTTP header routing pattern', 'Pros', 'Configuration changes require minimal effort and can be automated easily. This method is also flexible and supports creative ways to expose only specific operations you would want from a service.'], 'expected_answer': 'HTTP header routing offers minimal effort for configuration changes, easy automation, flexibility, and supports exposing specific service operations creatively.', 'query': 'What are the pros of HTTP header routing?'}, {'citations': ['API routing patterns', 'HTTP header routing pattern', 'Cons', 'As with the hostname routing method, HTTP header routing assumes that you have full control over the client and can manipulate custom HTTP headers. Proxies, content delivery networks (CDNs), and load balancers can limit the header size.'], 'expected_answer': 'Similar to hostname routing, HTTP header routing requires full client control to manipulate custom HTTP headers, and proxies, CDNs, and load balancers may limit header size.', 'query': 'What are the cons of HTTP header routing?'}, {'citations': ['Circuit breaker pattern', 'Intent', 'The circuit breaker pattern can prevent a caller service from retrying a call to another service (callee) when the call has previously caused repeated timeouts or failures. The pattern is also used to detect when the callee service is functional again.'], 'expected_answer': 'The circuit breaker pattern prevents a caller service from retrying calls to a callee service after repeated timeouts or failures, and it also detects when the callee service becomes functional again.', 'query': 'What is the intent of the Circuit breaker pattern?'}, {'citations': ['Circuit breaker pattern', 'Motivation', 'When multiple microservices collaborate to handle requests, one or more services might become unavailable or exhibit high latency. When complex applications use microservices, an outage in one microservice can lead to application failure.'], 'expected_answer': 'The circuit breaker pattern is motivated by the need to prevent application failures caused by unavailable or high-latency microservices in complex, collaborative microservice architectures.', 'query': 'What is the motivation behind the Circuit breaker pattern?'}, {'citations': ['Circuit breaker pattern', 'Applicability', \"Use this pattern when: The caller service makes a call that is most likely going to fail. A high latency exhibited by the callee service (for example, when database connections are slow) causes timeouts to the callee service. The caller service makes a synchronous call, but the callee service isn't available or exhibits high latency.\"], 'expected_answer': 'The circuit breaker pattern is applicable when a caller service makes calls likely to fail, when the callee service exhibits high latency causing timeouts, or when a synchronous call is made to an unavailable or high-latency callee service.', 'query': 'When should the Circuit breaker pattern be used?'}, {'citations': ['Circuit breaker pattern', 'Issues and considerations', 'Service agnostic implementation: To prevent code bloat, we recommend that you implement the circuit breaker object in a microservice-agnostic and API-driven way.'], 'expected_answer': \"To avoid code bloat, it's recommended to implement the circuit breaker object in a microservice-agnostic and API-driven manner.\", 'query': 'What is recommended for implementing the circuit breaker object?'}, {'citations': ['Circuit breaker pattern', 'Issues and considerations', 'Observability: The application should have logging set up to identify the calls that fail when the circuit breaker is open.'], 'expected_answer': 'For observability, the application should have logging configured to identify failed calls when the circuit breaker is open.', 'query': 'What is important for observability in the circuit breaker pattern?'}, {'citations': ['Circuit breaker pattern', 'Implementation', 'High-level architecture', 'In the following example, the caller is the order service and the callee is the payment service. When there are no failures, the order service routes all calls to the payment service by the circuit breaker.'], 'expected_answer': 'In the high-level architecture example, the order service acts as the caller and the payment service as the callee. When no failures occur, the circuit breaker routes all calls from the order service to the payment service.', 'query': 'Describe the high-level architecture of the Circuit breaker pattern.'}, {'citations': ['Circuit breaker pattern', 'Implementation using AWS services', 'The sample solution uses express workflows in AWS Step Functions to implement the circuit breaker pattern. The Step Functions state machine lets you configure the retry capabilities and decision-based control flow required for the pattern implementation.'], 'expected_answer': \"The sample solution uses AWS Step Functions' express workflows to implement the circuit breaker pattern, leveraging its state machine for retry capabilities and decision-based control flow.\", 'query': 'How is the Circuit breaker pattern implemented using AWS services?'}, {'citations': ['Circuit breaker pattern', 'Implementation using AWS services', 'The solution also uses an Amazon DynamoDB table as the data store to track the circuit status. This can be replaced with an in-memory datastore such as Amazon ElastiCache (Redis OSS) for better performance.'], 'expected_answer': 'The solution uses an Amazon DynamoDB table to track circuit status, but for better performance, it can be replaced with an in-memory datastore like Amazon ElastiCache (Redis OSS).', 'query': 'What data store is used to track circuit status in the AWS implementation, and what alternative is suggested for better performance?'}, {'citations': ['Circuit breaker pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/circuit-breaker-netcore-blog.'], 'expected_answer': 'A complete implementation of the sample architecture for the Circuit breaker pattern is available in the GitHub repository at https://github.com/aws-samples/circuit-breaker-netcore-blog.', 'query': 'Where can I find the GitHub repository for the Circuit breaker pattern sample architecture?'}, {'citations': ['Event sourcing pattern', 'Intent', 'In event-driven architectures, the event sourcing pattern stores the events that result in a state change in a data store. This helps to capture and maintain a complete history of state changes, and promotes auditability, traceability, and the ability to analyze past states.'], 'expected_answer': 'The event sourcing pattern stores events that cause state changes in a data store, capturing a complete history for auditability, traceability, and analysis of past states in event-driven architectures.', 'query': 'What is the intent of the Event sourcing pattern?'}, {'citations': ['Event sourcing pattern', 'Motivation', 'Multiple microservices can collaborate to handle requests, and they communicate through events. These events can result in a change in state (data). Storing event objects in the order in which they occur provides valuable information on the current state of the data entity and additional information about how it arrived at that state.'], 'expected_answer': 'The motivation for event sourcing is to capture and store event objects in chronological order, providing a complete history of state changes and how the current state was reached, especially in microservice collaborations.', 'query': 'What is the motivation behind the Event sourcing pattern?'}, {'citations': ['Event sourcing pattern', 'Applicability', \"Use the event sourcing pattern when: An immutable history of the events that occur in an application is required for tracking. Polyglot data projections are required from a single source of truth (SSOT). Point-in time reconstruction of the application state is needed. Long-term storage of application state isn't required, but you might want to reconstruct it as needed. Workloads have different read and write volumes. For example, you have write-intensive workloads that don't require real-time processing. Change data capture (CDC) is required to analyze the application performance and other metrics. Audit data is required for all events that happen in a system for reporting and compliance purposes. You want to derive what-if scenarios by changing (inserting, updating, or deleting) events during the replay process to determine the possible end state.\"], 'expected_answer': \"The event sourcing pattern is applicable when an immutable event history is needed, polyglot data projections from a single source of truth are required, point-in-time state reconstruction is necessary, long-term state storage isn't a primary need but reconstruction is, workloads have varying read/write volumes (e.g., write-intensive without real-time processing), change data capture is needed for performance analysis, audit data is required for reporting/compliance, or when deriving what-if scenarios by replaying events.\", 'query': 'When should the Event sourcing pattern be used?'}, {'citations': ['Event sourcing pattern', 'Issues and considerations', 'Optimistic concurrency control: This pattern stores every event that causes a state change in the system. Multiple users or services can try to update the same piece of data at the same time, causing event collisions. To solve this issue, you can implement strategies to detect and resolve event collisions.'], 'expected_answer': 'Event sourcing faces optimistic concurrency control issues when multiple users/services update the same data simultaneously, leading to event collisions. Strategies to detect and resolve these collisions should be implemented.', 'query': 'What is a key issue with optimistic concurrency control in event sourcing?'}, {'citations': ['Event sourcing pattern', 'Issues and considerations', 'Complexity: Implementing event sourcing necessitates a shift in mindset from traditional CRUD operations to event-driven thinking. The replay process, which is used to restore the system to its original state, can be complex in order to ensure data idempotency. Event storage, backups, and snapshots can also add additional complexity.'], 'expected_answer': 'Implementing event sourcing is complex due to the shift to event-driven thinking, the intricate replay process for data idempotency, and the added complexity of event storage, backups, and snapshots.', 'query': 'What adds to the complexity of implementing event sourcing?'}, {'citations': ['Event sourcing pattern', 'Issues and considerations', 'Eventual consistency: Data projections derived from the events are eventually consistent because of the latency in updating data by using the command query responsibility segregation (CQRS) pattern or materialized views.'], 'expected_answer': 'Data projections from events in event sourcing are eventually consistent due to latency in updating data via CQRS or materialized views.', 'query': 'Why is eventual consistency a consideration in event sourcing?'}, {'citations': ['Event sourcing pattern', 'Implementation', 'High-level architecture', 'Events are logged into an immutable, append-only, chronologically ordered repository or data store known as the event store. Each state change is treated as an individual event object.'], 'expected_answer': 'In event sourcing, events are logged into an immutable, append-only, chronologically ordered event store, where each state change is an individual event object.', 'query': \"How are events stored in the Event sourcing pattern's high-level architecture?\"}, {'citations': ['Event sourcing pattern', 'Implementation using AWS services', 'In the following architecture, Amazon Kinesis Data Streams is used as the event store. This service captures and manages application changes as events, and offers a high-throughput and real-time data streaming solution.'], 'expected_answer': 'In the provided architecture, Amazon Kinesis Data Streams is used as the event store, offering a high-throughput, real-time data streaming solution for capturing and managing application changes as events.', 'query': 'Which AWS service is used as the event store in the example architecture for event sourcing?'}, {'citations': ['Event sourcing pattern', 'Implementation using AWS services', \"To implement the event sourcing pattern on AWS, you can also use services such as Amazon EventBridge and Amazon Managed Streaming for Apache Kafka (Amazon MSK) based on your application's needs.\"], 'expected_answer': 'Besides Amazon Kinesis Data Streams, Amazon EventBridge and Amazon Managed Streaming for Apache Kafka (Amazon MSK) can also be used to implement the event sourcing pattern on AWS, depending on application needs.', 'query': 'What other AWS services can be used for event sourcing besides Kinesis Data Streams?'}, {'citations': ['Hexagonal architecture pattern', 'Intent', 'The hexagonal architecture pattern, which is also known as the ports and adapters pattern, was proposed by Dr. Alistair Cockburn in 2005. It aims to create loosely coupled architectures where application components can be tested independently, with no dependencies on data stores or user interfaces (UIs).'], 'expected_answer': 'The hexagonal architecture pattern, also known as the ports and adapters pattern, was proposed by Dr. Alistair Cockburn in 2005. Its intent is to create loosely coupled architectures, enabling independent testing of application components without dependencies on data stores or UIs.', 'query': 'What is the intent of the Hexagonal architecture pattern and who proposed it?'}, {'citations': ['Hexagonal architecture pattern', 'Motivation', 'The hexagonal architecture pattern is used to isolate business logic (domain logic) from related infrastructure code, such as code to access a database or external APIs. This pattern is useful for creating loosely coupled business logic and infrastructure code for AWS Lambda functions that require integration with external services.'], 'expected_answer': 'The hexagonal architecture pattern is motivated by the need to isolate business logic from infrastructure code, particularly for AWS Lambda functions integrating with external services, to create loosely coupled components.', 'query': 'What is the motivation behind the Hexagonal architecture pattern?'}, {'citations': ['Hexagonal architecture pattern', 'Applicability', \"Use the hexagonal architecture pattern when: You want to decouple your application architecture to create components that can be fully tested. Multiple types of clients can use the same domain logic. Your UI and database components require periodical technology refreshes that don't affect application logic. Your application requires multiple input providers and output consumers, and customizing the application logic leads to code complexity and lack of extensibility.\"], 'expected_answer': 'The hexagonal architecture pattern is applicable when decoupling application architecture for testability, when multiple client types use the same domain logic, when UI/database components need technology refreshes without affecting application logic, or when an application requires multiple input/output providers and consumers, where custom logic leads to complexity.', 'query': 'When should the Hexagonal architecture pattern be applied?'}, {'citations': ['Hexagonal architecture pattern', 'Issues and considerations', 'Testability: By design, a hexagonal architecture uses abstractions for inputs and outputs. Therefore, writing unit tests and testing in isolation become easier because of the inherent loose coupling.'], 'expected_answer': 'Hexagonal architecture enhances testability by using abstractions for inputs and outputs, which facilitates easier unit testing and isolated testing due to its inherent loose coupling.', 'query': 'How does hexagonal architecture improve testability?'}, {'citations': ['Hexagonal architecture pattern', 'Implementation', 'Ports are technology-agnostic entry points into an application component. These custom interfaces determine the interface that allows external actors to communicate with the application component, regardless of who or what implements the interface.'], 'expected_answer': 'Ports in hexagonal architecture are technology-agnostic entry points into an application component, defining custom interfaces for external actors to communicate with the component.', 'query': 'What are ports in hexagonal architecture?'}, {'citations': ['Hexagonal architecture pattern', 'Implementation', 'Adapters interact with the application through a port by using a specific technology. Adapters plug into these ports, receive data from or provide data to the ports, and transform the data for further processing.'], 'expected_answer': 'Adapters in hexagonal architecture interact with the application through a port using specific technology, plugging into ports to receive or provide data and transform it for processing.', 'query': 'What are adapters in hexagonal architecture?'}, {'citations': ['Hexagonal architecture pattern', 'Implementation using AWS services', 'AWS Lambda functions often contain both business logic and database integration code, which are tightly coupled to meet an objective. You can use the hexagonal architecture pattern to separate business logic from infrastructure code.'], 'expected_answer': 'The hexagonal architecture pattern can be used with AWS Lambda functions to separate business logic from infrastructure code, addressing the common tight coupling between them.', 'query': 'How can hexagonal architecture be applied to AWS Lambda functions?'}, {'citations': ['Hexagonal architecture pattern', 'Sample code', 'The sample code in this section shows how to implement the domain model by using Lambda, separate it from infrastructure code (such as the code to access DynamoDB), and implement unit testing for the function.'], 'expected_answer': 'The sample code demonstrates implementing a domain model with Lambda, separating it from infrastructure code like DynamoDB access, and unit testing the function.', 'query': 'What does the sample code for hexagonal architecture illustrate?'}, {'citations': ['Hexagonal architecture pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/aws-lambda-domain-model-sample.'], 'expected_answer': 'A complete implementation of the sample architecture for the Hexagonal architecture pattern is available in the GitHub repository at https://github.com/aws-samples/aws-lambda-domain-model-sample.', 'query': 'Where can I find the GitHub repository for the Hexagonal architecture pattern sample architecture?'}, {'citations': ['Publish-subscribe pattern', 'Intent', 'The publish-subscribe pattern, which is also known as the pub-sub pattern, is a messaging pattern that decouples a message sender (publisher) from interested receivers (subscribers). This pattern implements asynchronous communications by publishing messages or events through an intermediary known as a message broker or router (message infrastructure).'], 'expected_answer': 'The publish-subscribe (pub-sub) pattern is a messaging pattern that decouples publishers from subscribers, enabling asynchronous communication through a message broker or router.', 'query': 'What is the intent of the Publish-subscribe pattern?'}, {'citations': ['Publish-subscribe pattern', 'Motivation', 'In distributed architectures, system components often need to provide information to other components as events take place within the system. The publish-subscribe pattern separates concerns so that applications can focus on their core capabilities while the message infrastructure handles communication responsibilities such as message routing and reliable delivery.'], 'expected_answer': 'The publish-subscribe pattern is motivated by the need to separate concerns in distributed architectures, allowing applications to focus on core capabilities while the message infrastructure handles communication responsibilities like routing and reliable delivery.', 'query': 'What is the motivation behind the Publish-subscribe pattern?'}, {'citations': ['Publish-subscribe pattern', 'Applicability', \"Use the publish-subscribe pattern when: Parallel processing is required if a single message has different workflows. Broadcasting messages to multiple subscribers and real-time responses from receivers aren't required. The system or application can tolerate eventual consistency for data or state. The application or component has to communicate with other applications or services that might use different languages, protocols, or platforms.\"], 'expected_answer': 'The publish-subscribe pattern is applicable when parallel processing of a single message with different workflows is needed, broadcasting messages to multiple subscribers without real-time responses is acceptable, the system tolerates eventual consistency, or when an application needs to communicate with services using different languages, protocols, or platforms.', 'query': 'When should the Publish-subscribe pattern be used?'}, {'citations': ['Publish-subscribe pattern', 'Issues and considerations', \"Subscriber availability: The publisher isn't aware whether the subscribers are listening, and they might not be. Published messages are transient in nature and can result in being dropped if the subscribers aren't available.\"], 'expected_answer': 'A consideration for the publish-subscribe pattern is subscriber availability; publishers are unaware if subscribers are listening, and transient messages can be dropped if subscribers are unavailable.', 'query': 'What is a key issue regarding subscriber availability in pub-sub?'}, {'citations': ['Publish-subscribe pattern', 'Implementation', 'High-level architecture', 'In a publish-subscribe pattern, the asynchronous messaging subsystem known as a message broker or router keeps track of subscriptions. When a producer publishes an event, the messaging infrastructure sends a message to each consumer.'], 'expected_answer': 'In the publish-subscribe pattern, a message broker or router manages subscriptions, and when a producer publishes an event, the messaging infrastructure sends a message to each consumer.', 'query': 'How does the high-level architecture of the Publish-subscribe pattern work?'}, {'citations': ['Publish-subscribe pattern', 'Implementation using AWS services', 'Amazon SNS is a fully managed publisher-subscriber service that provides application-to-application (A2A) messaging to decouple distributed applications. It also provides application-to-person (A2P) messaging for sending SMS, email, and other push notifications.'], 'expected_answer': 'Amazon SNS is a fully managed publisher-subscriber service that offers A2A messaging for decoupling distributed applications and A2P messaging for sending SMS, email, and push notifications.', 'query': 'What is Amazon SNS and what does it provide?'}, {'citations': ['Publish-subscribe pattern', 'Implementation using AWS services', 'Amazon SNS provides two types of topics: standard and first in, first out (FIFO).'], 'expected_answer': 'Amazon SNS provides two types of topics: standard and First-In, First-Out (FIFO).', 'query': 'What are the two types of topics provided by Amazon SNS?'}, {'citations': ['Publish-subscribe pattern', 'Implementation using AWS services', 'You can use Amazon EventBridge when you need more complex routing of messages from multiple producers across different protocols to subscribed consumers, or direct and fan-out subscriptions. EventBridge also supports content-based routing, filtering, sequencing, and splitting or aggregation.'], 'expected_answer': 'Amazon EventBridge is suitable for complex message routing from multiple producers across different protocols to subscribed consumers, supporting direct and fan-out subscriptions, content-based routing, filtering, sequencing, and splitting/aggregation.', 'query': 'When should Amazon EventBridge be used for publish-subscribe?'}, {'citations': ['Retry with backoff pattern', 'Intent', 'The retry with backoff pattern improves application stability by transparently retrying operations that fail due to transient errors.'], 'expected_answer': 'The retry with backoff pattern aims to improve application stability by transparently retrying operations that fail due to transient errors.', 'query': 'What is the intent of the Retry with backoff pattern?'}, {'citations': ['Retry with backoff pattern', 'Motivation', 'In distributed architectures, transient errors might be caused by service throttling, temporary loss of network connectivity, or temporary service unavailability. Automatically retrying operations that fail because of these transient errors improves the user experience and application resilience.'], 'expected_answer': 'The motivation for the retry with backoff pattern is to improve user experience and application resilience by automatically retrying operations that fail due to transient errors like service throttling, temporary network loss, or service unavailability in distributed architectures.', 'query': 'What motivates the use of the Retry with backoff pattern?'}, {'citations': ['Retry with backoff pattern', 'Applicability', 'Use the retry with backoff pattern when: Your services frequently throttle the request to prevent overload, resulting in a 429 Too many requests exception to the calling process. The network is an unseen participant in distributed architectures, and temporary network issues result in failures. The service being called is temporarily unavailable, causing failures. Frequent retries might cause service degradation unless you introduce a backoff timeout by using this pattern.'], 'expected_answer': 'The retry with backoff pattern is applicable when services frequently throttle requests (429 errors), temporary network issues cause failures, or the called service is temporarily unavailable, to prevent service degradation from frequent retries.', 'query': 'When should the Retry with backoff pattern be used?'}, {'citations': ['Retry with backoff pattern', 'Issues and considerations', 'Idempotency: If multiple calls to the method have the same effect as a single call on the system state, the operation is considered idempotent. Operations should be idempotent when you use the retry with backoff pattern. Otherwise, partial updates might corrupt the system state.'], 'expected_answer': 'When using the retry with backoff pattern, operations should be idempotent to prevent partial updates from corrupting the system state if multiple calls have the same effect as a single call.', 'query': 'Why is idempotency important for the Retry with backoff pattern?'}, {'citations': ['Retry with backoff pattern', 'Implementation', 'High-level architecture', \"The following diagram illustrates how Service A can retry the calls to Service B until a successful response is returned. If Service B doesn't return a successful response after a few tries, Service A can stop retrying and return a failure to its caller.\"], 'expected_answer': 'The high-level architecture shows Service A retrying calls to Service B until a successful response is received. If Service B fails to respond successfully after several attempts, Service A stops retrying and returns a failure.', 'query': 'Describe the high-level architecture of the Retry with backoff pattern.'}, {'citations': ['Retry with backoff pattern', 'Implementation using AWS services', 'The sample solution uses express workflows in AWS Step Functions to implement the circuit breaker pattern. The Step Functions state machine lets you configure the retry capabilities and decision-based control flow required for the pattern implementation.'], 'expected_answer': \"The sample solution uses AWS Step Functions' express workflows to implement the circuit breaker pattern, leveraging its state machine for retry capabilities and decision-based control flow.\", 'query': 'How is the Retry with backoff pattern implemented using AWS services?'}, {'citations': ['Retry with backoff pattern', 'Implementation using AWS services', \"In this example, a maximum of three retries are configured with an increase multiplier of 1.5 seconds. If the first retry occurs after 3 seconds, the second retry occurs after 3 x 1.5 seconds = 4.5 seconds, and the third retry occurs after 4.5 x 1.5 seconds = 6.75 seconds. If the third retry is unsuccessful, the workflow fails. The backoff logic doesn't require any custom codeâit's provided as a configuration by AWS Step Functions.\"], 'expected_answer': 'In the example, a maximum of three retries are configured with a 1.5-second increase multiplier. The first retry is after 3 seconds, the second after 4.5 seconds, and the third after 6.75 seconds. If the third fails, the workflow fails. AWS Step Functions provides the backoff logic as a configuration.', 'query': 'Explain the retry logic configuration in the AWS Step Functions example for retry with backoff.'}, {'citations': ['Retry with backoff pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/retry-with-backoff.'], 'expected_answer': 'A complete implementation of the sample architecture for the Retry with backoff pattern is available in the GitHub repository at https://github.com/aws-samples/retry-with-backoff.', 'query': 'Where can I find the GitHub repository for the Retry with backoff pattern sample architecture?'}, {'citations': ['Saga patterns', 'A saga consists of a sequence of local transactions. Each local transaction in a saga updates the database and triggers the next local transaction. If a transaction fails, the saga runs compensating transactions to revert the database changes made by the previous transactions.'], 'expected_answer': 'A saga is a sequence of local transactions where each updates the database and triggers the next. If a transaction fails, compensating transactions are run to revert previous database changes.', 'query': 'What is a saga in the context of design patterns?'}, {'citations': ['Saga patterns', 'This sequence of local transactions helps achieve a business workflow by using continuation and compensation principles. The continuation principle decides the forward recovery of the workflow, whereas the compensation principle decides the backward recovery.'], 'expected_answer': 'Sagas achieve business workflows using continuation for forward recovery and compensation for backward recovery, ensuring data integrity.', 'query': 'What principles do sagas use to achieve business workflows?'}, {'citations': ['Saga patterns', 'The saga pattern has two variants: choreography and orchestration.'], 'expected_answer': 'The two variants of the saga pattern are choreography and orchestration.', 'query': 'What are the two variants of the saga pattern?'}, {'citations': ['Saga choreography', 'The saga choreography pattern depends on the events published by the microservices. The saga participants (microservices) subscribe to the events and act based on the event triggers.'], 'expected_answer': 'The saga choreography pattern relies on events published by microservices, where participants subscribe to and act upon these event triggers.', 'query': 'How does the saga choreography pattern work?'}, {'citations': ['Saga choreography', 'The saga choreography pattern is suitable when there are only a few participants in the saga, and you need a simple implementation with no single point of failure. When more participants are added, it becomes harder to track the dependencies between the participants by using this pattern.'], 'expected_answer': 'Saga choreography is suitable for sagas with few participants and simple implementations without a single point of failure. However, tracking dependencies becomes difficult with more participants.', 'query': 'When is the saga choreography pattern suitable?'}, {'citations': ['Saga orchestration', 'The saga orchestration pattern has a central coordinator called an orchestrator. The saga orchestrator manages and coordinates the entire transaction lifecycle.'], 'expected_answer': 'The saga orchestration pattern uses a central coordinator, an orchestrator, to manage and coordinate the entire transaction lifecycle.', 'query': 'What is the role of an orchestrator in the saga orchestration pattern?'}, {'citations': ['Saga orchestration', 'The saga orchestration pattern is suitable when there are many participants, and loose coupling is required between saga participants. The orchestrator encapsulates the complexity in the logic by making the participants loosely coupled. However, the orchestrator can become a single point of failure because it controls the entire workflow.'], 'expected_answer': 'Saga orchestration is suitable for many participants requiring loose coupling, as the orchestrator encapsulates complexity. However, it can become a single point of failure.', 'query': 'When is the saga orchestration pattern suitable?'}, {'citations': ['Saga choreography pattern', 'Intent', 'The saga choreography pattern helps preserve data integrity in distributed transactions that span multiple services by using event subscriptions.'], 'expected_answer': 'The saga choreography pattern aims to preserve data integrity in distributed transactions across multiple services through event subscriptions.', 'query': 'What is the intent of the Saga choreography pattern?'}, {'citations': ['Saga choreography pattern', 'Motivation', \"In distributed systems that follow a database-per-service design pattern, the two-phase commit is not an option. This is because each transaction is distributed across various databases, and there is no single controller that can coordinate a process that's similar to the two-phase commit in relational data stores. In this case, one solution is to use the saga choreography pattern.\"], 'expected_answer': 'The saga choreography pattern is motivated by the inability to use two-phase commit in distributed systems with a database-per-service design, where transactions span multiple databases without a single coordinator.', 'query': 'What motivates the use of the Saga choreography pattern?'}, {'citations': ['Saga choreography pattern', 'Applicability', \"Use the saga choreography pattern when: Your system requires data integrity and consistency in distributed transactions that span multiple data stores. The data store (for example, a NoSQL database) doesn't provide 2PC to provide ACID transactions, you need to update multiple tables within a single transaction, and implementing 2PC within the application boundaries would be a complex task. A central controlling process that manages the participant transactions might become a single point of failure. The saga participants are independent services and need to be loosely coupled. There is communication between bounded contexts in a business domain.\"], 'expected_answer': 'The saga choreography pattern is applicable when distributed transactions across multiple data stores require data integrity and consistency, when a data store lacks 2PC for ACID transactions and implementing it is complex, when a central controller is a single point of failure, when saga participants need to be independent and loosely coupled, or when communication between bounded contexts in a business domain is present.', 'query': 'When should the Saga choreography pattern be used?'}, {'citations': ['Saga choreography pattern', 'Issues and considerations', 'Complexity: As the number of microservices increases, saga choreography can become difficult to manage because of the number of interactions between the microservices. Additionally, compensatory transactions and retries add complexities to the application code, which can result in maintenance overhead.'], 'expected_answer': 'Saga choreography becomes complex and incurs maintenance overhead as the number of microservices increases due to numerous interactions, compensatory transactions, and retries.', 'query': 'What is a complexity issue with saga choreography?'}, {'citations': ['Saga choreography pattern', 'Implementation', 'High-level architecture', 'In the following architecture diagram, the saga choreography has three participants: the order service, the inventory service, and the payment service. Three steps are required to complete the transaction: T1, T2, and T3. Three compensatory transactions restore the data to the initial state: C1, C2, and C3.'], 'expected_answer': 'In the high-level architecture, saga choreography involves three participants (order, inventory, payment services) and three transaction steps (T1, T2, T3), with three compensatory transactions (C1, C2, C3) to restore data on failure.', 'query': 'Describe the high-level architecture of the Saga choreography pattern.'}, {'citations': ['Saga choreography pattern', 'Implementation using AWS services', 'You can implement the saga choreography pattern by using Amazon EventBridge. EventBridge uses events to connect application components. It processes events through event buses or pipes.'], 'expected_answer': 'The saga choreography pattern can be implemented using Amazon EventBridge, which connects application components through events processed via event buses or pipes.', 'query': 'How can the Saga choreography pattern be implemented using AWS services?'}, {'citations': ['Saga orchestration pattern', 'Intent', 'The saga orchestration pattern uses a central coordinator (orchestrator) to help preserve data integrity in distributed transactions that span multiple services.'], 'expected_answer': 'The saga orchestration pattern uses a central coordinator (orchestrator) to maintain data integrity in distributed transactions across multiple services.', 'query': 'What is the intent of the Saga orchestration pattern?'}, {'citations': ['Saga orchestration pattern', 'Motivation', \"In distributed systems that follow a database-per-service design pattern, the two-phase commit is not an option. This is because each transaction is distributed across various databases, and there is no single controller that can coordinate a process that's similar to the two-phase commit in relational data stores. In this case, one solution is to use the saga orchestration pattern.\"], 'expected_answer': 'The saga orchestration pattern is motivated by the inability to use two-phase commit in distributed systems with a database-per-service design, where transactions span multiple databases without a single coordinator.', 'query': 'What motivates the use of the Saga orchestration pattern?'}, {'citations': ['Saga orchestration pattern', 'Applicability', \"Use the saga orchestration pattern when: Your system requires data integrity and consistency in distributed transactions that span multiple data stores. The data store doesn't provide 2PC to provide ACID transactions, and implementing 2PC within the application boundaries is a complex task. You have NoSQL databases, which do not provide ACID transactions, and you need to update multiple tables within a single transaction.\"], 'expected_answer': 'The saga orchestration pattern is applicable when distributed transactions across multiple data stores require data integrity and consistency, when the data store lacks 2PC for ACID transactions and implementing it is complex, or when NoSQL databases are used and multiple tables need updating within a single transaction.', 'query': 'When should the Saga orchestration pattern be used?'}, {'citations': ['Saga orchestration pattern', 'Issues and considerations', 'Single point of failure: The orchestrator can become a single point of failure because it coordinates the entire transaction. In some cases, the saga choreography pattern is preferred because of this issue.'], 'expected_answer': 'A key issue with the saga orchestration pattern is that the orchestrator can become a single point of failure, leading to a preference for saga choreography in some cases.', 'query': 'What is a significant issue with the saga orchestration pattern?'}, {'citations': ['Saga orchestration pattern', 'Implementation', 'High-level architecture', 'In the following architecture diagram, the saga orchestrator has three participants: the order service, the inventory service, and the payment service. Three steps are required to complete the transaction: T1, T2, and T3. The saga orchestrator is aware of the steps and runs them in the required order. When step T3 fails (payment failure), the orchestrator runs the compensatory transactions C1 and C2 to restore the data to the initial state.'], 'expected_answer': 'In the high-level architecture, the saga orchestrator coordinates three participants (order, inventory, payment services) through steps T1, T2, T3. If T3 fails, the orchestrator executes compensatory transactions C1 and C2 to restore the initial data state.', 'query': 'Describe the high-level architecture of the Saga orchestration pattern.'}, {'citations': ['Saga orchestration pattern', 'Implementation using AWS services', 'The sample solution uses the standard workflow in Step Functions to implement the saga orchestration pattern.'], 'expected_answer': 'The sample solution implements the saga orchestration pattern using the standard workflow in AWS Step Functions.', 'query': 'How is the Saga orchestration pattern implemented using AWS services?'}, {'citations': ['Saga orchestration pattern', 'Implementation using AWS services', 'The use of Step Functions mitigates the single point of failure issue, which is inherent in the implementation of the saga orchestration pattern. Step Functions has built-in fault tolerance and maintains service capacity across multiple Availability Zones in each AWS Region to protect applications against individual machine or data center failures.'], 'expected_answer': 'Using AWS Step Functions mitigates the single point of failure in saga orchestration due to its built-in fault tolerance and Multi-AZ service capacity, protecting applications from machine or data center failures.', 'query': 'How does AWS Step Functions mitigate the single point of failure in saga orchestration?'}, {'citations': ['Saga orchestration pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/saga-orchestration-netcore-blog.'], 'expected_answer': 'A complete implementation of the sample architecture for the Saga orchestration pattern is available in the GitHub repository at https://github.com/aws-samples/saga-orchestration-netcore-blog.', 'query': 'Where can I find the GitHub repository for the Saga orchestration pattern sample architecture?'}, {'citations': ['Scatter-gather pattern', 'Intent', 'The scatter-gather pattern is a message routing pattern that involves broadcasting similar or related requests to multiple recipients, and aggregating their responses back into a single message by using a component called an aggregator.'], 'expected_answer': 'The scatter-gather pattern is a message routing pattern that broadcasts requests to multiple recipients and aggregates their responses into a single message using an aggregator.', 'query': 'What is the intent of the Scatter-gather pattern?'}, {'citations': ['Scatter-gather pattern', 'Motivation', 'In application processing, a request that might take a long time to process sequentially can be split into multiple requests that are processed in parallel. You can also send requests to multiple external systems through API calls to get a response. The scatter-gather pattern is useful when you need input from multiple sources.'], 'expected_answer': 'The scatter-gather pattern is motivated by the need to parallelize long sequential requests or gather input from multiple external sources via API calls, reducing processing time.', 'query': 'What is the motivation behind the Scatter-gather pattern?'}, {'citations': ['Scatter-gather pattern', 'Applicability', 'Use the scatter-gather pattern when: You plan to aggregate and consolidate data from various APIs to create an accurate response. The same request has to be sent to multiple recipients simultaneously to complete a transaction. You want to implement a reliable and scalable system where load balancing can be achieved by distributing requests across multiple recipients. You want to optimize performance when implementing complex queries that involve multiple data sources. You are implementing a type of map-reduce processing where the data request is routed to multiple data processing endpoints for sharding and replication. You want to distribute write operations across a partition key space in write-heavy workloads in key-value databases.'], 'expected_answer': 'The scatter-gather pattern is applicable when aggregating data from various APIs, sending the same request to multiple recipients simultaneously, implementing a reliable and scalable system with load balancing, optimizing complex queries across multiple data sources, performing map-reduce processing with sharding/replication, or distributing write operations in write-heavy key-value databases.', 'query': 'When should the Scatter-gather pattern be used?'}, {'citations': ['Scatter-gather pattern', 'Issues and considerations', 'Fault tolerance: This pattern relies on multiple recipients that work in parallel, so it is essential to handle failures gracefully. To mitigate the impact of recipient failures on the overall system, you can implement strategies such as redundancy, replication, and fault detection.'], 'expected_answer': 'Fault tolerance is a key consideration for the scatter-gather pattern, requiring graceful handling of recipient failures through strategies like redundancy, replication, and fault detection to mitigate system impact.', 'query': 'What is a key consideration for fault tolerance in scatter-gather?'}, {'citations': ['Scatter-gather pattern', 'Implementation', 'High-level architecture', 'The scatter-gather pattern uses a root controller to distribute requests to recipients that will process the requests. During the scatter phase, this pattern can use two mechanisms to send messages to recipients: Scatter by distribution and Scatter by auction.'], 'expected_answer': \"The scatter-gather pattern's high-level architecture uses a root controller to distribute requests to recipients. During the scatter phase, it employs two mechanisms: scatter by distribution or scatter by auction.\", 'query': 'Describe the high-level architecture of the Scatter-gather pattern.'}, {'citations': ['Scatter-gather pattern', 'Implementation', 'High-level architecture', 'Scatter by distribution: In the scatter by distribution method, the root controller divides the incoming request into independent tasks and assigns them to available recipients (the scatter phase). Each recipient (process, container, or Lambda function) works independently and in parallel on its computation, and produces a portion of the response. When the recipients complete their tasks, they send their responses to an aggregator (the gather phase).'], 'expected_answer': 'In scatter by distribution, the root controller divides requests into independent tasks for parallel processing by recipients (e.g., processes, containers, Lambda functions). Each recipient computes a portion of the response, which is then sent to an aggregator for the gather phase.', 'query': \"Explain the 'Scatter by distribution' method.\"}, {'citations': ['Scatter-gather pattern', 'Implementation', 'High-level architecture', \"Scatter by auction: If the controller isn't aware of the recipients or the recipients are loosely coupled, you can use the scatter by auction method. In this method, the recipients subscribe to a topic and the controller publishes the request to the topic. Recipients publish the results to a response queue.\"], 'expected_answer': \"The 'Scatter by auction' method is used when the controller is unaware of recipients or they are loosely coupled. Recipients subscribe to a topic where the controller publishes requests, and then they publish their results to a response queue.\", 'query': \"Explain the 'Scatter by auction' method.\"}, {'citations': ['Scatter-gather pattern', 'Implementation using AWS services', 'Scatter by distribution', 'In the following architecture, the root controller is a data file processor (Amazon ECS) that splits the incoming request data into individual Amazon Simple Storage Service (Amazon S3) buckets and starts an AWS Step Functions workflow. The workflow downloads the data and initiates parallel file processing. The Parallel state waits for all the tasks to return a response. An AWS Lambda function aggregates the data and saves it back to Amazon S3.'], 'expected_answer': 'In the AWS implementation of scatter by distribution, an Amazon ECS data file processor acts as the root controller, splitting request data into S3 buckets and initiating an AWS Step Functions workflow for parallel file processing. A Lambda function then aggregates the data and saves it back to S3.', 'query': \"How is 'Scatter by distribution' implemented using AWS services?\"}, {'citations': ['Scatter-gather pattern', 'Implementation using AWS services', 'Scatter by auction', 'The following diagram shows an AWS architecture for the scatter by auction method. The root controller flight booking service scatters the flight search request to multiple microservices. A publish-subscribe channel is implemented with Amazon Simple Notification Service (Amazon SNS), which is a managed messaging service for communications.'], 'expected_answer': 'The AWS architecture for scatter by auction uses a flight booking service as the root controller to scatter flight search requests to microservices via an Amazon SNS publish-subscribe channel.', 'query': \"How is 'Scatter by auction' implemented using AWS services?\"}, {'citations': ['Scatter-gather pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/asynchronous-messaging-workshop/tree/master/code/lab-3.'], 'expected_answer': 'A complete implementation of the sample architecture for the Scatter-gather pattern is available in the GitHub repository at https://github.com/aws-samples/asynchronous-messaging-workshop/tree/master/code/lab-3.', 'query': 'Where can I find the GitHub repository for the Scatter-gather pattern sample architecture?'}, {'citations': ['Strangler fig pattern', 'Intent', 'The strangler fig pattern helps migrate a monolithic application to a microservices architecture incrementally, with reduced transformation risk and business disruption.'], 'expected_answer': 'The strangler fig pattern aims to incrementally migrate monolithic applications to a microservices architecture, reducing transformation risk and business disruption.', 'query': 'What is the intent of the Strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Motivation', 'Monolithic applications are developed to provide most of their functionality within a single process or container. The code is tightly coupled. As a result, application changes require thorough retesting to avoid regression issues. The changes cannot be tested in isolation, which impacts the cycle time.'], 'expected_answer': 'The strangler fig pattern is motivated by the challenges of monolithic applications, such as tightly coupled code, extensive retesting for changes, and difficulty in isolated testing, all of which impact cycle time.', 'query': 'What motivates the use of the Strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Applicability', 'Use the strangler fig pattern when: You want to migrate your monolithic application gradually to a microservices architecture. A big bang migration approach is risky because of the size and complexity of the monolith. The business wants to add new features and cannot wait for the transformation to be complete. End users must be minimally impacted during the transformation.'], 'expected_answer': 'The strangler fig pattern is applicable when gradually migrating a monolithic application to microservices, when a big bang migration is too risky due to monolith size/complexity, when new features are needed before transformation completion, or when minimizing end-user impact during transformation is crucial.', 'query': 'When should the Strangler fig pattern be used?'}, {'citations': ['Strangler fig pattern', 'Issues and considerations', \"Code base access: To implement the strangler fig pattern, you must have access to the monolith application's code base. As features are migrated out of the monolith, you will need to make minor code changes and implement an anti-corruption layer within the monolith to route calls to new microservices.\"], 'expected_answer': \"Implementing the strangler fig pattern requires access to the monolith's code base to make minor changes and implement an anti-corruption layer for routing calls to new microservices as features are migrated.\", 'query': 'Why is code base access important for the strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Issues and considerations', 'Anti-corruption layer: During the migration process, when the features within the monolith have to call the features that were migrated as microservices, you should implement an anti-corruption layer (ACL) that routes each call to the appropriate microservice.'], 'expected_answer': 'During migration with the strangler fig pattern, an anti-corruption layer (ACL) should be implemented within the monolith to route calls from existing features to newly migrated microservices.', 'query': 'What is the role of an Anti-corruption layer in the strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Implementation', 'In the strangler fig pattern, you replace specific functionality with a new service or application, one component at a time. A proxy layer intercepts requests that go to the monolithic application and routes them to either the legacy system or the new system.'], 'expected_answer': 'In the strangler fig pattern, specific functionality is replaced incrementally with new services, and a proxy layer intercepts and routes requests to either the legacy or new system.', 'query': 'How is the Strangler fig pattern implemented?'}, {'citations': ['Strangler fig pattern', 'Implementation', 'High-level architecture', 'The first step is to add a proxy layer between the storefront UI and the monolithic application. At the start, the proxy routes all traffic to the monolithic application.'], 'expected_answer': 'The first step in the high-level architecture of the strangler fig pattern is to introduce a proxy layer between the storefront UI and the monolithic application, initially routing all traffic to the monolith.', 'query': 'What is the initial step in the high-level architecture of the Strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Implementation', 'Handling data synchronization', 'As a best practice, the microservice should own its data. The user service stores its data in its own data store. It might need to synchronize data with the monolithic database to handle dependencies such as reporting and to support downstream applications that are not yet ready to access the microservices directly.'], 'expected_answer': 'In the strangler fig pattern, microservices should own their data, but data synchronization with the monolithic database might be necessary for reporting and supporting downstream applications not yet migrated.', 'query': 'How is data synchronization handled in the strangler fig pattern?'}, {'citations': ['Strangler fig pattern', 'Implementation using AWS services', 'Using API Gateway as the application proxy', 'In the following architecture, AWS Migration Hub Refactor Spaces deploys Amazon API Gateway in front of the monolithic application. Refactor Spaces creates a refactoring infrastructure inside your account, and API Gateway acts as the proxy layer for routing calls to the monolith.'], 'expected_answer': 'In the AWS implementation, AWS Migration Hub Refactor Spaces deploys Amazon API Gateway as the proxy layer in front of the monolithic application, routing calls to the monolith.', 'query': 'How is API Gateway used as an application proxy in the Strangler fig pattern with AWS services?'}, {'citations': ['Strangler fig pattern', 'Implementation using AWS services', 'Using multiple accounts', 'Refactor Spaces helps you create and configure the AWS infrastructure for routing API calls away from the monolithic application. Refactor Spaces orchestrates API Gateway, Network Load Balancer, and resource-based AWS Identity and Access Management (IAM) policies inside your AWS accounts as part of its application resource.'], 'expected_answer': 'Refactor Spaces facilitates routing API calls away from monolithic applications by orchestrating API Gateway, Network Load Balancer, and resource-based IAM policies within AWS accounts.', 'query': 'How does Refactor Spaces assist with routing in a multi-account AWS environment for the Strangler fig pattern?'}, {'citations': ['Transactional outbox pattern', 'Intent', 'The transactional outbox pattern resolves the dual write operations issue that occurs in distributed systems when a single operation involves both a database write operation and a message or event notification.'], 'expected_answer': 'The transactional outbox pattern resolves the dual write operations issue in distributed systems where a single operation involves both a database write and a message/event notification.', 'query': 'What is the intent of the Transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Motivation', 'When a microservice sends an event notification after a database update, these two operations should run atomically to ensure data consistency and reliability.'], 'expected_answer': 'The transactional outbox pattern is motivated by the need for atomic execution of database updates and event notifications in microservices to ensure data consistency and reliability.', 'query': 'What is the motivation behind the Transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Applicability', \"Use the transactional outbox pattern when: You're building an event-driven application where a database update initiates an event notification . You want to ensure atomicity in operations that involve two services. You want to implement the event sourcing pattern.\"], 'expected_answer': 'The transactional outbox pattern is applicable when building event-driven applications where database updates trigger event notifications, ensuring atomicity in two-service operations, or implementing the event sourcing pattern.', 'query': 'When should the Transactional outbox pattern be used?'}, {'citations': ['Transactional outbox pattern', 'Issues and considerations', 'Duplicate messages: The events processing service might send out duplicate messages or events, so we recommend that you make the consuming service idempotent by tracking the processed messages.'], 'expected_answer': \"A consideration for the transactional outbox pattern is duplicate messages; it's recommended to make the consuming service idempotent by tracking processed messages.\", 'query': 'What is a key issue with duplicate messages in the transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Implementation', 'High-level architecture', 'The following sequence diagram shows the order of events that happen during dual write operations.'], 'expected_answer': 'The high-level architecture illustrates the sequence of events during dual write operations.', 'query': 'Describe the high-level architecture of the Transactional outbox pattern.'}, {'citations': ['Transactional outbox pattern', 'Implementation using AWS services', 'To address this problem, you can use an outbox table or change data capture (CDC).'], 'expected_answer': 'To address the dual write problem, you can use an outbox table or change data capture (CDC).', 'query': 'What two options can be used to address the dual write problem in the transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Implementation using AWS services', 'Using an outbox table with a relational database', 'An outbox table stores all the events from the flight service with a timestamp and a sequence number. When the flight table is updated, the outbox table is also updated in the same transaction. Another service (for example, the event processing service) reads from the outbox table and sends the event to Amazon SQS.'], 'expected_answer': 'With an outbox table, events from the flight service are stored with timestamps and sequence numbers. When the flight table is updated, the outbox table is also updated in the same transaction. An event processing service then reads from the outbox table and sends the event to Amazon SQS.', 'query': 'How does using an outbox table work with a relational database in the transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Implementation using AWS services', 'Using change data capture (CDC)', 'Some databases support the publishing of item-level modifications to capture changed data. You can identify the changed items and send an event notification accordingly. This saves the overhead of creating another table to track the updates.'], 'expected_answer': 'Change data capture (CDC) allows databases to publish item-level modifications, enabling identification of changed items and sending event notifications, thus avoiding the need for an additional tracking table.', 'query': 'What is change data capture (CDC) in the context of the transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Implementation using AWS services', 'Using change data capture (CDC)', 'Amazon DynamoDB is a key-value NoSQL database that supports CDC updates. In the following sequence diagram, DynamoDB publishes item-level modifications to Amazon DynamoDB Streams. The event processing service reads from the streams and publishes the event notification to the payment service for further processing.'], 'expected_answer': 'Amazon DynamoDB, a NoSQL database, supports CDC updates by publishing item-level modifications to DynamoDB Streams. An event processing service reads these streams and publishes event notifications to the payment service.', 'query': 'How does Amazon DynamoDB support CDC in the transactional outbox pattern?'}, {'citations': ['Transactional outbox pattern', 'Sample code', 'Using an outbox table', 'The sample code in this section shows how you can implement the transactional outbox pattern by using an outbox table.'], 'expected_answer': 'The sample code demonstrates implementing the transactional outbox pattern using an outbox table.', 'query': 'What does the sample code for the transactional outbox pattern with an outbox table show?'}, {'citations': ['Transactional outbox pattern', 'GitHub repository', 'For a complete implementation of the sample architecture for this pattern, see the GitHub repository at https://github.com/aws-samples/transactional-outbox-pattern.'], 'expected_answer': 'A complete implementation of the sample architecture for the Transactional outbox pattern is available in the GitHub repository at https://github.com/aws-samples/transactional-outbox-pattern.', 'query': 'Where can I find the GitHub repository for the Transactional outbox pattern sample architecture?'}, {'citations': ['Document history', 'New patterns', 'Added two new patterns: hexagonal architecture and scatter-gather.', 'May 7, 2024'], 'expected_answer': 'On May 7, 2024, hexagonal architecture and scatter-gather patterns were added.', 'query': 'What new patterns were added on May 7, 2024?'}, {'citations': ['Document history', 'New code examples', 'Added sample code for the change data capture (CDC) use case to the transactional outbox pattern pattern.', 'February 23, 2024'], 'expected_answer': 'On February 23, 2024, sample code for the change data capture (CDC) use case was added to the transactional outbox pattern.', 'query': 'What update was made to the transactional outbox pattern on February 23, 2024?'}, {'citations': ['Document history', 'New code examples', 'Updated the transactional outbox pattern with sample code.', 'November 16, 2023'], 'expected_answer': 'On November 16, 2023, the transactional outbox pattern was updated with sample code.', 'query': 'What was updated in the transactional outbox pattern on November 16, 2023?'}, {'citations': ['Document history', 'Removed the section on orchestration and choreography patterns, which were superseded by saga choreography and saga orchestration.', 'November 16, 2023'], 'expected_answer': 'On November 16, 2023, the sections on orchestration and choreography patterns were removed, superseded by saga choreography and saga orchestration.', 'query': 'What sections were removed on November 16, 2023, and why?'}, {'citations': ['Document history', 'New patterns', 'Added three new patterns: saga choreography, publish-subscribe, and event sourcing.', 'November 14, 2023'], 'expected_answer': 'On November 14, 2023, saga choreography, publish-subscribe, and event sourcing patterns were added.', 'query': 'What new patterns were added on November 14, 2023?'}, {'citations': ['Document history', 'Update', 'Updated the strangler fig pattern implementation section.', 'October 2, 2023'], 'expected_answer': 'On October 2, 2023, the strangler fig pattern implementation section was updated.', 'query': 'What update was made to the strangler fig pattern on October 2, 2023?'}, {'citations': ['Document history', 'Initial publication', 'This first release includes eight design patterns: anti-corruption layer (ACL), API routing, circuit breaker, orchestration and choreography, retry with backoff, saga orchestration, strangler fig, and transactional outbox.', 'July 28, 2023'], 'expected_answer': 'The initial publication on July 28, 2023, included eight design patterns: anti-corruption layer (ACL), API routing, circuit breaker, orchestration and choreography, retry with backoff, saga orchestration, strangler fig, and transactional outbox.', 'query': 'When was the initial publication of this guide, and what patterns did it include?'}, {'citations': ['Glossary', '7 Rs', 'Seven common migration strategies for moving applications to the cloud. These strategies build upon the 5 Rs that Gartner identified in 2011 and consist of the following: Refactor/re-architect, Replatform (lift and reshape), Repurchase (drop and shop), Rehost (lift and shift), Relocate (hypervisor-level lift and shift), Retain (revisit), Retire.'], 'expected_answer': \"The 7 Rs are seven common migration strategies for moving applications to the cloud, building on Gartner's 5 Rs from 2011. They include Refactor/re-architect, Replatform (lift and reshape), Repurchase (drop and shop), Rehost (lift and shift), Relocate (hypervisor-level lift and shift), Retain (revisit), and Retire.\", 'query': 'What are the 7 Rs in cloud migration strategies?'}, {'citations': ['Glossary', 'ACID', 'A set of software properties that guarantee the data validity and operational reliability of a database, even in the case of errors, power failures, or other problems.'], 'expected_answer': 'ACID refers to a set of software properties that guarantee data validity and operational reliability for a database, even during errors or power failures.', 'query': 'What does ACID stand for in database contexts?'}, {'citations': ['Glossary', 'active-active migration', 'A database migration method in which the source and target databases are kept in sync (by using a bidirectional replication tool or dual write operations), and both databases handle transactions from connecting applications during migration.'], 'expected_answer': 'Active-active migration is a database migration method where both source and target databases are kept in sync via bidirectional replication or dual writes, and both handle transactions from connecting applications during migration.', 'query': 'Define active-active migration.'}, {'citations': ['Glossary', 'active-passive migration', 'A database migration method in which in which the source and target databases are kept in sync, but only the source database handles transactions from connecting applications while data is replicated to the target database. The target database doesnât accept any transactions during migration.'], 'expected_answer': 'Active-passive migration is a database migration method where source and target databases are kept in sync, but only the source handles transactions while data replicates to the target, which does not accept transactions during migration.', 'query': 'What is active-passive migration?'}, {'citations': ['Glossary', 'anti-pattern', 'A frequently used solution for a recurring issue where the solution is counter-productive, ineffective, or less effective than an alternative.'], 'expected_answer': 'An anti-pattern is a frequently used solution for a recurring issue that is counter-productive, ineffective, or less effective than an alternative.', 'query': 'What is an anti-pattern?'}, {'citations': ['Glossary', 'Availability Zone', 'A distinct location within an AWS Region that is insulated from failures in other Availability Zones and provides inexpensive, low-latency network connectivity to other Availability Zones in the same Region.'], 'expected_answer': 'An Availability Zone is a distinct location within an AWS Region, insulated from failures in other AZs, offering inexpensive, low-latency network connectivity to other AZs in the same Region.', 'query': 'What is an Availability Zone?'}, {'citations': ['Glossary', 'blue/green deployment', 'A deployment strategy where you create two separate but identical environments. You run the current application version in one environment (blue) and the new application version in the other environment (green). This strategy helps you quickly roll back with minimal impact.'], 'expected_answer': 'Blue/green deployment is a strategy where two identical environments run current (blue) and new (green) application versions, allowing quick rollbacks with minimal impact.', 'query': 'Explain blue/green deployment.'}, {'citations': ['Glossary', 'canary deployment', 'The slow and incremental release of a version to end users. When you are confident, you deploy the new version and replace the current version in its entirety.'], 'expected_answer': 'Canary deployment is a slow, incremental release of a new version to end users. Once confident, the new version fully replaces the current one.', 'query': 'What is canary deployment?'}, {'citations': ['Glossary', 'change data capture (CDC)', 'The process of tracking changes to a data source, such as a database table, and recording metadata about the change. You can use CDC for various purposes, such as auditing or replicating changes in a target system to maintain synchronization.'], 'expected_answer': 'Change data capture (CDC) is the process of tracking and recording metadata about changes to a data source, like a database table, used for purposes such as auditing or replicating changes for synchronization.', 'query': 'Define change data capture (CDC).'}, {'citations': ['Glossary', 'chaos engineering', 'Intentionally introducing failures or disruptive events to test a systemâs resilience. You can use AWS Fault Injection Service (AWS FIS) to perform experiments that stress your AWS workloads and evaluate their response.'], 'expected_answer': 'Chaos engineering involves intentionally introducing failures or disruptive events to test system resilience, often using tools like AWS Fault Injection Service (AWS FIS) to evaluate workload responses.', 'query': 'What is chaos engineering?'}, {'citations': ['Glossary', 'CI/CD', 'The process of automating the source, build, test, staging, and production stages of the software release process. CI/CD is commonly described as a pipeline. CI/CD can help you automate processes, improve productivity, improve code quality, and deliver faster.'], 'expected_answer': 'CI/CD is the automation of the source, build, test, staging, and production stages of software release, commonly described as a pipeline, which helps automate processes, improve productivity, code quality, and delivery speed.', 'query': 'What is CI/CD?'}, {'citations': ['Glossary', 'Cloud Center of Excellence (CCoE)', 'A multi-disciplinary team that drives cloud adoption efforts across an organization, including developing cloud best practices, mobilizing resources, establishing migration timelines, and leading the organization through large-scale transformations.'], 'expected_answer': 'A Cloud Center of Excellence (CCoE) is a multi-disciplinary team that spearheads cloud adoption within an organization, developing best practices, mobilizing resources, setting migration timelines, and guiding large-scale transformations.', 'query': 'What is a Cloud Center of Excellence (CCoE)?'}, {'citations': ['Glossary', 'data at rest', 'Data that is stationary in your network, such as data that is in storage.'], 'expected_answer': 'Data at rest refers to data that is stationary in your network, such as data in storage.', 'query': 'What is data at rest?'}, {'citations': ['Glossary', 'data in transit', 'Data that is actively moving through your network, such as between network resources.'], 'expected_answer': 'Data in transit is data actively moving through your network, for example, between network resources.', 'query': 'What is data in transit?'}, {'citations': ['Glossary', 'data mesh', 'An architectural framework that provides distributed, decentralized data ownership with centralized management and governance.'], 'expected_answer': 'A data mesh is an architectural framework offering distributed, decentralized data ownership with centralized management and governance.', 'query': 'Define data mesh.'}, {'citations': ['Glossary', 'defense-in-depth', 'An information security approach in which a series of security mechanisms and controls are thoughtfully layered throughout a computer network to protect the confidentiality, integrity, and availability of the network and the data within.'], 'expected_answer': 'Defense-in-depth is an information security approach that layers security mechanisms and controls throughout a network to protect its confidentiality, integrity, and availability, as well as its data.', 'query': 'What is defense-in-depth?'}, {'citations': ['Glossary', 'disaster recovery (DR)', 'The strategy and process you use to minimize downtime and data loss caused by a disaster.'], 'expected_answer': 'Disaster recovery (DR) is the strategy and process used to minimize downtime and data loss resulting from a disaster.', 'query': 'What is disaster recovery (DR)?'}, {'citations': ['Glossary', 'domain-driven design', 'An approach to developing a complex software system by connecting its components to evolving domains, or core business goals, that each component serves.'], 'expected_answer': 'Domain-driven design is an approach to developing complex software systems by linking components to evolving domains or core business goals they serve.', 'query': 'What is domain-driven design?'}, {'citations': ['Glossary', 'eventual consistency', 'The sequential processing of local transactions results in eventual consistency, which can be a challenge in systems that require strong consistency.'], 'expected_answer': 'Eventual consistency results from sequential processing of local transactions and can be a challenge for systems requiring strong consistency.', 'query': 'What is eventual consistency?'}, {'citations': ['Glossary', 'fail fast', 'A philosophy that uses frequent and incremental testing to reduce the development lifecycle. It is a critical part of an agile approach.'], 'expected_answer': 'Fail fast is an agile philosophy that reduces the development lifecycle through frequent, incremental testing.', 'query': \"What is the 'fail fast' philosophy?\"}, {'citations': ['Glossary', 'fault isolation boundary', 'In the AWS Cloud, a boundary such as an Availability Zone, AWS Region, control plane, or data plane that limits the effect of a failure and helps improve the resilience of workloads.'], 'expected_answer': 'In the AWS Cloud, a fault isolation boundary, such as an Availability Zone or AWS Region, limits the impact of a failure and enhances workload resilience.', 'query': 'What is a fault isolation boundary in the AWS Cloud?'}, {'citations': ['Glossary', 'foundation model (FM)', 'A large deep-learning neural network that has been training on massive datasets of generalized and unlabeled data. FMs are capable of performing a wide variety of general tasks, such as understanding language, generating text and images, and conversing in natural language.'], 'expected_answer': 'A foundation model (FM) is a large deep-learning neural network trained on massive, generalized, unlabeled datasets, capable of diverse tasks like language understanding, text/image generation, and natural language conversation.', 'query': 'What is a foundation model (FM)?'}, {'citations': ['Glossary', 'generative AI', 'A subset of AI models that have been trained on large amounts of data and that can use a simple text prompt to create new content and artifacts, such as images, videos, text, and audio.'], 'expected_answer': 'Generative AI is a subset of AI models trained on large datasets that can create new content like images, videos, text, and audio from simple text prompts.', 'query': 'What is generative AI?'}, {'citations': ['Glossary', 'golden image', 'A snapshot of a system or software that is used as a template to deploy new instances of that system or software.'], 'expected_answer': 'A golden image is a system or software snapshot used as a template for deploying new instances.', 'query': 'What is a golden image?'}, {'citations': ['Glossary', 'high availability (HA)', 'The ability of a workload to operate continuously, without intervention, in the event of challenges or disasters. HA systems are designed to automatically fail over, consistently deliver high-quality performance, and handle different loads and failures with minimal performance impact.'], 'expected_answer': \"High availability (HA) is a workload's ability to operate continuously without intervention during challenges or disasters, designed for automatic failover, consistent high performance, and minimal impact from loads and failures.\", 'query': 'What is high availability (HA)?'}, {'citations': ['Glossary', 'IaC', \"The process of provisioning and managing an application's infrastructure through a set of configuration files. IaC is designed to help you centralize infrastructure management, standardize resources, and scale quickly so that new environments are repeatable, reliable, and consistent.\"], 'expected_answer': 'IaC (Infrastructure as Code) is the process of provisioning and managing application infrastructure via configuration files, aiming to centralize management, standardize resources, and enable quick, repeatable, reliable, and consistent scaling of new environments.', 'query': 'What is Infrastructure as Code (IaC)?'}, {'citations': ['Glossary', 'immutable infrastructure', 'A model that deploys new infrastructure for production workloads instead of updating, patching, or modifying the existing infrastructure. Immutable infrastructures are inherently more consistent, reliable, and predictable than mutable infrastructure.'], 'expected_answer': 'Immutable infrastructure is a model where new infrastructure is deployed for production workloads instead of modifying existing ones, leading to more consistent, reliable, and predictable systems than mutable infrastructure.', 'query': 'What is immutable infrastructure?'}, {'citations': ['Glossary', 'incremental migration', 'A cutover strategy in which you migrate your application in small parts instead of performing a single, full cutover. For example, you might move only a few microservices or users to the new system initially. After you verify that everything is working properly, you can incrementally move additional microservices or users until you can decommission your legacy system.'], 'expected_answer': 'Incremental migration is a cutover strategy where applications are migrated in small parts, rather than a single full cutover, allowing for gradual movement of microservices or users and verification before decommissioning the legacy system.', 'query': 'Explain incremental migration.'}, {'citations': ['Glossary', 'least privilege', 'The security best practice of granting the minimum permissions required to perform a task.'], 'expected_answer': 'Least privilege is the security best practice of granting only the minimum permissions necessary to perform a task.', 'query': 'What is the principle of least privilege?'}, {'citations': ['Glossary', 'large language model (LLM)', 'A deep learning AI model that is pretrained on a vast amount of data. An LLM can perform multiple tasks, such as answering questions, summarizing documents, translating text into other languages, and completing sentences.'], 'expected_answer': 'A large language model (LLM) is a deep learning AI model pretrained on vast data, capable of tasks like answering questions, summarizing documents, translating text, and completing sentences.', 'query': 'What is a large language model (LLM)?'}, {'citations': ['Glossary', 'microservice', 'A small, independent service that communicates over well-defined APIs and is typically owned by small, self-contained teams.'], 'expected_answer': 'A microservice is a small, independent service that communicates via well-defined APIs, typically owned by small, self-contained teams.', 'query': 'Define microservice.'}, {'citations': ['Glossary', 'microservices architecture', 'An approach to building an application with independent components that run each application process as a microservice. These microservices communicate through a well-defined interface by using lightweight APIs.'], 'expected_answer': 'Microservices architecture is an approach to building applications with independent components, where each process runs as a microservice, communicating via well-defined interfaces and lightweight APIs.', 'query': 'What is microservices architecture?'}, {'citations': ['Glossary', 'modernization', 'Transforming an outdated (legacy or monolithic) application and its infrastructure into an agile, elastic, and highly available system in the cloud to reduce costs, gain efficiencies, and take advantage of innovations.'], 'expected_answer': 'Modernization involves transforming outdated applications and infrastructure into agile, elastic, highly available cloud systems to reduce costs, improve efficiency, and leverage innovation.', 'query': 'What does modernization entail?'}, {'citations': ['Glossary', 'monolithic applications (monoliths)', 'Applications that run as a single service with tightly coupled processes. Monolithic applications have several drawbacks. If one application feature experiences a spike in demand, the entire architecture must be scaled. Adding or improving a monolithic applicationâs features also becomes more complex when the code base grows.'], 'expected_answer': \"Monolithic applications run as a single service with tightly coupled processes, leading to drawbacks such as needing to scale the entire architecture for a single feature's demand spike, and increased complexity in adding or improving features as the codebase grows.\", 'query': 'What are monolithic applications and their drawbacks?'}, {'citations': ['Glossary', 'online migration', 'A migration method in which the source workload is copied to the target system without being taken offline. Applications that are connected to the workload can continue to function during the migration. This method involves zero to minimal downtime and is typically used for critical production workloads.'], 'expected_answer': \"Online migration is a method where the source workload is copied to the target system without downtime, allowing connected applications to function during the process. It's typically used for critical production workloads.\", 'query': 'Describe online migration.'}, {'citations': ['Glossary', 'polyglot persistence', 'Independently choosing a microserviceâs data storage technology based on data access patterns and other requirements. If your microservices have the same data storage technology, they can encounter implementation challenges or experience poor performance.'], 'expected_answer': \"Polyglot persistence is the independent selection of a microservice's data storage technology based on its data access patterns and requirements, avoiding challenges and poor performance that can arise from using the same technology across all microservices.\", 'query': 'What is polyglot persistence?'}, {'citations': ['Glossary', 'publish/subscribe (pub/sub)', 'A pattern that enables asynchronous communications among microservices to improve scalability and responsiveness.'], 'expected_answer': 'Publish/subscribe (pub/sub) is a pattern that enables asynchronous communication among microservices to enhance scalability and responsiveness.', 'query': 'What is the publish/subscribe (pub/sub) pattern?'}, {'citations': ['Glossary', 'recovery point objective (RPO)', 'The maximum acceptable amount of time since the last data recovery point. This determines what is considered an acceptable loss of data between the last recovery point and the interruption of service.'], 'expected_answer': 'RPO (Recovery Point Objective) is the maximum acceptable time since the last data recovery point, defining the tolerable data loss between that point and a service interruption.', 'query': 'What is RPO?'}, {'citations': ['Glossary', 'recovery time objective (RTO)', 'The maximum acceptable delay between the interruption of service and restoration of service.'], 'expected_answer': 'RTO (Recovery Time Objective) is the maximum acceptable delay between service interruption and restoration.', 'query': 'What is RTO?'}, {'citations': ['Glossary', 'resiliency', \"An application's ability to resist or recover from disruptions. High availability and disaster recovery are common considerations when planning for resiliency in the AWS Cloud.\"], 'expected_answer': \"Resiliency is an application's ability to resist or recover from disruptions, with high availability and disaster recovery being key considerations in the AWS Cloud.\", 'query': 'Define resiliency.'}, {'citations': ['Glossary', 'Retrieval Augmented Generation (RAG)', 'A generative AI technology in which an LLM references an authoritative data source that is outside of its training data sources before generating a response.'], 'expected_answer': 'Retrieval Augmented Generation (RAG) is a generative AI technology where an LLM references an authoritative external data source before generating a response.', 'query': 'What is Retrieval Augmented Generation (RAG)?'}, {'citations': ['Glossary', 'shared responsibility model', 'A model describing the responsibility you share with AWS for cloud security and compliance. AWS is responsible for security of the cloud, whereas you are responsible for security in the cloud.'], 'expected_answer': 'The shared responsibility model outlines that AWS is responsible for security *of* the cloud, while the user is responsible for security *in* the cloud, regarding cloud security and compliance.', 'query': 'Explain the shared responsibility model.'}, {'citations': ['Glossary', 'single point of failure (SPOF)', 'A failure in a single, critical component of an application that can disrupt the system.'], 'expected_answer': 'A single point of failure (SPOF) is a failure in a single, critical application component that can disrupt the entire system.', 'query': 'What is a single point of failure (SPOF)?'}, {'citations': ['Glossary', 'strangler fig pattern', 'An approach to modernizing monolithic systems by incrementally rewriting and replacing system functionality until the legacy system can be decommissioned.'], 'expected_answer': 'The strangler fig pattern is an approach to modernize monolithic systems by incrementally rewriting and replacing functionality until the legacy system can be decommissioned.', 'query': 'What is the strangler fig pattern?'}, {'citations': ['Glossary', 'two-pizza team', 'A small DevOps team that you can feed with two pizzas. A two-pizza team size ensures the best possible opportunity for collaboration in software development.'], 'expected_answer': 'A two-pizza team is a small DevOps team, ideally sized to be fed by two pizzas, designed to maximize collaboration in software development.', 'query': 'What is a two-pizza team?'}, {'citations': ['Glossary', 'undifferentiated tasks', 'Also known as heavy lifting, work that is necessary to create and operate an application but that doesnât provide direct value to the end user or provide competitive advantage.'], 'expected_answer': 'Undifferentiated tasks, also known as heavy lifting, are necessary for application creation and operation but do not provide direct value to the end user or competitive advantage.', 'query': 'What are undifferentiated tasks?'}, {'citations': ['Glossary', 'zero-day vulnerability', 'An unmitigated flaw or vulnerability in a production system. Threat actors can use this type of vulnerability to attack the system. Developers frequently become aware of the vulnerability as a result of the attack.'], 'expected_answer': 'A zero-day vulnerability is an unmitigated flaw in a production system that threat actors can exploit, often becoming known to developers only after an attack.', 'query': 'What is a zero-day vulnerability?'}, {'citations': ['Glossary', 'zero-shot prompting', 'Providing an LLM with instructions for performing a task but no examples (shots) that can help guide it. The LLM must use its pre-trained knowledge to handle the task.'], 'expected_answer': 'Zero-shot prompting involves providing an LLM with task instructions but no examples, requiring the LLM to use its pre-trained knowledge to complete the task.', 'query': 'What is zero-shot prompting?'}, {'citations': ['Glossary', 'few-shot prompting', 'Providing an LLM with a small number of examples that demonstrate the task and desired output before asking it to perform a similar task. This technique is an application of in-context learning, where models learn from examples (shots) that are embedded in prompts.'], 'expected_answer': 'Few-shot prompting provides an LLM with a small number of examples demonstrating a task and desired output, allowing the model to learn from these in-context examples before performing similar tasks.', 'query': 'What is few-shot prompting?'}, {'citations': ['Glossary', 'hot data', 'Data that is frequently accessed, such as real-time data or recent translational data. This data typically requires a high-performance storage tier or class to provide fast query responses.'], 'expected_answer': 'Hot data is frequently accessed data, like real-time or recent transactional data, requiring high-performance storage for fast query responses.', 'query': 'What is hot data?'}, {'citations': ['Glossary', 'cold data', 'Data that is rarely accessed and is typically historical. When querying this kind of data, slow queries are typically acceptable. Moving this data to lower-performing and less expensive storage tiers or classes can reduce costs.'], 'expected_answer': 'Cold data is rarely accessed, typically historical data, where slow queries are acceptable. Moving it to lower-performing, less expensive storage tiers can reduce costs.', 'query': 'What is cold data?'}, {'citations': ['Glossary', 'warm data', 'Data that is infrequently accessed. When querying this kind of data, moderately slow queries are typically acceptable.'], 'expected_answer': 'Warm data is infrequently accessed data where moderately slow queries are typically acceptable.', 'query': 'What is warm data?'}, {'citations': ['Glossary', 'hotfix', 'An urgent fix for a critical issue in a production environment. Due to its urgency, a hotfix is usually made outside of the typical DevOps release workflow.'], 'expected_answer': 'A hotfix is an urgent fix for a critical production issue, typically deployed outside the standard DevOps release workflow due to its urgency.', 'query': 'What is a hotfix?'}, {'citations': ['Glossary', 'hypercare period', 'Immediately following cutover, the period of time when a migration team manages and monitors the migrated applications in the cloud in order to address any issues. Typically, this period is 1â4 days in length.'], 'expected_answer': 'The hypercare period is the 1-4 day period immediately after cutover when a migration team manages and monitors migrated cloud applications to address any issues.', 'query': 'What is the hypercare period in migration?'}, {'citations': ['Glossary', 'idle application', 'An application that has an average CPU and memory usage between 5 and 20 percent over a period of 90 days. In a migration project, it is common to retire these applications or retain them on premises.'], 'expected_answer': 'An idle application has average CPU and memory usage between 5% and 20% over 90 days; in migration projects, these are often retired or kept on-premises.', 'query': 'What defines an idle application?'}, {'citations': ['Glossary', 'zombie application', 'An application that has an average CPU and memory usage below 5 percent. In a migration project, it is common to retire these applications.'], 'expected_answer': 'A zombie application has average CPU and memory usage below 5 percent, and is commonly retired in migration projects.', 'query': 'What is a zombie application?'}, {'citations': ['Glossary', 'landing zone', 'A landing zone is a well-architected, multi-account AWS environment that is scalable and secure. This is a starting point from which your organizations can quickly launch and deploy workloads and applications with confidence in their security and infrastructure environment.'], 'expected_answer': 'A landing zone is a well-architected, scalable, and secure multi-account AWS environment, serving as a starting point for organizations to confidently launch and deploy workloads.', 'query': 'What is a landing zone?'}, {'citations': ['Glossary', 'large migration', 'A migration of 300 or more servers.'], 'expected_answer': 'A large migration involves 300 or more servers.', 'query': 'How many servers define a large migration?'}, {'citations': ['Glossary', 'migration factory', 'Cross-functional teams that streamline the migration of workloads through automated, agile approaches.'], 'expected_answer': 'A migration factory consists of cross-functional teams that streamline workload migration using automated, agile approaches.', 'query': 'What is a migration factory?'}, {'citations': ['Glossary', 'migration at scale', 'The process of moving the majority of the application portfolio to the cloud in waves, with more applications moved at a faster rate in each wave. This phase uses the best practices and lessons learned from the earlier phases to implement a migration factory of teams, tools, and processes to streamline the migration of workloads through automation and agile delivery.'], 'expected_answer': 'Migration at scale is the process of moving most of an application portfolio to the cloud in increasing waves, leveraging best practices and lessons learned to establish a migration factory for streamlined, automated, and agile workload migration.', 'query': 'What is migration at scale?'}, {'citations': ['Glossary', 'Migration Acceleration Program (MAP)', 'An AWS program that provides consulting support, training, and services to help organizations build a strong operational foundation for moving to the cloud, and to help offset the initial cost of migrations.'], 'expected_answer': 'The Migration Acceleration Program (MAP) is an AWS program offering consulting, training, and services to help organizations build a strong operational foundation for cloud migration and offset initial costs.', 'query': 'What is the Migration Acceleration Program (MAP)?'}, {'citations': ['Glossary', 'Migration Portfolio Assessment (MPA)', 'An online tool that provides information for validating the business case for migrating to the AWS Cloud. MPA provides detailed portfolio assessment (server right-sizing, pricing, TCO comparisons, migration cost analysis) as well as migration planning (application data analysis and data collection, application grouping, migration prioritization, and wave planning).'], 'expected_answer': 'Migration Portfolio Assessment (MPA) is an online tool that validates the business case for AWS Cloud migration, offering detailed portfolio assessment (server right-sizing, pricing, TCO, cost analysis) and migration planning (data analysis, grouping, prioritization, wave planning).', 'query': 'What is Migration Portfolio Assessment (MPA)?'}, {'citations': ['Glossary', 'Migration Readiness Assessment (MRA)', 'The process of gaining insights about an organizationâs cloud readiness status, identifying strengths and weaknesses, and building an action plan to close identified gaps, using the AWS CAF.'], 'expected_answer': \"Migration Readiness Assessment (MRA) is the process of evaluating an organization's cloud readiness using AWS CAF, identifying strengths and weaknesses, and creating an action plan to address gaps.\", 'query': 'What is Migration Readiness Assessment (MRA)?'}, {'citations': ['Glossary', 'offline migration', 'A migration method in which the source workload is taken down during the migration process. This method involves extended downtime and is typically used for small, non-critical workloads.'], 'expected_answer': 'Offline migration is a method where the source workload is taken down during migration, resulting in extended downtime, typically used for small, non-critical workloads.', 'query': 'What is offline migration?'}, {'citations': ['Glossary', 'operational readiness review (ORR)', 'A checklist of questions and associated best practices that help you understand, evaluate, prevent, or reduce the scope of incidents and possible failures.'], 'expected_answer': 'An operational readiness review (ORR) is a checklist of questions and best practices to understand, evaluate, prevent, or reduce the scope of incidents and failures.', 'query': 'What is an operational readiness review (ORR)?'}, {'citations': ['Glossary', 'organizational change management (OCM)', 'A framework for managing major, disruptive business transformations from a people, culture, and leadership perspective.'], 'expected_answer': 'Organizational change management (OCM) is a framework for managing major, disruptive business transformations from the perspective of people, culture, and leadership.', 'query': 'What is organizational change management (OCM)?'}, {'citations': ['Glossary', 'playbook', 'A set of predefined steps that capture the work associated with migrations, such as delivering core operations functions in the cloud. A playbook can take the form of scripts, automated runbooks, or a summary of processes or steps required to operate your modernized environment.'], 'expected_answer': 'A playbook is a set of predefined steps capturing migration work, such as delivering cloud operations functions. It can be scripts, automated runbooks, or process summaries for operating a modernized environment.', 'query': 'What is a playbook in the context of migrations?'}, {'citations': ['Glossary', 'query plan', 'A series of steps, like instructions, that are used to access the data in a SQL relational database system.'], 'expected_answer': 'A query plan is a series of instructional steps used to access data in a SQL relational database system.', 'query': 'What is a query plan?'}, {'citations': ['Glossary', 'query plan regression', 'When a database service optimizer chooses a less optimal plan than it did before a given change to the database environment. This can be caused by changes to statistics, constraints, environment settings, query parameter bindings, and updates to the database engine.'], 'expected_answer': 'Query plan regression occurs when a database optimizer selects a suboptimal plan after an environment change, caused by alterations in statistics, constraints, settings, parameter bindings, or database engine updates.', 'query': 'What is query plan regression?'}, {'citations': ['Glossary', 'read replica', 'A copy of a database thatâs used for read-only purposes. You can route queries to the read replica to reduce the load on your primary database.'], 'expected_answer': 'A read replica is a read-only copy of a database, used to offload queries from the primary database.', 'query': 'What is a read replica?'}, {'citations': ['Glossary', 'runbook', 'A set of manual or automated procedures required to perform a specific task. These are typically built to streamline repetitive operations or procedures with high error rates.'], 'expected_answer': 'A runbook is a set of manual or automated procedures for specific tasks, designed to streamline repetitive operations or those with high error rates.', 'query': 'What is a runbook?'}, {'citations': ['Glossary', 'secret', 'In AWS Secrets Manager, confidential or restricted information, such as a password or user credentials, that you store in encrypted form. It consists of the secret value and its metadata.'], 'expected_answer': 'In AWS Secrets Manager, a secret is confidential or restricted information, like a password or user credentials, stored in encrypted form, comprising the secret value and its metadata.', 'query': 'What is a secret in AWS Secrets Manager?'}, {'citations': ['Glossary', 'security hardening', 'The process of reducing the attack surface to make it more resistant to attacks. This can include actions such as removing resources that are no longer needed, implementing the security best practice of granting least privilege, or deactivating unnecessary features in configuration files.'], 'expected_answer': 'Security hardening is the process of reducing an attack surface to improve resistance to attacks, involving actions like removing unneeded resources, implementing least privilege, or deactivating unnecessary features.', 'query': 'What is security hardening?'}, {'citations': ['Glossary', 'service control policy (SCP)', 'A policy that provides centralized control over permissions for all accounts in an organization in AWS Organizations. SCPs define guardrails or set limits on actions that an administrator can delegate to users or roles.'], 'expected_answer': 'A service control policy (SCP) provides centralized control over permissions for all accounts in an AWS Organizations organization, defining guardrails or limits on actions an administrator can delegate.', 'query': 'What is a service control policy (SCP)?'}, {'citations': ['Glossary', 'service endpoint', 'The URL of the entry point for an AWS service. You can use the endpoint to connect programmatically to the target service.'], 'expected_answer': 'A service endpoint is the URL entry point for an AWS service, used for programmatic connections to that service.', 'query': 'What is a service endpoint?'}, {'citations': ['Glossary', 'star schema', 'A database organizational structure that uses one large fact table to store transactional or measured data and uses one or more smaller dimensional tables to store data attributes. This structure is designed for use in a data warehouse or for business intelligence purposes.'], 'expected_answer': 'A star schema is a database structure with a large fact table for transactional data and smaller dimensional tables for data attributes, designed for data warehousing or business intelligence.', 'query': 'What is a star schema?'}, {'citations': ['Glossary', 'subnet', 'A range of IP addresses in your VPC. A subnet must reside in a single Availability Zone.'], 'expected_answer': 'A subnet is a range of IP addresses within your VPC, confined to a single Availability Zone.', 'query': 'What is a subnet?'}, {'citations': ['Glossary', 'tags', 'Key-value pairs that act as metadata for organizing your AWS resources. Tags can help you manage, identify, organize, search for, and filter resources.'], 'expected_answer': 'Tags are key-value pairs serving as metadata to organize AWS resources, aiding in management, identification, organization, searching, and filtering.', 'query': 'What are tags in AWS?'}, {'citations': ['Glossary', 'training', 'To provide data for your ML model to learn from. The training data must contain the correct answer. The learning algorithm finds patterns in the training data that map the input data attributes to the target (the answer that you want to predict). It outputs an ML model that captures these patterns.'], 'expected_answer': 'Training an ML model involves providing data with correct answers, allowing the learning algorithm to find patterns mapping input attributes to the target, and producing an ML model that captures these patterns.', 'query': 'What is training in machine learning?'}, {'citations': ['Glossary', 'transit gateway', 'A network transit hub that you can use to interconnect your VPCs and on-premises networks.'], 'expected_answer': 'A transit gateway is a network transit hub used to interconnect VPCs and on-premises networks.', 'query': 'What is a transit gateway?'}, {'citations': ['Glossary', 'trunk-based workflow', 'An approach in which developers build and test features locally in a feature branch and then merge those changes into the main branch. The main branch is then built to the development, preproduction, and production environments, sequentially.'], 'expected_answer': 'A trunk-based workflow involves developers building and testing features locally in a feature branch, merging changes into the main branch, which is then sequentially built to development, preproduction, and production environments.', 'query': 'What is a trunk-based workflow?'}, {'citations': ['Glossary', 'VPC peering', 'A connection between two VPCs that allows you to route traffic by using private IP addresses.'], 'expected_answer': 'VPC peering is a connection between two VPCs that enables traffic routing using private IP addresses.', 'query': 'What is VPC peering?'}, {'citations': ['Glossary', 'workload', 'A collection of resources and code that delivers business value, such as a customer-facing application or backend process.'], 'expected_answer': 'A workload is a collection of resources and code that delivers business value, such as a customer-facing application or backend process.', 'query': 'Define workload.'}, {'citations': ['Glossary', 'write once, read many (WORM)', 'A storage model that writes data a single time and prevents the data from being deleted or modified. Authorized users can read the data as many times as needed, but they cannot change it.'], 'expected_answer': 'Write once, read many (WORM) is a storage model where data is written once and cannot be deleted or modified, but authorized users can read it repeatedly.', 'query': 'What is WORM storage?'}, {'citations': ['Glossary', 'computer vision (CV)', 'A field of AI that uses machine learning to analyze and extract information from visual formats such as digital images and videos.'], 'expected_answer': 'Computer vision (CV) is an AI field that uses machine learning to analyze and extract information from visual formats like digital images and videos.', 'query': 'What is computer vision (CV)?'}, {'citations': ['Glossary', 'machine learning (ML)', 'A type of artificial intelligence that uses algorithms and techniques for pattern recognition and learning. ML analyzes and learns from recorded data, such as Internet of Things (IoT) data, to generate a statistical model based on patterns.'], 'expected_answer': 'Machine learning (ML) is a type of artificial intelligence that uses algorithms and techniques for pattern recognition and learning, analyzing recorded data to generate statistical models based on patterns.', 'query': 'What is machine learning (ML)?'}, {'citations': ['Glossary', 'deep learning', 'An ML subfield that uses multiple layers of artificial neural networks to identify mapping between input data and target variables of interest.'], 'expected_answer': 'Deep learning is an ML subfield that uses multiple layers of artificial neural networks to map input data to target variables.', 'query': 'What is deep learning?'}, {'citations': ['Glossary', 'Internet of Things (IoT)', 'The network of connected physical objects with embedded sensors or processors that communicate with other devices and systems through the internet or over a local communication network.'], 'expected_answer': 'The Internet of Things (IoT) is a network of physical objects with embedded sensors or processors that communicate with other devices and systems via the internet or local networks.', 'query': 'What is the Internet of Things (IoT)?'}, {'citations': ['Glossary', 'industrial Internet of Things (IIoT)', 'The use of internet-connected sensors and devices in the industrial sectors, such as manufacturing, energy, automotive, healthcare, life sciences, and agriculture.'], 'expected_answer': 'Industrial Internet of Things (IIoT) refers to the use of internet-connected sensors and devices in industrial sectors like manufacturing, energy, automotive, healthcare, life sciences, and agriculture.', 'query': 'What is Industrial Internet of Things (IIoT)?'}, {'citations': ['Glossary', 'operational technology (OT)', 'Hardware and software systems that work with the physical environment to control industrial operations, equipment, and infrastructure.'], 'expected_answer': 'Operational technology (OT) refers to hardware and software systems that interact with the physical environment to control industrial operations, equipment, and infrastructure.', 'query': 'What is operational technology (OT)?'}, {'citations': ['Glossary', 'historian modernization', 'An approach used to modernize and upgrade operational technology (OT) systems to better serve the needs of the manufacturing industry. A historian is a type of database that is used to collect and store data from various sources in a factory.'], 'expected_answer': 'Historian modernization is an approach to upgrade operational technology (OT) systems for the manufacturing industry, where a historian is a database collecting and storing factory data.', 'query': 'What is historian modernization?'}, {'citations': ['Glossary', 'Industry 4.0', 'A term that was introduced by Klaus Schwab in 2016 to refer to the modernization of manufacturing processes through advances in connectivity, real-time data, automation, analytics, and AI/ML.'], 'expected_answer': 'Industry 4.0, introduced by Klaus Schwab in 2016, refers to the modernization of manufacturing processes through advancements in connectivity, real-time data, automation, analytics, and AI/ML.', 'query': 'What is Industry 4.0 and who introduced the term?'}, {'citations': ['Glossary', 'Message Queuing Telemetry Transport (MQTT)', 'A lightweight, machine-to-machine (M2M) communication protocol, based on the publish/ subscribe pattern, for resource-constrained IoT devices.'], 'expected_answer': 'Message Queuing Telemetry Transport (MQTT) is a lightweight, publish/subscribe-based M2M communication protocol designed for resource-constrained IoT devices.', 'query': 'What is MQTT?'}, {'citations': ['Glossary', 'Open Process Communications - Unified Architecture (OPC-UA)', 'A machine-to-machine (M2M) communication protocol for industrial automation. OPC-UA provides an interoperability standard with data encryption, authentication, and authorization schemes.'], 'expected_answer': 'Open Process Communications - Unified Architecture (OPC-UA) is an M2M communication protocol for industrial automation, offering an interoperability standard with data encryption, authentication, and authorization.', 'query': 'What is OPC-UA?'}, {'citations': ['Glossary', 'programmable logic controller (PLC)', 'In manufacturing, a highly reliable, adaptable computer that monitors machines and automates manufacturing processes.'], 'expected_answer': 'In manufacturing, a programmable logic controller (PLC) is a highly reliable, adaptable computer that monitors machines and automates manufacturing processes.', 'query': 'What is a PLC in manufacturing?'}, {'citations': ['Glossary', 'supervisory control and data acquisition (SCADA)', 'In manufacturing, a system that uses hardware and software to monitor physical assets and production operations.'], 'expected_answer': 'In manufacturing, SCADA is a system that uses hardware and software to monitor physical assets and production operations.', 'query': 'What is SCADA in manufacturing?'}, {'citations': ['Glossary', 'product lifecycle management (PLM)', 'The management of data and processes for a product throughout its entire lifecycle, from design, development, and launch, through growth and maturity, to decline and removal.'], 'expected_answer': 'Product lifecycle management (PLM) is the management of data and processes for a product across its entire lifecycle, from design to decline.', 'query': 'What is product lifecycle management (PLM)?'}, {'citations': ['Glossary', 'enterprise resource planning (ERP)', 'A system that automates and manages key business processes (such as accounting, MES, and project management) for an enterprise.'], 'expected_answer': 'Enterprise resource planning (ERP) is a system that automates and manages key business processes like accounting, MES, and project management for an enterprise.', 'query': 'What is enterprise resource planning (ERP)?'}, {'citations': ['Glossary', 'manufacturing execution system (MES)', 'A software system for tracking, monitoring, documenting, and controlling production processes that convert raw materials to finished products on the shop floor.'], 'expected_answer': 'A manufacturing execution system (MES) is a software system that tracks, monitors, documents, and controls production processes from raw materials to finished products on the shop floor.', 'query': 'What is a manufacturing execution system (MES)?'}, {'citations': ['Glossary', 'electronic data interchange (EDI)', 'The automated exchange of business documents between organizations.'], 'expected_answer': 'Electronic data interchange (EDI) is the automated exchange of business documents between organizations.', 'query': 'What is electronic data interchange (EDI)?'}, {'citations': ['Glossary', 'cloud computing', 'The cloud technology that is typically used for remote data storage and IoT device management. Cloud computing is commonly connected to edge computing technology.'], 'expected_answer': 'Cloud computing is a technology typically used for remote data storage and IoT device management, often connected to edge computing.', 'query': 'What is cloud computing?'}, {'citations': ['Glossary', 'edge computing', 'The technology that increases the computing power for smart devices at the edges of an IoT network. When compared with cloud computing, edge computing can reduce communication latency and improve response time.'], 'expected_answer': 'Edge computing increases computing power for smart devices at the edges of an IoT network, reducing communication latency and improving response time compared to cloud computing.', 'query': 'What is edge computing?'}, {'citations': ['Glossary', 'data warehouse', 'A data management system that supports business intelligence, such as analytics. Data warehouses commonly contain large amounts of historical data, and they are typically used for queries and analysis.'], 'expected_answer': 'A data warehouse is a data management system supporting business intelligence and analytics, typically containing large amounts of historical data for queries and analysis.', 'query': 'What is a data warehouse?'}, {'citations': ['Glossary', 'data minimization', 'The principle of collecting and processing only the data that is strictly necessary. Practicing data minimization in the AWS Cloud can reduce privacy risks, costs, and your analytics carbon footprint.'], 'expected_answer': 'Data minimization is the principle of collecting and processing only strictly necessary data, which in the AWS Cloud can reduce privacy risks, costs, and analytics carbon footprint.', 'query': 'What is data minimization?'}, {'citations': ['Glossary', 'data perimeter', 'A set of preventive guardrails in your AWS environment that help make sure that only trusted identities are accessing trusted resources from expected networks.'], 'expected_answer': 'A data perimeter is a set of preventive guardrails in an AWS environment ensuring only trusted identities access trusted resources from expected networks.', 'query': 'What is a data perimeter?'}, {'citations': ['Glossary', 'data provenance', 'The process of tracking the origin and history of data throughout its lifecycle, such as how the data was generated, transmitted, and stored.'], 'expected_answer': \"Data provenance is the process of tracking data's origin and history throughout its lifecycle, including how it was generated, transmitted, and stored.\", 'query': 'What is data provenance?'}, {'citations': ['Glossary', 'data classification', 'A process for identifying and categorizing the data in your network based on its criticality and sensitivity. It is a critical component of any cybersecurity risk management strategy because it helps you determine the appropriate protection and retention controls for the data.'], 'expected_answer': 'Data classification is the process of identifying and categorizing network data by criticality and sensitivity, crucial for cybersecurity risk management to determine appropriate protection and retention controls.', 'query': 'What is data classification?'}, {'citations': ['Glossary', 'data preprocessing', 'To transform raw data into a format that is easily parsed by your ML model. Preprocessing data can mean removing certain columns or rows and addressing missing, inconsistent, or duplicate values.'], 'expected_answer': 'Data preprocessing transforms raw data into a format easily parsed by an ML model, involving tasks like removing columns/rows and handling missing, inconsistent, or duplicate values.', 'query': 'What is data preprocessing?'}, {'citations': ['Glossary', 'data drift', 'A meaningful variation between the production data and the data that was used to train an ML model, or a meaningful change in the input data over time. Data drift can reduce the overall quality, accuracy, and fairness in ML model predictions.'], 'expected_answer': 'Data drift is a significant variation between production data and ML model training data, or a meaningful change in input data over time, which can reduce ML model prediction quality, accuracy, and fairness.', 'query': 'What is data drift?'}, {'citations': ['Glossary', 'data subject', 'An individual whose data is being collected and processed.'], 'expected_answer': 'A data subject is an individual whose data is being collected and processed.', 'query': 'Who is a data subject?'}, {'citations': ['Glossary', 'digital twin', 'A virtual representation of a real-world system, such as a building, factory, industrial equipment, or production line. Digital twins support predictive maintenance, remote monitoring, and production optimization.'], 'expected_answer': 'A digital twin is a virtual representation of a real-world system, like a factory, supporting predictive maintenance, remote monitoring, and production optimization.', 'query': 'What is a digital twin?'}, {'citations': ['Glossary', 'encryption', 'A computing process that transforms plaintext data, which is human-readable, into ciphertext.'], 'expected_answer': 'Encryption is a computing process that transforms human-readable plaintext data into ciphertext.', 'query': 'What is encryption?'}, {'citations': ['Glossary', 'encryption key', 'A cryptographic string of randomized bits that is generated by an encryption algorithm. Keys can vary in length, and each key is designed to be unpredictable and unique.'], 'expected_answer': 'An encryption key is a cryptographic string of randomized bits generated by an encryption algorithm, varying in length, and designed to be unpredictable and unique.', 'query': 'What is an encryption key?'}, {'citations': ['Glossary', 'envelope encryption', 'The process of encrypting an encryption key with another encryption key.'], 'expected_answer': 'Envelope encryption is the process of encrypting an encryption key with another encryption key.', 'query': 'What is envelope encryption?'}, {'citations': ['Glossary', 'symmetric encryption', 'An encryption algorithm that uses the same key to encrypt and decrypt the data.'], 'expected_answer': 'Symmetric encryption uses the same key for both encrypting and decrypting data.', 'query': 'What is symmetric encryption?'}, {'citations': ['Glossary', 'asymmetric encryption', 'An encryption algorithm that uses a pair of keys, a public key for encryption and a private key for decryption. You can share the public key because it isnât used for decryption, but access to the private key should be highly restricted.'], 'expected_answer': 'Asymmetric encryption uses a public key for encryption and a private key for decryption; the public key can be shared, but private key access must be highly restricted.', 'query': 'What is asymmetric encryption?'}, {'citations': ['Glossary', 'client-side encryption', 'Encryption of data locally, before the target AWS service receives it.'], 'expected_answer': 'Client-side encryption is the local encryption of data before it reaches the target AWS service.', 'query': 'What is client-side encryption?'}, {'citations': ['Glossary', 'server-side encryption', 'Encryption of data at its destination, by the AWS service that receives it.'], 'expected_answer': 'Server-side encryption is the encryption of data at its destination by the receiving AWS service.', 'query': 'What is server-side encryption?'}, {'citations': ['Glossary', 'environment', 'An instance of a running application. The following are common types of environments in cloud computing: development environment, lower environments, production environment, upper environments.'], 'expected_answer': 'An environment is an instance of a running application, with common types in cloud computing including development, lower, production, and upper environments.', 'query': 'What is an environment in cloud computing?'}, {'citations': ['Glossary', 'development environment', 'An instance of a running application that is available only to the core team responsible for maintaining the application. Development environments are used to test changes before promoting them to upper environments. This type of environment is sometimes referred to as a test environment.'], 'expected_answer': 'A development environment is an instance of a running application accessible only to the core maintenance team, used for testing changes before promotion to upper environments, sometimes called a test environment.', 'query': 'What is a development environment?'}, {'citations': ['Glossary', 'production environment', 'An instance of a running application that end users can access. In a CI/CD pipeline, the production environment is the last deployment environment.'], 'expected_answer': 'A production environment is an instance of a running application accessible by end users, serving as the final deployment environment in a CI/CD pipeline.', 'query': 'What is a production environment?'}, {'citations': ['Glossary', 'lower environments', 'All development environments for an application, such as those used for initial builds and tests.'], 'expected_answer': 'Lower environments encompass all development environments for an application, including those used for initial builds and tests.', 'query': 'What are lower environments?'}, {'citations': ['Glossary', 'upper environments', 'All environments that can be accessed by users other than the core development team. This can include a production environment, preproduction environments, and environments for user acceptance testing.'], 'expected_answer': 'Upper environments include all environments accessible by users beyond the core development team, such as production, preproduction, and user acceptance testing environments.', 'query': 'What are upper environments?'}, {'citations': ['Glossary', 'Gitflow workflow', 'An approach in which lower and upper environments use different branches in a source code repository. The Gitflow workflow is considered legacy, and the trunk-based workflow is the modern, preferred approach.'], 'expected_answer': 'Gitflow workflow is a legacy approach where lower and upper environments use different branches in a source code repository; trunk-based workflow is the modern, preferred alternative.', 'query': 'What is Gitflow workflow?'}, {'citations': ['Glossary', 'branch', 'A contained area of a code repository. The first branch created in a repository is the main branch. You can create a new branch from an existing branch, and you can then develop features or fix bugs in the new branch.'], 'expected_answer': 'A branch is a contained area within a code repository. The initial branch is the main branch, from which new branches can be created for developing features or fixing bugs.', 'query': 'What is a branch in a code repository?'}, {'citations': ['Glossary', 'main branch', 'The first branch created in a repository is the main branch.'], 'expected_answer': 'The main branch is the first branch created in a repository.', 'query': 'What is the main branch?'}, {'citations': ['Glossary', 'feature branch', 'A branch you create to build a feature is commonly referred to as a feature branch.'], 'expected_answer': 'A feature branch is a branch created specifically for building a new feature.', 'query': 'What is a feature branch?'}, {'citations': ['Glossary', 'heterogeneous database migration', 'Migrating your source database to a target database that uses a different database engine (for example, Oracle to Amazon Aurora). Heterogeneous migration is typically part of a re-architecting effort, and converting the schema can be a complex task.'], 'expected_answer': 'Heterogeneous database migration involves moving a source database to a target database with a different engine (e.g., Oracle to Amazon Aurora), typically part of a re-architecting effort, and schema conversion can be complex.', 'query': 'What is heterogeneous database migration?'}, {'citations': ['Glossary', 'homogeneous database migration', 'Migrating your source database to a target database that shares the same database engine (for example, Microsoft SQL Server to Amazon RDS for SQL Server). Homogeneous migration is typically part of a rehosting or replatforming effort. You can use native database utilities to migrate the schema.'], 'expected_answer': 'Homogeneous database migration involves moving a source database to a target database with the same engine (e.g., SQL Server to Amazon RDS for SQL Server), typically for rehosting or replatforming, using native database utilities for schema migration.', 'query': 'What is homogeneous database migration?'}, {'citations': ['Glossary', 'RACI matrix', 'A matrix that defines the roles and responsibilities for all parties involved in migration activities and cloud operations. The matrix name is derived from the responsibility types defined in the matrix: responsible (R), accountable (A), consulted (C), and informed (I).'], 'expected_answer': 'A RACI matrix defines roles and responsibilities for migration and cloud operations, with its name derived from the responsibility types: Responsible (R), Accountable (A), Consulted (C), and Informed (I).', 'query': 'What is a RACI matrix?'}, {'citations': ['Glossary', 'RASCI matrix', \"If you include support, the matrix is called a RASCI matrix, and if you exclude it, it's called a RACI matrix.\"], 'expected_answer': \"If the support (S) type is included, the matrix is called a RASCI matrix; otherwise, it's a RACI matrix.\", 'query': 'What is the difference between a RACI and RASCI matrix?'}, {'citations': ['Glossary', 'security control', 'A technical or administrative guardrail that prevents, detects, or reduces the ability of a threat actor to exploit a security vulnerability. There are four primary types of security controls: preventative, detective, responsive, and proactive.'], 'expected_answer': \"A security control is a technical or administrative guardrail that prevents, detects, or reduces a threat actor's ability to exploit a security vulnerability. The four primary types are preventative, detective, responsive, and proactive.\", 'query': 'What is a security control and what are its primary types?'}, {'citations': ['Glossary', 'preventative control', 'A security control that is designed to prevent an event from occurring. These controls are a first line of defense to help prevent unauthorized access or unwanted changes to your network.'], 'expected_answer': 'A preventative control is a security control designed to prevent an event from occurring, serving as a first line of defense against unauthorized access or unwanted network changes.', 'query': 'What is a preventative control?'}, {'citations': ['Glossary', 'detective control', 'A security control that is designed to detect, log, and alert after an event has occurred. These controls are a second line of defense, alerting you to security events that bypassed the preventative controls in place.'], 'expected_answer': 'A detective control is a security control designed to detect, log, and alert after an event, acting as a second line of defense by notifying of security events that bypassed preventative controls.', 'query': 'What is a detective control?'}, {'citations': ['Glossary', 'responsive control', 'A security control that is designed to drive remediation of adverse events or deviations from your security baseline.'], 'expected_answer': 'A responsive control is a security control designed to remediate adverse events or deviations from a security baseline.', 'query': 'What is a responsive control?'}, {'citations': ['Glossary', 'proactive control', 'A security control designed to prevent the deployment of noncompliant resources. These controls scan resources before they are provisioned. If the resource is not compliant with the control, then it isnât provisioned.'], 'expected_answer': 'A proactive control is a security control designed to prevent the deployment of noncompliant resources by scanning them before provisioning and blocking non-compliant ones.', 'query': 'What is a proactive control?'}, {'citations': ['Glossary', 'security by design', 'A system engineering approach that takes security into account through the whole development process.'], 'expected_answer': 'Security by design is a system engineering approach that integrates security considerations throughout the entire development process.', 'query': 'What is security by design?'}, {'citations': ['Glossary', 'privacy by design', 'A system engineering approach that takes privacy into account through the whole development process.'], 'expected_answer': 'Privacy by design is a system engineering approach that integrates privacy considerations throughout the entire development process.', 'query': 'What is privacy by design?'}, {'citations': ['Glossary', 'anonymization', 'The process of permanently deleting personal information in a dataset. Anonymization can help protect personal privacy. Anonymized data is no longer considered to be personal data.'], 'expected_answer': 'Anonymization is the process of permanently deleting personal information from a dataset to protect privacy, rendering the data no longer personal.', 'query': 'What is anonymization?'}, {'citations': ['Glossary', 'pseudonymization', 'The process of replacing personal identifiers in a dataset with placeholder values. Pseudonymization can help protect personal privacy. Pseudonymized data is still considered to be personal data.'], 'expected_answer': 'Pseudonymization is the process of replacing personal identifiers in a dataset with placeholder values to protect privacy, though the data is still considered personal.', 'query': 'What is pseudonymization?'}, {'citations': ['Glossary', 'bad bot', 'A bot that is intended to disrupt or cause harm to individuals or organizations.'], 'expected_answer': 'A bad bot is a bot designed to disrupt or harm individuals or organizations.', 'query': 'What is a bad bot?'}, {'citations': ['Glossary', 'botnet', 'Networks of bots that are infected by malware and are under the control of a single party, known as a bot herder or bot operator.'], 'expected_answer': 'A botnet is a network of malware-infected bots controlled by a single party, known as a bot herder or operator.', 'query': 'What is a botnet?'}, {'citations': ['Glossary', 'malware', 'Software that is designed to compromise computer security or privacy. Malware might disrupt computer systems, leak sensitive information, or gain unauthorized access.'], 'expected_answer': 'Malware is software designed to compromise computer security or privacy, potentially disrupting systems, leaking sensitive information, or gaining unauthorized access.', 'query': 'What is malware?'}, {'citations': ['Glossary', 'ransomware', 'A malicious software that is designed to block access to a computer system or data until a payment is made.'], 'expected_answer': 'Ransomware is malicious software designed to block access to a computer system or data until a payment is made.', 'query': 'What is ransomware?'}, {'citations': ['Glossary', 'zero-day exploit', 'An attack, typically malware, that takes advantage of a zero-day vulnerability.'], 'expected_answer': 'A zero-day exploit is an attack, usually malware, that leverages a zero-day vulnerability.', 'query': 'What is a zero-day exploit?'}, {'citations': ['Glossary', 'vulnerability', 'A software or hardware flaw that compromises the security of the system.'], 'expected_answer': 'A vulnerability is a software or hardware flaw that compromises system security.', 'query': 'What is a vulnerability?'}, {'citations': ['Glossary', 'configuration drift', \"For a workload, a configuration change from the expected state. It might cause the workload to become noncompliant, and it's typically gradual and unintentional.\"], 'expected_answer': 'Configuration drift is a gradual, unintentional configuration change in a workload from its expected state, potentially leading to noncompliance.', 'query': 'What is configuration drift?'}, {'citations': ['Glossary', 'drift detection', 'Tracking deviations from a baselined configuration. For example, you can use AWS CloudFormation to detect drift in system resources, or you can use AWS Control Tower to detect changes in your landing zone that might affect compliance with governance requirements.'], 'expected_answer': 'Drift detection tracks deviations from a baselined configuration, such as using AWS CloudFormation for system resources or AWS Control Tower for landing zone changes affecting governance compliance.', 'query': 'What is drift detection?'}, {'citations': ['Glossary', 'conformance pack', 'A collection of AWS Config rules and remediation actions that you can assemble to customize your compliance and security checks. You can deploy a conformance pack as a single entity in an AWS account and Region, or across an organization, by using a YAML template.'], 'expected_answer': 'A conformance pack is a collection of AWS Config rules and remediation actions customizable for compliance and security checks, deployable as a single entity in an AWS account/Region or across an organization via a YAML template.', 'query': 'What is a conformance pack?'}, {'citations': ['Glossary', 'IT service management (ITSM)', 'Activities associated with designing, implementing, managing, and supporting IT services for an organization.'], 'expected_answer': 'IT service management (ITSM) encompasses activities related to designing, implementing, managing, and supporting IT services for an organization.', 'query': 'What is IT service management (ITSM)?'}, {'citations': ['Glossary', 'IT information library (ITIL)', 'A set of best practices for delivering IT services and aligning these services with business requirements. ITIL provides the foundation for ITSM.'], 'expected_answer': 'ITIL (IT information library) is a set of best practices for delivering IT services and aligning them with business requirements, forming the foundation for ITSM.', 'query': 'What is ITIL?'}, {'citations': ['Glossary', 'cloud operating model', 'In an IT organization, the operating model that is used to build, mature, and optimize one or more cloud environments.'], 'expected_answer': 'A cloud operating model is the framework used by an IT organization to build, mature, and optimize cloud environments.', 'query': 'What is a cloud operating model?'}, {'citations': ['Glossary', 'AWS Cloud Adoption Framework (AWS CAF)', 'A framework of guidelines and best practices from AWS to help organizations develop an efficient and effective plan to move successfully to the cloud.'], 'expected_answer': 'The AWS Cloud Adoption Framework (AWS CAF) is an AWS framework providing guidelines and best practices to help organizations develop efficient and effective plans for successful cloud migration.', 'query': 'What is the AWS Cloud Adoption Framework (AWS CAF)?'}, {'citations': ['Glossary', 'AWS Workload Qualification Framework (AWS WQF)', 'A tool that evaluates database migration workloads, recommends migration strategies, and provides work estimates. AWS WQF is included with AWS Schema Conversion Tool (AWS SCT).'], 'expected_answer': 'AWS Workload Qualification Framework (AWS WQF) is a tool included with AWS Schema Conversion Tool (AWS SCT) that evaluates database migration workloads, recommends strategies, and provides work estimates.', 'query': 'What is the AWS Workload Qualification Framework (AWS WQF)?'}, {'citations': ['Glossary', 'cloud stages of adoption', 'The four phases that organizations typically go through when they migrate to the AWS Cloud: Project, Foundation, Migration, Re-invention.'], 'expected_answer': 'The four cloud stages of adoption are Project, Foundation, Migration, and Re-invention.', 'query': 'What are the four cloud stages of adoption?'}, {'citations': ['Glossary', 'business continuity planning (BCP)', 'A plan that addresses the potential impact of a disruptive event, such as a large-scale migration, on operations and enables a business to resume operations quickly.'], 'expected_answer': 'Business continuity planning (BCP) is a plan addressing the potential impact of disruptive events on operations, enabling quick business resumption.', 'query': 'What is business continuity planning (BCP)?'}, {'citations': ['Glossary', 'application portfolio', 'A collection of detailed information about each application used by an organization, including the cost to build and maintain the application, and its business value.'], 'expected_answer': \"An application portfolio is a collection of detailed information about an organization's applications, including their build/maintenance costs and business value.\", 'query': 'What is an application portfolio?'}, {'citations': ['Glossary', 'portfolio assessment', 'A process of discovering, analyzing, and prioritizing the application portfolio in order to plan the migration.'], 'expected_answer': 'Portfolio assessment is the process of discovering, analyzing, and prioritizing an application portfolio to plan migration.', 'query': 'What is portfolio assessment?'}, {'citations': ['Glossary', 'CMDB', 'A repository that stores and manages information about a database and its IT environment, including both hardware and software components and their configurations.'], 'expected_answer': 'A CMDB is a repository that stores and manages information about a database and its IT environment, including hardware, software, and configurations.', 'query': 'What is a CMDB?'}, {'citations': ['Glossary', 'code repository', 'A location where source code and other assets, such as documentation, samples, and scripts, are stored and updated through version control processes.'], 'expected_answer': 'A code repository is a location where source code and other assets like documentation, samples, and scripts are stored and updated via version control.', 'query': 'What is a code repository?'}, {'citations': ['Glossary', 'version control', 'Processes and tools that track changes, such as changes to source code in a repository.'], 'expected_answer': 'Version control refers to processes and tools that track changes, such as those in source code repositories.', 'query': 'What is version control?'}, {'citations': ['Glossary', 'deployment', 'The process of making an application, new features, or code fixes available in the target environment. Deployment involves implementing changes in a code base and then building and running that code base in the applicationâs environments.'], 'expected_answer': \"Deployment is the process of making an application, new features, or code fixes available in the target environment, involving implementing changes in a codebase, then building and running it in the application's environments.\", 'query': 'What is deployment?'}, {'citations': ['Glossary', 'release', 'In a deployment process, the act of promoting changes to a production environment.'], 'expected_answer': 'In a deployment process, a release is the act of promoting changes to a production environment.', 'query': 'What is a release in a deployment process?'}, {'citations': ['Glossary', 'infrastructure', \"All of the resources and assets contained within an application's environment.\"], 'expected_answer': \"Infrastructure refers to all resources and assets within an application's environment.\", 'query': 'What is infrastructure?'}, {'citations': ['Glossary', 'mechanism', 'A complete process in which you create a tool, drive adoption of the tool, and then inspect the results in order to make adjustments. A mechanism is a cycle that reinforces and improves itself as it operates.'], 'expected_answer': 'A mechanism is a complete process involving tool creation, adoption, and result inspection for adjustments, forming a self-reinforcing and improving cycle.', 'query': 'What is a mechanism in the context of operations?'}, {'citations': ['Glossary', 'operational-level agreement (OLA)', 'An agreement that clarifies what functional IT groups promise to deliver to each other, to support a service-level agreement (SLA).'], 'expected_answer': 'An operational-level agreement (OLA) clarifies what functional IT groups promise to deliver to each other to support a service-level agreement (SLA).', 'query': 'What is an OLA?'}, {'citations': ['Glossary', 'service-level agreement (SLA)', 'An agreement that clarifies what an IT team promises to deliver to their customers, such as service uptime and performance.'], 'expected_answer': 'A service-level agreement (SLA) is an agreement clarifying what an IT team promises to deliver to customers, including service uptime and performance.', 'query': 'What is an SLA?'}, {'citations': ['Glossary', 'service-level indicator (SLI)', 'A measurement of a performance aspect of a service, such as its error rate, availability, or throughput.'], 'expected_answer': \"A service-level indicator (SLI) measures a service's performance aspect, such as error rate, availability, or throughput.\", 'query': 'What is an SLI?'}, {'citations': ['Glossary', 'service-level objective (SLO)', 'A target metric that represents the health of a service, as measured by a service-level indicator.'], 'expected_answer': \"A service-level objective (SLO) is a target metric indicating a service's health, measured by a service-level indicator.\", 'query': 'What is an SLO?'}, {'citations': ['Glossary', 'workstream', 'Functional groups in a migration project that are responsible for a specific set of tasks. Each workstream is independent but supports the other workstreams in the project.'], 'expected_answer': 'A workstream refers to independent functional groups in a migration project, each responsible for specific tasks while supporting other workstreams.', 'query': 'What is a workstream in a migration project?'}, {'citations': ['Glossary', 'responsible, accountable, consulted, informed (RACI) matrix', 'The matrix name is derived from the responsibility types defined in the matrix: responsible (R), accountable (A), consulted (C), and informed (I).'], 'expected_answer': 'The RACI matrix derives its name from the responsibility types: Responsible (R), Accountable (A), Consulted (C), and Informed (I).', 'query': 'What do the letters in RACI stand for?'}, {'citations': ['Glossary', 'binary classification', 'A process that predicts a binary outcome (one of two possible classes). For example, your ML model might need to predict problems such as \"Is this email spam or not spam?\" or \"Is this product a book or a car?\"'], 'expected_answer': 'Binary classification predicts one of two possible outcomes, such as whether an email is spam or not spam.', 'query': 'What is binary classification?'}, {'citations': ['Glossary', 'multiclass classification', 'A process that helps generate predictions for multiple classes (predicting one of more than two outcomes). For example, an ML model might ask \"Is this product a book, car, or phone?\" or \"Which product category is most interesting to this customer?\"'], 'expected_answer': 'Multiclass classification generates predictions for more than two outcomes, such as identifying a product as a book, car, or phone.', 'query': 'What is multiclass classification?'}, {'citations': ['Glossary', 'regression', 'An ML technique that predicts a numeric value. For example, to solve the problem of \"What price will this house sell for?\" an ML model could use a linear regression model to predict a houseâs sale price based on known facts about the house (for example, the square footage).'], 'expected_answer': \"Regression is an ML technique that predicts a numeric value, such as a house's sale price based on its square footage.\", 'query': 'What is regression in machine learning?'}, {'citations': ['Glossary', 'target variable', 'The value that you are trying to predict in supervised ML. This is also referred to as an outcome variable. For example, in a manufacturing setting the target variable could be a product defect.'], 'expected_answer': 'The target variable, also known as an outcome variable, is the value being predicted in supervised machine learning, such as a product defect in manufacturing.', 'query': 'What is a target variable in supervised ML?'}, {'citations': ['Glossary', 'features', 'The input data that you use to make a prediction. For example, in a manufacturing context, features could be images that are periodically captured from the manufacturing line.'], 'expected_answer': 'Features are the input data used for predictions, such as images captured from a manufacturing line.', 'query': 'What are features in machine learning?'}, {'citations': ['Glossary', 'feature importance', 'How significant a feature is for a modelâs predictions. This is usually expressed as a numerical score that can be calculated through various techniques, such as Shapley Additive Explanations (SHAP) and integrated gradients.'], 'expected_answer': \"Feature importance quantifies a feature's significance for a model's predictions, typically expressed as a numerical score calculated using techniques like SHAP and integrated gradients.\", 'query': 'What is feature importance?'}, {'citations': ['Glossary', 'feature transformation', 'To optimize data for the ML process, including enriching data with additional sources, scaling values, or extracting multiple sets of information from a single data field. This enables the ML model to benefit from the data.'], 'expected_answer': 'Feature transformation optimizes data for ML by enriching it with additional sources, scaling values, or extracting multiple information sets from a single field, enabling the ML model to benefit from the data.', 'query': 'What is feature transformation?'}, {'citations': ['Glossary', 'interpretability', \"A characteristic of a machine learning model that describes the degree to which a human can understand how the model's predictions depend on its inputs.\"], 'expected_answer': \"Interpretability describes how well a human can understand a machine learning model's predictions based on its inputs.\", 'query': 'What is interpretability in machine learning?'}, {'citations': ['Glossary', 'uncertainty', 'A concept that refers to imprecise, incomplete, or unknown information that can undermine the reliability of predictive ML models. There are two types of uncertainty: Epistemic uncertainty is caused by limited, incomplete data, whereas aleatoric uncertainty is caused by the noise and randomness inherent in the data.'], 'expected_answer': 'Uncertainty refers to imprecise, incomplete, or unknown information that can undermine ML model reliability. It has two types: epistemic (due to limited data) and aleatoric (due to inherent data noise/randomness).', 'query': 'What is uncertainty in ML models, and what are its two types?'}, {'citations': ['Glossary', 'cold cache', 'A buffer cache that is empty, not well populated, or contains stale or irrelevant data. This affects performance because the database instance must read from the main memory or disk, which is slower than reading from the buffer cache.'], 'expected_answer': 'A cold cache is an empty, poorly populated, or stale buffer cache, impacting performance as the database must read slower from main memory or disk instead of the cache.', 'query': 'What is a cold cache?'}, {'citations': ['Glossary', 'warm cache', 'A buffer cache that contains current, relevant data that is frequently accessed. The database instance can read from the buffer cache, which is faster than reading from the main memory or disk.'], 'expected_answer': 'A warm cache is a buffer cache containing current, frequently accessed data, allowing the database instance to read faster from it than from main memory or disk.', 'query': 'What is a warm cache?'}, {'citations': ['Glossary', 'buffer cache', 'The memory area where the most frequently accessed data is stored.'], 'expected_answer': 'The buffer cache is the memory area where the most frequently accessed data is stored.', 'query': 'What is a buffer cache?'}, {'citations': ['Glossary', 'database definition language (DDL)', 'Statements or commands for creating or modifying the structure of tables and objects in a database.'], 'expected_answer': 'Database Definition Language (DDL) consists of statements or commands used to create or modify the structure of tables and objects in a database.', 'query': 'What is DDL?'}, {'citations': ['Glossary', 'database manipulation language (DML)', 'Statements or commands for modifying (inserting, updating, and deleting) information in a database.'], 'expected_answer': 'Database Manipulation Language (DML) consists of statements or commands for modifying (inserting, updating, and deleting) information in a database.', 'query': 'What is DML?'}, {'citations': ['Glossary', 'predicate', 'A query condition that returns true or false, commonly located in a WHERE clause.'], 'expected_answer': 'A predicate is a query condition, typically found in a WHERE clause, that returns true or false.', 'query': 'What is a predicate in a database query?'}, {'citations': ['Glossary', 'predicate pushdown', 'A database query optimization technique that filters the data in the query before transfer. This reduces the amount of data that must be retrieved and processed from the relational database, and it improves query performance.'], 'expected_answer': 'Predicate pushdown is a database query optimization technique that filters data before transfer, reducing data retrieval and processing from the relational database, thereby improving query performance.', 'query': 'What is predicate pushdown?'}, {'citations': ['Glossary', 'window function', 'A SQL function that performs a calculation on a group of rows that relate in some way to the current record. Window functions are useful for processing tasks, such as calculating a moving average or accessing the value of rows based on the relative position of the current row.'], 'expected_answer': 'A window function is a SQL function that calculates over a group of rows related to the current record, useful for tasks like moving averages or accessing row values based on relative position.', 'query': 'What is a window function in SQL?'}, {'citations': ['Glossary', 'aggregate function', 'A SQL function that operates on a group of rows and calculates a single return value for the group. Examples of aggregate functions include SUM and MAX.'], 'expected_answer': 'An aggregate function is a SQL function that operates on a group of rows to calculate a single return value for that group, such as SUM or MAX.', 'query': 'What is an aggregate function in SQL?'}, {'citations': ['Glossary', 'endianness', 'The order in which bytes are stored in computer memory. Big-endian systems store the most significant byte first. Little-endian systems store the least significant byte first.'], 'expected_answer': 'Endianness refers to the byte order in computer memory: big-endian stores the most significant byte first, while little-endian stores the least significant byte first.', 'query': 'What is endianness?'}, {'citations': ['Glossary', 'big-endian system', 'A system that stores the most significant byte first.'], 'expected_answer': 'A big-endian system stores the most significant byte first.', 'query': 'What is a big-endian system?'}, {'citations': ['Glossary', 'little-endian system', 'A system that stores the least significant byte first.'], 'expected_answer': 'A little-endian system stores the least significant byte first.', 'query': 'What is a little-endian system?'}, {'citations': ['Glossary', 'vacuuming', 'A database maintenance operation that involves cleaning up after incremental updates to reclaim storage and improve performance.'], 'expected_answer': 'Vacuuming is a database maintenance operation that cleans up after incremental updates to reclaim storage and improve performance.', 'query': 'What is vacuuming in database maintenance?'}, {'citations': ['Glossary', 'private hosted zones', 'A container that holds information about how you want Amazon Route 53 to respond to DNS queries for a domain and its subdomains within one or more VPCs.'], 'expected_answer': 'Private hosted zones are containers in Amazon Route 53 that define how DNS queries for a domain and its subdomains are resolved within one or more VPCs.', 'query': 'What are private hosted zones?'}, {'citations': ['Glossary', 'Region', 'A collection of AWS resources in a geographic area. Each AWS Region is isolated and independent of the others to provide fault tolerance, stability, and resilience.'], 'expected_answer': 'An AWS Region is a collection of AWS resources in a geographic area, isolated and independent for fault tolerance, stability, and resilience.', 'query': 'What is an AWS Region?'}, {'citations': ['Glossary', 'origin access control (OAC)', 'In CloudFront, an enhanced option for restricting access to secure your Amazon Simple Storage Service (Amazon S3) content. OAC supports all S3 buckets in all AWS Regions, server-side encryption with AWS KMS (SSE-KMS), and dynamic PUT and DELETE requests to the S3 bucket.'], 'expected_answer': 'Origin Access Control (OAC) in CloudFront is an enhanced option for securing Amazon S3 content by restricting access. It supports all S3 buckets across all AWS Regions, server-side encryption with AWS KMS, and dynamic PUT/DELETE requests to S3 buckets.', 'query': 'What is Origin Access Control (OAC) in CloudFront?'}, {'citations': ['Glossary', 'origin access identity (OAI)', 'In CloudFront, an option for restricting access to secure your Amazon S3 content. When you use OAI, CloudFront creates a principal that Amazon S3 can authenticate with. Authenticated principals can access content in an S3 bucket only through a specific CloudFront distribution.'], 'expected_answer': 'Origin Access Identity (OAI) in CloudFront restricts access to Amazon S3 content by creating a principal that S3 authenticates with, allowing access only through a specific CloudFront distribution.', 'query': 'What is Origin Access Identity (OAI) in CloudFront?'}, {'citations': ['Glossary', 'geo blocking', 'In Amazon CloudFront, an option to prevent users in specific countries from accessing content distributions. You can use an allow list or block list to specify approved and banned countries.'], 'expected_answer': 'Geo blocking, or geographic restrictions, in Amazon CloudFront is an option to prevent users in specific countries from accessing content distributions, using allow or block lists.', 'query': 'What is geo blocking in Amazon CloudFront?'}, {'citations': ['Glossary', 'attribute-based access control (ABAC)', 'The practice of creating fine-grained permissions based on user attributes, such as department, job role, and team name.'], 'expected_answer': 'Attribute-based access control (ABAC) is the practice of creating fine-grained permissions based on user attributes like department, job role, and team name.', 'query': 'What is attribute-based access control (ABAC)?'}, {'citations': ['Glossary', 'fine-grained access control (FGAC)', 'The use of multiple conditions to allow or deny an access request.'], 'expected_answer': 'Fine-grained access control (FGAC) uses multiple conditions to allow or deny an access request.', 'query': 'What is fine-grained access control (FGAC)?'}, {'citations': ['Glossary', 'row and column access control (RCAC)', 'The use of basic, flexible SQL expressions that have defined access rules. RCAC consists of row permissions and column masks.'], 'expected_answer': 'Row and column access control (RCAC) uses basic, flexible SQL expressions with defined access rules, comprising row permissions and column masks.', 'query': 'What is row and column access control (RCAC)?'}, {'citations': ['Glossary', 'identity-based policy', 'A policy attached to one or more IAM principals that defines their permissions within the AWS Cloud environment.'], 'expected_answer': 'An identity-based policy is attached to IAM principals, defining their permissions within the AWS Cloud environment.', 'query': 'What is an identity-based policy?'}, {'citations': ['Glossary', 'resource-based policy', 'A policy attached to a resource, such as an Amazon S3 bucket, an endpoint, or an encryption key. This type of policy specifies which principals are allowed access, supported actions, and any other conditions that must be met.'], 'expected_answer': 'A resource-based policy is attached to a resource (e.g., S3 bucket, endpoint, encryption key), specifying allowed principals, actions, and conditions for access.', 'query': 'What is a resource-based policy?'}, {'citations': ['Glossary', 'permissions boundary', 'An IAM management policy that is attached to IAM principals to set the maximum permissions that the user or role can have.'], 'expected_answer': 'A permissions boundary is an IAM management policy attached to IAM principals, setting the maximum permissions for that user or role.', 'query': 'What is a permissions boundary?'}, {'citations': ['Glossary', 'system prompt', 'A technique for providing context, instructions, or guidelines to an LLM to direct its behavior. System prompts help set context and establish rules for interactions with users.'], 'expected_answer': 'A system prompt is a technique for providing context, instructions, or guidelines to an LLM to direct its behavior, helping to set context and establish rules for user interactions.', 'query': 'What is a system prompt for an LLM?'}, {'citations': ['Glossary', 'prompt chaining', 'Using the output of one LLM prompt as the input for the next prompt to generate better responses. This technique is used to break down a complex task into subtasks, or to iteratively refine or expand a preliminary response.'], 'expected_answer': 'Prompt chaining uses the output of one LLM prompt as input for the next, improving responses by breaking down complex tasks or iteratively refining/expanding preliminary responses.', 'query': 'What is prompt chaining?'}, {'citations': ['Glossary', 'managed services', 'AWS services for which AWS operates the infrastructure layer, the operating system, and platforms, and you access the endpoints to store and retrieve data. Amazon Simple Storage Service (Amazon S3) and Amazon DynamoDB are examples of managed services. These are also known as abstracted services.'], 'expected_answer': 'Managed services are AWS services where AWS operates the infrastructure, OS, and platforms, while users access endpoints for data storage and retrieval. Examples include Amazon S3 and Amazon DynamoDB, also known as abstracted services.', 'query': 'What are managed services in AWS?'}, {'citations': ['Glossary', 'abstracted services', 'See managed services.'], 'expected_answer': 'Abstracted services are also known as managed services.', 'query': 'What are abstracted services?'}, {'citations': ['Glossary', 'business capability', 'What a business does to generate value (for example, sales, customer service, or marketing). Microservices architectures and development decisions can be driven by business capabilities.'], 'expected_answer': 'A business capability is what a business does to generate value, such as sales or customer service, and can drive microservices architectures and development decisions.', 'query': 'What is a business capability?'}, {'citations': ['Glossary', 'brownfield strategy', 'The existing infrastructure in your environment. When adopting a brownfield strategy for a system architecture, you design the architecture around the constraints of the current systems and infrastructure.'], 'expected_answer': 'A brownfield strategy involves designing system architecture around the constraints of existing infrastructure in your environment.', 'query': 'What is a brownfield strategy?'}, {'citations': ['Glossary', 'greenfield strategy', 'The absence of existing infrastructure in a new environment. When adopting a greenfield strategy for a system architecture, you can select all new technologies without the restriction of compatibility with existing infrastructure, also known as brownfield.'], 'expected_answer': 'A greenfield strategy involves designing system architecture in a new environment without existing infrastructure constraints, allowing selection of all new technologies.', 'query': 'What is a greenfield strategy?'}, {'citations': ['Glossary', 'inbound (ingress) VPC', 'In an AWS multi-account architecture, a VPC that accepts, inspects, and routes network connections from outside an application.'], 'expected_answer': 'In an AWS multi-account architecture, an inbound (ingress) VPC accepts, inspects, and routes network connections originating from outside an application.', 'query': 'What is an inbound (ingress) VPC?'}, {'citations': ['Glossary', 'outbound (egress) VPC', 'In an AWS multi-account architecture, a VPC that handles network connections that are initiated from within an application.'], 'expected_answer': 'In an AWS multi-account architecture, an outbound (egress) VPC handles network connections initiated from within an application.', 'query': 'What is an outbound (egress) VPC?'}, {'citations': ['Glossary', 'inspection VPC', 'In an AWS multi-account architecture, a centralized VPC that manages inspections of network traffic between VPCs (in the same or different AWS Regions), the internet, and on-premises networks.'], 'expected_answer': 'In an AWS multi-account architecture, an inspection VPC is a centralized VPC that manages network traffic inspections between VPCs (within or across regions), the internet, and on-premises networks.', 'query': 'What is an inspection VPC?'}, {'citations': ['Glossary', 'member account', 'All AWS accounts other than the management account that are part of an organization in AWS Organizations. An account can be a member of only one organization at a time.'], 'expected_answer': 'A member account is any AWS account, excluding the management account, that belongs to an organization in AWS Organizations. An account can only be a member of one organization at a time.', 'query': 'What is a member account in AWS Organizations?'}, {'citations': ['Glossary', 'delegated administrator', 'In AWS Organizations, a compatible service can register an AWS member account to administer the organizationâs accounts and manage permissions for that service. This account is called the delegated administrator for that service.'], 'expected_answer': \"In AWS Organizations, a delegated administrator is an AWS member account registered by a compatible service to administer the organization's accounts and manage permissions for that service.\", 'query': 'What is a delegated administrator in AWS Organizations?'}, {'citations': ['Glossary', 'trusted access', 'Granting permissions to a service that you specify to perform tasks in your organization in AWS Organizations and in its accounts on your behalf. The trusted service creates a service-linked role in each account, when that role is needed, to perform management tasks for you.'], 'expected_answer': 'Trusted access grants specified services permissions to perform tasks in your AWS Organizations organization and its accounts on your behalf, creating service-linked roles as needed for management tasks.', 'query': 'What is trusted access in AWS Organizations?'}, {'citations': ['Glossary', 'organization trail', 'A trail thatâs created by AWS CloudTrail that logs all events for all AWS accounts in an organization in AWS Organizations. This trail is created in each AWS account thatâs part of the organization and tracks the activity in each account.'], 'expected_answer': 'An organization trail is an AWS CloudTrail trail that logs all events for all AWS accounts within an AWS Organizations organization, created in each account to track its activity.', 'query': 'What is an organization trail in AWS CloudTrail?'}, {'citations': ['Glossary', 'break-glass access', \"In exceptional circumstances and through an approved process, a quick means for a user to gain access to an AWS account that they don't typically have permissions to access.\"], 'expected_answer': 'Break-glass access is a quick, approved means for a user to gain access to an AWS account they typically lack permissions for, used in exceptional circumstances.', 'query': 'What is break-glass access?'}, {'citations': ['Glossary', 'behavior graph', 'A unified, interactive view of resource behavior and interactions over time. You can use a behavior graph with Amazon Detective to examine failed logon attempts, suspicious API calls, and similar actions.'], 'expected_answer': 'A behavior graph provides a unified, interactive view of resource behavior and interactions over time, usable with Amazon Detective to examine failed logons, suspicious API calls, and similar actions.', 'query': 'What is a behavior graph?'}, {'citations': ['Glossary', 'security response automation', 'A predefined and programmed action that is designed to automatically respond to or remediate a security event. These automations serve as detective or responsive security controls that help you implement AWS security best practices.'], 'expected_answer': 'Security response automation is a predefined, programmed action designed to automatically respond to or remediate security events, serving as detective or responsive security controls to implement AWS security best practices.', 'query': 'What is security response automation?'}, {'citations': ['Glossary', 'security information and event management (SIEM) system', 'Tools and services that combine security information management (SIM) and security event management (SEM) systems. A SIEM system collects, monitors, and analyzes data from servers, networks, devices, and other sources to detect threats and security breaches, and to generate alerts.'], 'expected_answer': 'A SIEM system combines SIM and SEM tools/services to collect, monitor, and analyze data from various sources (servers, networks, devices) to detect threats, security breaches, and generate alerts.', 'query': 'What is a SIEM system?'}, {'citations': ['Glossary', 'synthetic testing', 'Testing a system in a way that simulates user interactions to detect potential issues or to monitor performance. You can use Amazon CloudWatch Synthetics to create these tests.'], 'expected_answer': 'Synthetic testing simulates user interactions to detect issues or monitor performance, and can be created using Amazon CloudWatch Synthetics.', 'query': 'What is synthetic testing?'}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "parsed = json.loads(result)\n",
    "print(parsed[\"test_cases\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cb3d10",
   "metadata": {},
   "source": [
    "# Turn into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "264b35e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citations</th>\n",
       "      <th>expected_answer</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Copyright \\nÂ© 2024 Amazon Web Services, Inc. ...</td>\n",
       "      <td>The copyright for the AWS Prescriptive Guidanc...</td>\n",
       "      <td>Who holds the copyright for this document and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Table of Contents, Introduction ................</td>\n",
       "      <td>The Introduction section of the document start...</td>\n",
       "      <td>On which page does the Introduction section be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Table of Contents, Anti-corruption layer patt...</td>\n",
       "      <td>The Anti-corruption layer pattern section star...</td>\n",
       "      <td>What page number is the Anti-corruption layer ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Table of Contents, API routing patterns ........</td>\n",
       "      <td>API routing patterns are covered starting on p...</td>\n",
       "      <td>Where can I find information about API routing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Table of Contents, Circuit breaker pattern .....</td>\n",
       "      <td>The Circuit breaker pattern begins on page 19.</td>\n",
       "      <td>What is the starting page for the Circuit brea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           citations  \\\n",
       "0  [Copyright \\nÂ© 2024 Amazon Web Services, Inc. ...   \n",
       "1  [Table of Contents, Introduction ................   \n",
       "2  [Table of Contents, Anti-corruption layer patt...   \n",
       "3  [Table of Contents, API routing patterns ........   \n",
       "4  [Table of Contents, Circuit breaker pattern .....   \n",
       "\n",
       "                                     expected_answer  \\\n",
       "0  The copyright for the AWS Prescriptive Guidanc...   \n",
       "1  The Introduction section of the document start...   \n",
       "2  The Anti-corruption layer pattern section star...   \n",
       "3  API routing patterns are covered starting on p...   \n",
       "4     The Circuit breaker pattern begins on page 19.   \n",
       "\n",
       "                                               query  \n",
       "0  Who holds the copyright for this document and ...  \n",
       "1  On which page does the Introduction section be...  \n",
       "2  What page number is the Anti-corruption layer ...  \n",
       "3  Where can I find information about API routing...  \n",
       "4  What is the starting page for the Circuit brea...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(parsed[\"test_cases\"])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df81cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns, query first, then expected_answer, then citations\n",
    "df = df[[\"query\", \"expected_answer\", \"citations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "356cbae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv(\"../tests/longCDPTestCases.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c92373",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
